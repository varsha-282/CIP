{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoi9IPoddepwWM6IZNQ+MY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varsha-282/CIP/blob/main/cipdemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qq3M_f3F_dZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe052ad-160c-4c94-f59b-28963c85343a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoded 'Preterm Pregnancy' column:\n",
            "0      1\n",
            "1      0\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "194    1\n",
            "195    0\n",
            "196    1\n",
            "197    1\n",
            "198    1\n",
            "Name: Preterm Pregnancy, Length: 199, dtype: int8\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"Gestational DM.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "label_encoded = df.copy()\n",
        "label_encoded['Preterm Pregnancy'] = label_encoded['Preterm Pregnancy'].astype('category').cat.codes\n",
        "\n",
        "print(\"Label Encoded 'Preterm Pregnancy' column:\")\n",
        "print(label_encoded['Preterm Pregnancy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_imputation(df):\n",
        "    column_means = df.mean()\n",
        "    df_filled = df.fillna(column_means)\n",
        "    return df_filled\n",
        "\n",
        "df_imputed = mean_imputation(label_encoded)\n",
        "changed_values = pd.concat([label_encoded[label_encoded != df_imputed].stack(), df_imputed[df_imputed != label_encoded].stack()], axis=1)\n",
        "changed_values.columns = ['Original', 'Imputed']\n",
        "\n",
        "print(\"Changed values before and after mean imputation:\")\n",
        "print(changed_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYTFBTBSjON1",
        "outputId": "cde66298-3aef-4adc-beb1-940be7dcb20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed values before and after mean imputation:\n",
            "         Original    Imputed\n",
            "10  BMI       NaN  21.991837\n",
            "22  BMI       NaN  21.991837\n",
            "130 BMI       NaN  21.991837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_file_path = \"preprocessed_data.csv\"\n",
        "df_imputed.to_csv(preprocessed_file_path, index=False)\n",
        "print(f\"Preprocessed data saved to '{preprocessed_file_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i65DeGBOjRXC",
        "outputId": "28002b0f-9ca7-466b-9a42-34a93551d936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed data saved to 'preprocessed_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "latent_dim = 100\n",
        "def build_generator():\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    label = Input(shape=(2,))\n",
        "    x = concatenate([noise, label])\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(12, activation='linear')(x)\n",
        "    generator = Model([noise, label], x)\n",
        "    return generator\n",
        "\n",
        "def build_discriminator():\n",
        "    data = Input(shape=(12,))\n",
        "    x = Dense(256, activation='relu')(data)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    validity = Dense(1, activation='sigmoid')(x)\n",
        "    discriminator = Model(data, validity)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "    return discriminator\n",
        "\n",
        "def build_combined(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    label = Input(shape=(2,))\n",
        "    synthetic_data = generator([noise, label])\n",
        "    validity = discriminator(synthetic_data)\n",
        "    combined = Model([noise, label], validity)\n",
        "    combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "    return combined\n",
        "\n",
        "def train_discriminator(discriminator, real_data, synthetic_data):\n",
        "    real_labels = np.ones((real_data.shape[0], 1))\n",
        "    fake_labels = np.zeros((synthetic_data.shape[0], 1))\n",
        "    discriminator.train_on_batch(real_data, real_labels)\n",
        "    discriminator.train_on_batch(synthetic_data, fake_labels)\n",
        "\n",
        "def train_generator(combined, noise, labels):\n",
        "    valid_labels = np.ones((noise.shape[0], 1))\n",
        "    combined.train_on_batch([noise, labels], valid_labels)\n",
        "\n",
        "def generate_synthetic_data(generator, num_samples):\n",
        "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
        "    labels = np.random.randint(0, 2, (num_samples, 2))\n",
        "    synthetic_data = generator.predict([noise, labels])\n",
        "    return synthetic_data\n",
        "\n",
        "preprocessed_data = pd.read_csv('preprocessed_data.csv')\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "combined = build_combined(generator, discriminator)\n",
        "\n",
        "num_epochs = 10000\n",
        "batch_size = 128\n",
        "for epoch in range(num_epochs):\n",
        "    idx = np.random.randint(0, preprocessed_data.shape[0], batch_size)\n",
        "    real_batch = preprocessed_data.iloc[idx]\n",
        "    synthetic_batch = generate_synthetic_data(generator, batch_size)\n",
        "    train_discriminator(discriminator, real_batch, synthetic_batch)\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    labels = np.random.randint(0, 2, (batch_size, 2))\n",
        "    train_generator(combined, noise, labels)\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "\n",
        "num_samples = 5000\n",
        "synthetic_data = generate_synthetic_data(generator, num_samples)\n",
        "synthetic_df = pd.DataFrame(synthetic_data, columns=preprocessed_data.columns)\n",
        "synthetic_df.to_csv('synthetic_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB-W_-9kjSl1",
        "outputId": "499eee56-9e30-429c-b26c-29e8a6cb6b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 5100/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 5200/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 5300/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 5400/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 5500/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 5600/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "Epoch 5700/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 5800/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 5900/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 6000/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 6100/10000\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 6200/10000\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 6300/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 6400/10000\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "Epoch 6500/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 6600/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 6700/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 6800/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 6900/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7000/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7100/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7200/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7300/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 7400/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7500/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7600/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 7700/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 7800/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 7900/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 8000/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 8100/10000\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "Epoch 8200/10000\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 8300/10000\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 8400/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 8500/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 8600/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 8700/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 8800/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 8900/10000\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 9000/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 9100/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 9200/10000\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 9300/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 9400/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 9500/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 9600/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "Epoch 9700/10000\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 9800/10000\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 13ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 9900/10000\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data = pd.read_csv('synthetic_data.csv')\n",
        "columns_to_round = ['Age', 'No of Pregnancy', 'Preterm Pregnancy', 'Systolic Blood Pressure', 'Diastolic Blood Pressure']\n",
        "synthetic_data.columns = synthetic_data.columns.str.strip()\n",
        "synthetic_data[columns_to_round] = synthetic_data[columns_to_round].round()\n",
        "synthetic_data['Preterm Pregnancy'] = synthetic_data['Preterm Pregnancy'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "synthetic_data.to_csv('synthetic_data_rounded.csv', index=False)\n"
      ],
      "metadata": {
        "id": "HBSlm4vRqIAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = pd.read_csv('synthetic_data_rounded.csv')\n",
        "preterm_pregnancy_counts = preprocessed_data['Preterm Pregnancy'].value_counts()\n",
        "\n",
        "print(\"Counts of 1's and 0's in 'Preterm Pregnancy' column:\")\n",
        "print(preterm_pregnancy_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfYdT9kiqLSO",
        "outputId": "4f647216-abcb-4b38-8e7e-5ad069c5f226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of 1's and 0's in 'Preterm Pregnancy' column:\n",
            "Preterm Pregnancy\n",
            "1    4057\n",
            "0     943\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import ADASYN\n",
        "data = pd.read_csv('synthetic_data_rounded.csv')\n",
        "\n",
        "feature_columns = ['Age', 'No of Pregnancy', 'BMI', 'Systolic Blood Pressure', 'Diastolic Blood Pressure',\n",
        "                   'Bloodc Sugar Fasting', 'Blood Sugar Post Prandial', 'Oral Gucose tolerance test',\n",
        "                   'C-Reactive Protein', 'Interleukin 6-IL 6', 'Birth weight']\n",
        "target_column = 'Preterm Pregnancy'  # Replace 'Target' with the name of your target column\n",
        "X = data[feature_columns]\n",
        "y = data[target_column]\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
        "balanced_data = pd.concat([pd.DataFrame(X_resampled, columns=feature_columns),\n",
        "                           pd.DataFrame(y_resampled, columns=[target_column])], axis=1)\n",
        "balanced_data.to_csv('balanced_dataset.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "_bHuREAqqMjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = pd.read_csv('balanced_dataset.csv')\n",
        "preterm_pregnancy_counts = preprocessed_data['Preterm Pregnancy'].value_counts()\n",
        "\n",
        "print(\"Counts of 1's and 0's in 'Preterm Pregnancy' column:\")\n",
        "print(preterm_pregnancy_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Dj64guqRJs",
        "outputId": "5026b765-05a7-4607-a48b-9f6a1f4984bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of 1's and 0's in 'Preterm Pregnancy' column:\n",
            "Preterm Pregnancy\n",
            "1    4057\n",
            "0    3987\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBa1gGf_quQh",
        "outputId": "9d7e44e0-1f34-4998-e474-d6f985dd7f8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftLWbFMCrJ-H",
        "outputId": "984280e9-8078-4bd8-ee23-7665d051a368"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.read_csv('balanced_dataset.csv')\n",
        "\n",
        "X = data.drop(columns=['Preterm Pregnancy'])\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_d\": trial.suggest_int(\"n_d\", 8, 64),\n",
        "        \"n_a\": trial.suggest_int(\"n_a\", 8, 64),\n",
        "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 2.0),\n",
        "        \"momentum\": trial.suggest_float(\"momentum\", 0.01, 0.5),\n",
        "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 0.0001, 0.1),\n",
        "        \"optimizer_params\": {\n",
        "            \"lr\": trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True),\n",
        "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    model = TabNetClassifier(**params)\n",
        "    model.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], patience=10, max_epochs=100,\n",
        "              batch_size=128, virtual_batch_size=32, num_workers=0, drop_last=False)\n",
        "\n",
        "    y_pred_proba = model.predict_proba(X_test.values)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.HyperbandPruner())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "best_auc = study.best_value\n",
        "print(\"Best AUC:\", best_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuLLFdQLqZ0X",
        "outputId": "85d5527c-3afa-482e-bed4-23541a10fd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-05 04:45:05,450] A new study created in memory with name: no-name-0085f994-023a-4414-9c55-e1983f37cb0f\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.7577  | val_0_auc: 0.67977 |  0:00:08s\n",
            "epoch 1  | loss: 0.54169 | val_0_auc: 0.83977 |  0:00:15s\n",
            "epoch 2  | loss: 0.52434 | val_0_auc: 0.83535 |  0:00:22s\n",
            "epoch 3  | loss: 0.49774 | val_0_auc: 0.77548 |  0:00:26s\n",
            "epoch 4  | loss: 0.48592 | val_0_auc: 0.88979 |  0:00:29s\n",
            "epoch 5  | loss: 0.49551 | val_0_auc: 0.89579 |  0:00:33s\n",
            "epoch 6  | loss: 0.47728 | val_0_auc: 0.89871 |  0:00:36s\n",
            "epoch 7  | loss: 0.46809 | val_0_auc: 0.908   |  0:00:40s\n",
            "epoch 8  | loss: 0.46702 | val_0_auc: 0.85618 |  0:00:43s\n",
            "epoch 9  | loss: 0.49165 | val_0_auc: 0.80168 |  0:00:47s\n",
            "epoch 10 | loss: 0.46796 | val_0_auc: 0.88859 |  0:00:50s\n",
            "epoch 11 | loss: 0.48174 | val_0_auc: 0.84781 |  0:00:53s\n",
            "epoch 12 | loss: 0.46541 | val_0_auc: 0.85728 |  0:00:57s\n",
            "epoch 13 | loss: 0.45937 | val_0_auc: 0.8993  |  0:01:01s\n",
            "epoch 14 | loss: 0.45017 | val_0_auc: 0.90948 |  0:01:04s\n",
            "epoch 15 | loss: 0.45668 | val_0_auc: 0.90143 |  0:01:07s\n",
            "epoch 16 | loss: 0.46642 | val_0_auc: 0.88664 |  0:01:11s\n",
            "epoch 17 | loss: 0.44695 | val_0_auc: 0.92035 |  0:01:15s\n",
            "epoch 18 | loss: 0.46012 | val_0_auc: 0.90034 |  0:01:18s\n",
            "epoch 19 | loss: 0.46386 | val_0_auc: 0.91731 |  0:01:22s\n",
            "epoch 20 | loss: 0.45931 | val_0_auc: 0.87024 |  0:01:26s\n",
            "epoch 21 | loss: 0.46475 | val_0_auc: 0.89925 |  0:01:29s\n",
            "epoch 22 | loss: 0.47063 | val_0_auc: 0.81387 |  0:01:33s\n",
            "epoch 23 | loss: 0.46151 | val_0_auc: 0.89713 |  0:01:37s\n",
            "epoch 24 | loss: 0.46406 | val_0_auc: 0.89149 |  0:01:41s\n",
            "epoch 25 | loss: 0.46497 | val_0_auc: 0.87281 |  0:01:46s\n",
            "epoch 26 | loss: 0.46807 | val_0_auc: 0.90478 |  0:01:50s\n",
            "epoch 27 | loss: 0.44544 | val_0_auc: 0.91172 |  0:01:55s\n",
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.92035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 04:47:07,261] Trial 0 finished with value: 0.920351000828357 and parameters: {'n_d': 17, 'n_a': 59, 'n_steps': 6, 'gamma': 0.5367163232180874, 'momentum': 0.05693366071755578, 'lambda_sparse': 0.04371467545266993, 'lr': 0.08584618631417748, 'weight_decay': 0.0008902198258361513}. Best is trial 0 with value: 0.920351000828357.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.68272 | val_0_auc: 0.52481 |  0:00:05s\n",
            "epoch 1  | loss: 0.46163 | val_0_auc: 0.69249 |  0:00:09s\n",
            "epoch 2  | loss: 0.4451  | val_0_auc: 0.82214 |  0:00:15s\n",
            "epoch 3  | loss: 0.39639 | val_0_auc: 0.90698 |  0:00:20s\n",
            "epoch 4  | loss: 0.38478 | val_0_auc: 0.92561 |  0:00:25s\n",
            "epoch 5  | loss: 0.39239 | val_0_auc: 0.93251 |  0:00:29s\n",
            "epoch 6  | loss: 0.36299 | val_0_auc: 0.93635 |  0:00:34s\n",
            "epoch 7  | loss: 0.35263 | val_0_auc: 0.92889 |  0:00:39s\n",
            "epoch 8  | loss: 0.34972 | val_0_auc: 0.94242 |  0:00:43s\n",
            "epoch 9  | loss: 0.33491 | val_0_auc: 0.93004 |  0:00:48s\n",
            "epoch 10 | loss: 0.3436  | val_0_auc: 0.9385  |  0:00:53s\n",
            "epoch 11 | loss: 0.34194 | val_0_auc: 0.95213 |  0:00:58s\n",
            "epoch 12 | loss: 0.32909 | val_0_auc: 0.95126 |  0:01:02s\n",
            "epoch 13 | loss: 0.32333 | val_0_auc: 0.94793 |  0:01:06s\n",
            "epoch 14 | loss: 0.32717 | val_0_auc: 0.94628 |  0:01:11s\n",
            "epoch 15 | loss: 0.33118 | val_0_auc: 0.94802 |  0:01:15s\n",
            "epoch 16 | loss: 0.32967 | val_0_auc: 0.95182 |  0:01:20s\n",
            "epoch 17 | loss: 0.31548 | val_0_auc: 0.94571 |  0:01:24s\n",
            "epoch 18 | loss: 0.32193 | val_0_auc: 0.95552 |  0:01:29s\n",
            "epoch 19 | loss: 0.32406 | val_0_auc: 0.95181 |  0:01:34s\n",
            "epoch 20 | loss: 0.32101 | val_0_auc: 0.94568 |  0:01:38s\n",
            "epoch 21 | loss: 0.31991 | val_0_auc: 0.94685 |  0:01:43s\n",
            "epoch 22 | loss: 0.30748 | val_0_auc: 0.95199 |  0:01:48s\n",
            "epoch 23 | loss: 0.31921 | val_0_auc: 0.95025 |  0:01:55s\n",
            "epoch 24 | loss: 0.30977 | val_0_auc: 0.94337 |  0:02:00s\n",
            "epoch 25 | loss: 0.31346 | val_0_auc: 0.95402 |  0:02:07s\n",
            "epoch 26 | loss: 0.31225 | val_0_auc: 0.95133 |  0:02:13s\n",
            "epoch 27 | loss: 0.31507 | val_0_auc: 0.95041 |  0:02:20s\n",
            "epoch 28 | loss: 0.30768 | val_0_auc: 0.95536 |  0:02:25s\n",
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.95552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 04:49:34,472] Trial 1 finished with value: 0.9555159922356984 and parameters: {'n_d': 46, 'n_a': 55, 'n_steps': 7, 'gamma': 0.37811161026892715, 'momentum': 0.4792089037356367, 'lambda_sparse': 0.01117727577406137, 'lr': 0.003241166799524568, 'weight_decay': 0.00045689069086874296}. Best is trial 1 with value: 0.9555159922356984.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.77579 | val_0_auc: 0.51721 |  0:00:03s\n",
            "epoch 1  | loss: 0.46851 | val_0_auc: 0.71302 |  0:00:07s\n",
            "epoch 2  | loss: 0.42767 | val_0_auc: 0.87682 |  0:00:11s\n",
            "epoch 3  | loss: 0.40646 | val_0_auc: 0.89602 |  0:00:15s\n",
            "epoch 4  | loss: 0.40544 | val_0_auc: 0.92115 |  0:00:19s\n",
            "epoch 5  | loss: 0.38833 | val_0_auc: 0.93316 |  0:00:23s\n",
            "epoch 6  | loss: 0.38496 | val_0_auc: 0.93485 |  0:00:26s\n",
            "epoch 7  | loss: 0.38647 | val_0_auc: 0.93446 |  0:00:31s\n",
            "epoch 8  | loss: 0.38505 | val_0_auc: 0.93279 |  0:00:35s\n",
            "epoch 9  | loss: 0.37689 | val_0_auc: 0.93026 |  0:00:39s\n",
            "epoch 10 | loss: 0.3709  | val_0_auc: 0.92267 |  0:00:44s\n",
            "epoch 11 | loss: 0.3685  | val_0_auc: 0.93704 |  0:00:47s\n",
            "epoch 12 | loss: 0.3701  | val_0_auc: 0.93984 |  0:00:51s\n",
            "epoch 13 | loss: 0.37643 | val_0_auc: 0.935   |  0:00:55s\n",
            "epoch 14 | loss: 0.37254 | val_0_auc: 0.933   |  0:00:59s\n",
            "epoch 15 | loss: 0.36426 | val_0_auc: 0.92933 |  0:01:02s\n",
            "epoch 16 | loss: 0.36107 | val_0_auc: 0.93448 |  0:01:06s\n",
            "epoch 17 | loss: 0.3566  | val_0_auc: 0.93985 |  0:01:10s\n",
            "epoch 18 | loss: 0.35614 | val_0_auc: 0.93694 |  0:01:14s\n",
            "epoch 19 | loss: 0.35252 | val_0_auc: 0.93666 |  0:01:19s\n",
            "epoch 20 | loss: 0.35159 | val_0_auc: 0.93535 |  0:01:23s\n",
            "epoch 21 | loss: 0.35725 | val_0_auc: 0.94176 |  0:01:27s\n",
            "epoch 22 | loss: 0.35706 | val_0_auc: 0.93505 |  0:01:30s\n",
            "epoch 23 | loss: 0.35076 | val_0_auc: 0.94507 |  0:01:35s\n",
            "epoch 24 | loss: 0.35189 | val_0_auc: 0.93613 |  0:01:38s\n",
            "epoch 25 | loss: 0.36445 | val_0_auc: 0.94377 |  0:01:42s\n",
            "epoch 26 | loss: 0.35646 | val_0_auc: 0.93805 |  0:01:47s\n",
            "epoch 27 | loss: 0.35451 | val_0_auc: 0.9356  |  0:01:51s\n",
            "epoch 28 | loss: 0.35046 | val_0_auc: 0.94864 |  0:01:55s\n",
            "epoch 29 | loss: 0.36027 | val_0_auc: 0.94147 |  0:02:00s\n",
            "epoch 30 | loss: 0.35943 | val_0_auc: 0.94386 |  0:02:04s\n",
            "epoch 31 | loss: 0.34902 | val_0_auc: 0.94502 |  0:02:10s\n",
            "epoch 32 | loss: 0.34248 | val_0_auc: 0.9481  |  0:02:15s\n",
            "epoch 33 | loss: 0.341   | val_0_auc: 0.94197 |  0:02:21s\n",
            "epoch 34 | loss: 0.34721 | val_0_auc: 0.94412 |  0:02:28s\n",
            "epoch 35 | loss: 0.3346  | val_0_auc: 0.94148 |  0:02:35s\n",
            "epoch 36 | loss: 0.34368 | val_0_auc: 0.92925 |  0:02:41s\n",
            "epoch 37 | loss: 0.35163 | val_0_auc: 0.92857 |  0:02:49s\n",
            "epoch 38 | loss: 0.34322 | val_0_auc: 0.92539 |  0:02:57s\n",
            "\n",
            "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.94864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 04:52:33,708] Trial 2 finished with value: 0.9486434108527132 and parameters: {'n_d': 19, 'n_a': 49, 'n_steps': 7, 'gamma': 0.5865103220838861, 'momentum': 0.3516857262512758, 'lambda_sparse': 0.011188998376822428, 'lr': 0.01126369603307391, 'weight_decay': 0.0008326413214649438}. Best is trial 1 with value: 0.9555159922356984.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.81694 | val_0_auc: 0.51246 |  0:00:02s\n",
            "epoch 1  | loss: 0.62596 | val_0_auc: 0.65835 |  0:00:04s\n",
            "epoch 2  | loss: 0.60841 | val_0_auc: 0.70743 |  0:00:07s\n",
            "epoch 3  | loss: 0.58736 | val_0_auc: 0.76528 |  0:00:10s\n",
            "epoch 4  | loss: 0.56708 | val_0_auc: 0.786   |  0:00:14s\n",
            "epoch 5  | loss: 0.56281 | val_0_auc: 0.82754 |  0:00:16s\n",
            "epoch 6  | loss: 0.53221 | val_0_auc: 0.81989 |  0:00:18s\n",
            "epoch 7  | loss: 0.53294 | val_0_auc: 0.8445  |  0:00:21s\n",
            "epoch 8  | loss: 0.48766 | val_0_auc: 0.84777 |  0:00:23s\n",
            "epoch 9  | loss: 0.46658 | val_0_auc: 0.88421 |  0:00:25s\n",
            "epoch 10 | loss: 0.4466  | val_0_auc: 0.90782 |  0:00:28s\n",
            "epoch 11 | loss: 0.4149  | val_0_auc: 0.89982 |  0:00:30s\n",
            "epoch 12 | loss: 0.41715 | val_0_auc: 0.89914 |  0:00:32s\n",
            "epoch 13 | loss: 0.42793 | val_0_auc: 0.90266 |  0:00:38s\n",
            "epoch 14 | loss: 0.40764 | val_0_auc: 0.92096 |  0:00:44s\n",
            "epoch 15 | loss: 0.38109 | val_0_auc: 0.93005 |  0:00:46s\n",
            "epoch 16 | loss: 0.38469 | val_0_auc: 0.91864 |  0:00:48s\n",
            "epoch 17 | loss: 0.37048 | val_0_auc: 0.9368  |  0:00:51s\n",
            "epoch 18 | loss: 0.38175 | val_0_auc: 0.92764 |  0:00:54s\n",
            "epoch 19 | loss: 0.36666 | val_0_auc: 0.93411 |  0:00:57s\n",
            "epoch 20 | loss: 0.37832 | val_0_auc: 0.93364 |  0:01:00s\n",
            "epoch 21 | loss: 0.35706 | val_0_auc: 0.94212 |  0:01:02s\n",
            "epoch 22 | loss: 0.35978 | val_0_auc: 0.91733 |  0:01:04s\n",
            "epoch 23 | loss: 0.35871 | val_0_auc: 0.93398 |  0:01:07s\n",
            "epoch 24 | loss: 0.34685 | val_0_auc: 0.9321  |  0:01:10s\n",
            "epoch 25 | loss: 0.34451 | val_0_auc: 0.93056 |  0:01:12s\n",
            "epoch 26 | loss: 0.3555  | val_0_auc: 0.9265  |  0:01:14s\n",
            "epoch 27 | loss: 0.37551 | val_0_auc: 0.92166 |  0:01:17s\n",
            "epoch 28 | loss: 0.35781 | val_0_auc: 0.94473 |  0:01:20s\n",
            "epoch 29 | loss: 0.3495  | val_0_auc: 0.93533 |  0:01:22s\n",
            "epoch 30 | loss: 0.33913 | val_0_auc: 0.93767 |  0:01:25s\n",
            "epoch 31 | loss: 0.33701 | val_0_auc: 0.94215 |  0:01:29s\n",
            "epoch 32 | loss: 0.33514 | val_0_auc: 0.94526 |  0:01:33s\n",
            "epoch 33 | loss: 0.33441 | val_0_auc: 0.94825 |  0:01:37s\n",
            "epoch 34 | loss: 0.33267 | val_0_auc: 0.9399  |  0:01:41s\n",
            "epoch 35 | loss: 0.34512 | val_0_auc: 0.94454 |  0:01:45s\n",
            "epoch 36 | loss: 0.33186 | val_0_auc: 0.94771 |  0:01:50s\n",
            "epoch 37 | loss: 0.32877 | val_0_auc: 0.93597 |  0:01:53s\n",
            "epoch 38 | loss: 0.32655 | val_0_auc: 0.94816 |  0:01:58s\n",
            "epoch 39 | loss: 0.3222  | val_0_auc: 0.95137 |  0:02:01s\n",
            "epoch 40 | loss: 0.32354 | val_0_auc: 0.94171 |  0:02:06s\n",
            "epoch 41 | loss: 0.32508 | val_0_auc: 0.94161 |  0:02:10s\n",
            "epoch 42 | loss: 0.33321 | val_0_auc: 0.90446 |  0:02:15s\n",
            "epoch 43 | loss: 0.34267 | val_0_auc: 0.93719 |  0:02:19s\n",
            "epoch 44 | loss: 0.32737 | val_0_auc: 0.95381 |  0:02:23s\n",
            "epoch 45 | loss: 0.31034 | val_0_auc: 0.95079 |  0:02:27s\n",
            "epoch 46 | loss: 0.31753 | val_0_auc: 0.93908 |  0:02:30s\n",
            "epoch 47 | loss: 0.31628 | val_0_auc: 0.94928 |  0:02:34s\n",
            "epoch 48 | loss: 0.31436 | val_0_auc: 0.95166 |  0:02:38s\n",
            "epoch 49 | loss: 0.3025  | val_0_auc: 0.94207 |  0:02:42s\n",
            "epoch 50 | loss: 0.31718 | val_0_auc: 0.95466 |  0:02:46s\n",
            "epoch 51 | loss: 0.30946 | val_0_auc: 0.95978 |  0:02:50s\n",
            "epoch 52 | loss: 0.30242 | val_0_auc: 0.95054 |  0:02:55s\n",
            "epoch 53 | loss: 0.30492 | val_0_auc: 0.94888 |  0:02:59s\n",
            "epoch 54 | loss: 0.29869 | val_0_auc: 0.95661 |  0:03:04s\n",
            "epoch 55 | loss: 0.29324 | val_0_auc: 0.9627  |  0:03:08s\n",
            "epoch 56 | loss: 0.3014  | val_0_auc: 0.95241 |  0:03:11s\n",
            "epoch 57 | loss: 0.29649 | val_0_auc: 0.94918 |  0:03:16s\n",
            "epoch 58 | loss: 0.28815 | val_0_auc: 0.93208 |  0:03:20s\n",
            "epoch 59 | loss: 0.32143 | val_0_auc: 0.94386 |  0:03:24s\n",
            "epoch 60 | loss: 0.29293 | val_0_auc: 0.95768 |  0:03:28s\n",
            "epoch 61 | loss: 0.30596 | val_0_auc: 0.95624 |  0:03:32s\n",
            "epoch 62 | loss: 0.29213 | val_0_auc: 0.95101 |  0:03:36s\n",
            "epoch 63 | loss: 0.29353 | val_0_auc: 0.95614 |  0:03:40s\n",
            "epoch 64 | loss: 0.28231 | val_0_auc: 0.95801 |  0:03:44s\n",
            "epoch 65 | loss: 0.28058 | val_0_auc: 0.95262 |  0:03:48s\n",
            "\n",
            "Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_auc = 0.9627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 04:56:24,998] Trial 3 finished with value: 0.9627007529394311 and parameters: {'n_d': 64, 'n_a': 47, 'n_steps': 3, 'gamma': 0.9745489339831573, 'momentum': 0.48773071153483066, 'lambda_sparse': 0.059996002307291275, 'lr': 0.05527460060984675, 'weight_decay': 1.575484066176723e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.05948 | val_0_auc: 0.44571 |  0:00:03s\n",
            "epoch 1  | loss: 0.75783 | val_0_auc: 0.59086 |  0:00:07s\n",
            "epoch 2  | loss: 0.69219 | val_0_auc: 0.61741 |  0:00:11s\n",
            "epoch 3  | loss: 0.6431  | val_0_auc: 0.69669 |  0:00:15s\n",
            "epoch 4  | loss: 0.63425 | val_0_auc: 0.71556 |  0:00:20s\n",
            "epoch 5  | loss: 0.6246  | val_0_auc: 0.74105 |  0:00:25s\n",
            "epoch 6  | loss: 0.61166 | val_0_auc: 0.76799 |  0:00:29s\n",
            "epoch 7  | loss: 0.60175 | val_0_auc: 0.77898 |  0:00:33s\n",
            "epoch 8  | loss: 0.59476 | val_0_auc: 0.78117 |  0:00:37s\n",
            "epoch 9  | loss: 0.59631 | val_0_auc: 0.78483 |  0:00:41s\n",
            "epoch 10 | loss: 0.58886 | val_0_auc: 0.79792 |  0:00:45s\n",
            "epoch 11 | loss: 0.56386 | val_0_auc: 0.79851 |  0:00:49s\n",
            "epoch 12 | loss: 0.5554  | val_0_auc: 0.79565 |  0:00:53s\n",
            "epoch 13 | loss: 0.5637  | val_0_auc: 0.799   |  0:00:57s\n",
            "epoch 14 | loss: 0.54188 | val_0_auc: 0.81499 |  0:01:02s\n",
            "epoch 15 | loss: 0.54442 | val_0_auc: 0.82243 |  0:01:06s\n",
            "epoch 16 | loss: 0.5386  | val_0_auc: 0.81738 |  0:01:10s\n",
            "epoch 17 | loss: 0.5346  | val_0_auc: 0.81599 |  0:01:14s\n",
            "epoch 18 | loss: 0.55142 | val_0_auc: 0.81574 |  0:01:18s\n",
            "epoch 19 | loss: 0.54761 | val_0_auc: 0.82025 |  0:01:22s\n",
            "epoch 20 | loss: 0.54053 | val_0_auc: 0.8229  |  0:01:27s\n",
            "epoch 21 | loss: 0.51523 | val_0_auc: 0.85193 |  0:01:31s\n",
            "epoch 22 | loss: 0.50448 | val_0_auc: 0.84938 |  0:01:35s\n",
            "epoch 23 | loss: 0.50889 | val_0_auc: 0.83945 |  0:01:40s\n",
            "epoch 24 | loss: 0.5194  | val_0_auc: 0.83952 |  0:01:43s\n",
            "epoch 25 | loss: 0.51651 | val_0_auc: 0.85291 |  0:01:47s\n",
            "epoch 26 | loss: 0.48939 | val_0_auc: 0.83724 |  0:01:52s\n",
            "epoch 27 | loss: 0.49662 | val_0_auc: 0.84349 |  0:01:56s\n",
            "epoch 28 | loss: 0.488   | val_0_auc: 0.86128 |  0:01:59s\n",
            "epoch 29 | loss: 0.47645 | val_0_auc: 0.85684 |  0:02:04s\n",
            "epoch 30 | loss: 0.49087 | val_0_auc: 0.85755 |  0:02:08s\n",
            "epoch 31 | loss: 0.47233 | val_0_auc: 0.8825  |  0:02:12s\n",
            "epoch 32 | loss: 0.45522 | val_0_auc: 0.88818 |  0:02:17s\n",
            "epoch 33 | loss: 0.4395  | val_0_auc: 0.88828 |  0:02:22s\n",
            "epoch 34 | loss: 0.43229 | val_0_auc: 0.87789 |  0:02:26s\n",
            "epoch 35 | loss: 0.42548 | val_0_auc: 0.8985  |  0:02:30s\n",
            "epoch 36 | loss: 0.42588 | val_0_auc: 0.87826 |  0:02:35s\n",
            "epoch 37 | loss: 0.41591 | val_0_auc: 0.89556 |  0:02:38s\n",
            "epoch 38 | loss: 0.41575 | val_0_auc: 0.90169 |  0:02:43s\n",
            "epoch 39 | loss: 0.42505 | val_0_auc: 0.91193 |  0:02:47s\n",
            "epoch 40 | loss: 0.40759 | val_0_auc: 0.90922 |  0:02:51s\n",
            "epoch 41 | loss: 0.40984 | val_0_auc: 0.91066 |  0:02:55s\n",
            "epoch 42 | loss: 0.40222 | val_0_auc: 0.91859 |  0:02:59s\n",
            "epoch 43 | loss: 0.39914 | val_0_auc: 0.90866 |  0:03:03s\n",
            "epoch 44 | loss: 0.38471 | val_0_auc: 0.91648 |  0:03:08s\n",
            "epoch 45 | loss: 0.40164 | val_0_auc: 0.91331 |  0:03:12s\n",
            "epoch 46 | loss: 0.38288 | val_0_auc: 0.92008 |  0:03:17s\n",
            "epoch 47 | loss: 0.39411 | val_0_auc: 0.92124 |  0:03:22s\n",
            "epoch 48 | loss: 0.38335 | val_0_auc: 0.92783 |  0:03:26s\n",
            "epoch 49 | loss: 0.37268 | val_0_auc: 0.93263 |  0:03:30s\n",
            "epoch 50 | loss: 0.36326 | val_0_auc: 0.92702 |  0:03:35s\n",
            "epoch 51 | loss: 0.36198 | val_0_auc: 0.92475 |  0:03:40s\n",
            "epoch 52 | loss: 0.36907 | val_0_auc: 0.93386 |  0:03:45s\n",
            "epoch 53 | loss: 0.36655 | val_0_auc: 0.92413 |  0:03:50s\n",
            "epoch 54 | loss: 0.37375 | val_0_auc: 0.91335 |  0:03:54s\n",
            "epoch 55 | loss: 0.36808 | val_0_auc: 0.93476 |  0:03:59s\n",
            "epoch 56 | loss: 0.37107 | val_0_auc: 0.91746 |  0:04:03s\n",
            "epoch 57 | loss: 0.36929 | val_0_auc: 0.93469 |  0:04:07s\n",
            "epoch 58 | loss: 0.36988 | val_0_auc: 0.93559 |  0:04:13s\n",
            "epoch 59 | loss: 0.34834 | val_0_auc: 0.93871 |  0:04:17s\n",
            "epoch 60 | loss: 0.34709 | val_0_auc: 0.93152 |  0:04:22s\n",
            "epoch 61 | loss: 0.34734 | val_0_auc: 0.94379 |  0:04:27s\n",
            "epoch 62 | loss: 0.34435 | val_0_auc: 0.93663 |  0:04:31s\n",
            "epoch 63 | loss: 0.3518  | val_0_auc: 0.94137 |  0:04:35s\n",
            "epoch 64 | loss: 0.34455 | val_0_auc: 0.93934 |  0:04:39s\n",
            "epoch 65 | loss: 0.34685 | val_0_auc: 0.9221  |  0:04:43s\n",
            "epoch 66 | loss: 0.33778 | val_0_auc: 0.93987 |  0:04:48s\n",
            "epoch 67 | loss: 0.33131 | val_0_auc: 0.94185 |  0:04:52s\n",
            "epoch 68 | loss: 0.3474  | val_0_auc: 0.92792 |  0:04:56s\n",
            "epoch 69 | loss: 0.35399 | val_0_auc: 0.93971 |  0:05:01s\n",
            "epoch 70 | loss: 0.34537 | val_0_auc: 0.9455  |  0:05:06s\n",
            "epoch 71 | loss: 0.35121 | val_0_auc: 0.93998 |  0:05:10s\n",
            "epoch 72 | loss: 0.35146 | val_0_auc: 0.93751 |  0:05:15s\n",
            "epoch 73 | loss: 0.33472 | val_0_auc: 0.94086 |  0:05:19s\n",
            "epoch 74 | loss: 0.35054 | val_0_auc: 0.9386  |  0:05:23s\n",
            "epoch 75 | loss: 0.3441  | val_0_auc: 0.93373 |  0:05:28s\n",
            "epoch 76 | loss: 0.33417 | val_0_auc: 0.94211 |  0:05:32s\n",
            "epoch 77 | loss: 0.32328 | val_0_auc: 0.92687 |  0:05:38s\n",
            "epoch 78 | loss: 0.34281 | val_0_auc: 0.93765 |  0:05:43s\n",
            "epoch 79 | loss: 0.33175 | val_0_auc: 0.94636 |  0:05:47s\n",
            "epoch 80 | loss: 0.32631 | val_0_auc: 0.93775 |  0:05:53s\n",
            "epoch 81 | loss: 0.33429 | val_0_auc: 0.93931 |  0:05:57s\n",
            "epoch 82 | loss: 0.31394 | val_0_auc: 0.94404 |  0:06:03s\n",
            "epoch 83 | loss: 0.32253 | val_0_auc: 0.93766 |  0:06:08s\n",
            "epoch 84 | loss: 0.32556 | val_0_auc: 0.93803 |  0:06:13s\n",
            "epoch 85 | loss: 0.34502 | val_0_auc: 0.9462  |  0:06:19s\n",
            "epoch 86 | loss: 0.33457 | val_0_auc: 0.93764 |  0:06:23s\n",
            "epoch 87 | loss: 0.32661 | val_0_auc: 0.94288 |  0:06:29s\n",
            "epoch 88 | loss: 0.32442 | val_0_auc: 0.94843 |  0:06:33s\n",
            "epoch 89 | loss: 0.32707 | val_0_auc: 0.94473 |  0:06:38s\n",
            "epoch 90 | loss: 0.32061 | val_0_auc: 0.94535 |  0:06:43s\n",
            "epoch 91 | loss: 0.31366 | val_0_auc: 0.94592 |  0:06:48s\n",
            "epoch 92 | loss: 0.31696 | val_0_auc: 0.94415 |  0:06:53s\n",
            "epoch 93 | loss: 0.32195 | val_0_auc: 0.9384  |  0:07:02s\n",
            "epoch 94 | loss: 0.33131 | val_0_auc: 0.94662 |  0:07:08s\n",
            "epoch 95 | loss: 0.3225  | val_0_auc: 0.95024 |  0:07:12s\n",
            "epoch 96 | loss: 0.32283 | val_0_auc: 0.93749 |  0:07:16s\n",
            "epoch 97 | loss: 0.3184  | val_0_auc: 0.94028 |  0:07:22s\n",
            "epoch 98 | loss: 0.32076 | val_0_auc: 0.94724 |  0:07:27s\n",
            "epoch 99 | loss: 0.30887 | val_0_auc: 0.94713 |  0:07:32s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_auc = 0.95024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:04:00,005] Trial 4 finished with value: 0.9502352163000879 and parameters: {'n_d': 9, 'n_a': 19, 'n_steps': 9, 'gamma': 1.7661493987258048, 'momentum': 0.015857209761141466, 'lambda_sparse': 0.011092664901716764, 'lr': 0.005985068451656573, 'weight_decay': 0.0005484719541373167}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 3.24978 | val_0_auc: 0.41139 |  0:00:04s\n",
            "epoch 1  | loss: 2.80263 | val_0_auc: 0.45895 |  0:00:10s\n",
            "epoch 2  | loss: 2.30382 | val_0_auc: 0.52582 |  0:00:15s\n",
            "epoch 3  | loss: 1.8864  | val_0_auc: 0.56906 |  0:00:22s\n",
            "epoch 4  | loss: 1.49586 | val_0_auc: 0.60865 |  0:00:27s\n",
            "epoch 5  | loss: 1.23531 | val_0_auc: 0.63917 |  0:00:33s\n",
            "epoch 6  | loss: 1.07107 | val_0_auc: 0.6561  |  0:00:39s\n",
            "epoch 7  | loss: 0.97751 | val_0_auc: 0.67728 |  0:00:45s\n",
            "epoch 8  | loss: 0.91446 | val_0_auc: 0.70443 |  0:00:50s\n",
            "epoch 9  | loss: 0.86897 | val_0_auc: 0.71823 |  0:00:55s\n",
            "epoch 10 | loss: 0.81867 | val_0_auc: 0.73795 |  0:01:01s\n",
            "epoch 11 | loss: 0.80618 | val_0_auc: 0.74612 |  0:01:06s\n",
            "epoch 12 | loss: 0.79078 | val_0_auc: 0.76245 |  0:01:12s\n",
            "epoch 13 | loss: 0.78581 | val_0_auc: 0.77184 |  0:01:17s\n",
            "epoch 14 | loss: 0.77334 | val_0_auc: 0.77976 |  0:01:23s\n",
            "epoch 15 | loss: 0.75587 | val_0_auc: 0.79514 |  0:01:28s\n",
            "epoch 16 | loss: 0.73268 | val_0_auc: 0.79244 |  0:01:33s\n",
            "epoch 17 | loss: 0.71296 | val_0_auc: 0.802   |  0:01:39s\n",
            "epoch 18 | loss: 0.7178  | val_0_auc: 0.8151  |  0:01:44s\n",
            "epoch 19 | loss: 0.69941 | val_0_auc: 0.80996 |  0:01:50s\n",
            "epoch 20 | loss: 0.70784 | val_0_auc: 0.82446 |  0:01:55s\n",
            "epoch 21 | loss: 0.69339 | val_0_auc: 0.82515 |  0:02:00s\n",
            "epoch 22 | loss: 0.68478 | val_0_auc: 0.83656 |  0:02:06s\n",
            "epoch 23 | loss: 0.66427 | val_0_auc: 0.83425 |  0:02:11s\n",
            "epoch 24 | loss: 0.6542  | val_0_auc: 0.8405  |  0:02:17s\n",
            "epoch 25 | loss: 0.65421 | val_0_auc: 0.84093 |  0:02:22s\n",
            "epoch 26 | loss: 0.65225 | val_0_auc: 0.84715 |  0:02:28s\n",
            "epoch 27 | loss: 0.645   | val_0_auc: 0.84731 |  0:02:33s\n",
            "epoch 28 | loss: 0.63277 | val_0_auc: 0.84503 |  0:02:40s\n",
            "epoch 29 | loss: 0.62087 | val_0_auc: 0.84687 |  0:02:45s\n",
            "epoch 30 | loss: 0.61527 | val_0_auc: 0.84879 |  0:02:50s\n",
            "epoch 31 | loss: 0.61947 | val_0_auc: 0.85408 |  0:02:56s\n",
            "epoch 32 | loss: 0.61478 | val_0_auc: 0.85482 |  0:03:01s\n",
            "epoch 33 | loss: 0.61857 | val_0_auc: 0.86551 |  0:03:07s\n",
            "epoch 34 | loss: 0.5902  | val_0_auc: 0.86886 |  0:03:13s\n",
            "epoch 35 | loss: 0.6085  | val_0_auc: 0.86804 |  0:03:19s\n",
            "epoch 36 | loss: 0.58843 | val_0_auc: 0.87103 |  0:03:24s\n",
            "epoch 37 | loss: 0.58706 | val_0_auc: 0.86526 |  0:03:30s\n",
            "epoch 38 | loss: 0.59098 | val_0_auc: 0.87642 |  0:03:36s\n",
            "epoch 39 | loss: 0.58504 | val_0_auc: 0.87993 |  0:03:42s\n",
            "epoch 40 | loss: 0.57765 | val_0_auc: 0.87256 |  0:03:48s\n",
            "epoch 41 | loss: 0.5789  | val_0_auc: 0.88093 |  0:03:53s\n",
            "epoch 42 | loss: 0.58168 | val_0_auc: 0.88631 |  0:03:59s\n",
            "epoch 43 | loss: 0.5664  | val_0_auc: 0.88984 |  0:04:04s\n",
            "epoch 44 | loss: 0.56069 | val_0_auc: 0.88349 |  0:04:10s\n",
            "epoch 45 | loss: 0.56151 | val_0_auc: 0.89011 |  0:04:14s\n",
            "epoch 46 | loss: 0.56073 | val_0_auc: 0.88797 |  0:04:20s\n",
            "epoch 47 | loss: 0.55157 | val_0_auc: 0.89048 |  0:04:25s\n",
            "epoch 48 | loss: 0.54989 | val_0_auc: 0.89813 |  0:04:30s\n",
            "epoch 49 | loss: 0.54935 | val_0_auc: 0.89595 |  0:04:36s\n",
            "epoch 50 | loss: 0.55365 | val_0_auc: 0.89038 |  0:04:42s\n",
            "epoch 51 | loss: 0.54264 | val_0_auc: 0.89158 |  0:04:48s\n",
            "epoch 52 | loss: 0.54141 | val_0_auc: 0.89541 |  0:04:53s\n",
            "epoch 53 | loss: 0.53576 | val_0_auc: 0.89051 |  0:04:58s\n",
            "epoch 54 | loss: 0.53043 | val_0_auc: 0.89596 |  0:05:04s\n",
            "epoch 55 | loss: 0.52402 | val_0_auc: 0.89333 |  0:05:09s\n",
            "epoch 56 | loss: 0.52674 | val_0_auc: 0.89324 |  0:05:14s\n",
            "epoch 57 | loss: 0.53278 | val_0_auc: 0.89412 |  0:05:20s\n",
            "epoch 58 | loss: 0.52835 | val_0_auc: 0.90175 |  0:05:26s\n",
            "epoch 59 | loss: 0.52284 | val_0_auc: 0.89718 |  0:05:30s\n",
            "epoch 60 | loss: 0.52392 | val_0_auc: 0.90059 |  0:05:36s\n",
            "epoch 61 | loss: 0.51788 | val_0_auc: 0.90171 |  0:05:41s\n",
            "epoch 62 | loss: 0.52387 | val_0_auc: 0.90393 |  0:05:47s\n",
            "epoch 63 | loss: 0.52518 | val_0_auc: 0.8959  |  0:05:52s\n",
            "epoch 64 | loss: 0.51041 | val_0_auc: 0.90186 |  0:05:57s\n",
            "epoch 65 | loss: 0.51823 | val_0_auc: 0.89931 |  0:06:03s\n",
            "epoch 66 | loss: 0.52171 | val_0_auc: 0.89807 |  0:06:08s\n",
            "epoch 67 | loss: 0.50622 | val_0_auc: 0.90192 |  0:06:14s\n",
            "epoch 68 | loss: 0.49979 | val_0_auc: 0.90054 |  0:06:19s\n",
            "epoch 69 | loss: 0.51106 | val_0_auc: 0.90636 |  0:06:25s\n",
            "epoch 70 | loss: 0.50643 | val_0_auc: 0.90983 |  0:06:30s\n",
            "epoch 71 | loss: 0.50286 | val_0_auc: 0.90855 |  0:06:35s\n",
            "epoch 72 | loss: 0.50416 | val_0_auc: 0.91402 |  0:06:41s\n",
            "epoch 73 | loss: 0.50857 | val_0_auc: 0.91117 |  0:06:46s\n",
            "epoch 74 | loss: 0.49773 | val_0_auc: 0.90793 |  0:06:51s\n",
            "epoch 75 | loss: 0.49487 | val_0_auc: 0.91057 |  0:06:56s\n",
            "epoch 76 | loss: 0.48791 | val_0_auc: 0.91181 |  0:07:02s\n",
            "epoch 77 | loss: 0.49935 | val_0_auc: 0.9108  |  0:07:07s\n",
            "epoch 78 | loss: 0.49996 | val_0_auc: 0.91662 |  0:07:13s\n",
            "epoch 79 | loss: 0.48474 | val_0_auc: 0.91328 |  0:07:18s\n",
            "epoch 80 | loss: 0.49366 | val_0_auc: 0.91754 |  0:07:23s\n",
            "epoch 81 | loss: 0.49035 | val_0_auc: 0.91054 |  0:07:30s\n",
            "epoch 82 | loss: 0.48452 | val_0_auc: 0.91614 |  0:07:35s\n",
            "epoch 83 | loss: 0.48461 | val_0_auc: 0.91079 |  0:07:41s\n",
            "epoch 84 | loss: 0.48267 | val_0_auc: 0.91578 |  0:07:46s\n",
            "epoch 85 | loss: 0.48393 | val_0_auc: 0.92003 |  0:07:52s\n",
            "epoch 86 | loss: 0.48409 | val_0_auc: 0.91836 |  0:07:57s\n",
            "epoch 87 | loss: 0.49026 | val_0_auc: 0.92093 |  0:08:02s\n",
            "epoch 88 | loss: 0.48742 | val_0_auc: 0.92117 |  0:08:08s\n",
            "epoch 89 | loss: 0.47388 | val_0_auc: 0.91391 |  0:08:13s\n",
            "epoch 90 | loss: 0.46998 | val_0_auc: 0.92088 |  0:08:19s\n",
            "epoch 91 | loss: 0.46731 | val_0_auc: 0.91529 |  0:08:24s\n",
            "epoch 92 | loss: 0.46722 | val_0_auc: 0.91704 |  0:08:30s\n",
            "epoch 93 | loss: 0.4755  | val_0_auc: 0.92303 |  0:08:36s\n",
            "epoch 94 | loss: 0.46789 | val_0_auc: 0.92717 |  0:08:43s\n",
            "epoch 95 | loss: 0.47143 | val_0_auc: 0.921   |  0:08:48s\n",
            "epoch 96 | loss: 0.47601 | val_0_auc: 0.91913 |  0:08:53s\n",
            "epoch 97 | loss: 0.4804  | val_0_auc: 0.92576 |  0:08:58s\n",
            "epoch 98 | loss: 0.47407 | val_0_auc: 0.92465 |  0:09:03s\n",
            "epoch 99 | loss: 0.47528 | val_0_auc: 0.92744 |  0:09:09s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_auc = 0.92744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:13:11,374] Trial 5 finished with value: 0.927436853232447 and parameters: {'n_d': 16, 'n_a': 55, 'n_steps': 10, 'gamma': 0.6150212192252065, 'momentum': 0.020010526379273474, 'lambda_sparse': 0.05494999004531719, 'lr': 0.00010580397815268968, 'weight_decay': 2.614650057694774e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.35358 | val_0_auc: 0.52413 |  0:00:03s\n",
            "epoch 1  | loss: 1.09474 | val_0_auc: 0.55512 |  0:00:06s\n",
            "epoch 2  | loss: 0.91883 | val_0_auc: 0.52337 |  0:00:09s\n",
            "epoch 3  | loss: 0.86458 | val_0_auc: 0.60387 |  0:00:12s\n",
            "epoch 4  | loss: 0.79667 | val_0_auc: 0.60159 |  0:00:15s\n",
            "epoch 5  | loss: 0.77059 | val_0_auc: 0.65645 |  0:00:20s\n",
            "epoch 6  | loss: 0.76045 | val_0_auc: 0.65576 |  0:00:26s\n",
            "epoch 7  | loss: 0.73988 | val_0_auc: 0.6974  |  0:00:29s\n",
            "epoch 8  | loss: 0.71954 | val_0_auc: 0.72223 |  0:00:33s\n",
            "epoch 9  | loss: 0.69355 | val_0_auc: 0.72374 |  0:00:36s\n",
            "epoch 10 | loss: 0.68478 | val_0_auc: 0.73396 |  0:00:39s\n",
            "epoch 11 | loss: 0.68019 | val_0_auc: 0.74726 |  0:00:42s\n",
            "epoch 12 | loss: 0.65373 | val_0_auc: 0.73702 |  0:00:45s\n",
            "epoch 13 | loss: 0.64362 | val_0_auc: 0.76417 |  0:00:48s\n",
            "epoch 14 | loss: 0.6434  | val_0_auc: 0.76662 |  0:00:51s\n",
            "epoch 15 | loss: 0.62613 | val_0_auc: 0.76784 |  0:00:55s\n",
            "epoch 16 | loss: 0.6318  | val_0_auc: 0.78794 |  0:00:58s\n",
            "epoch 17 | loss: 0.61717 | val_0_auc: 0.78524 |  0:01:01s\n",
            "epoch 18 | loss: 0.61547 | val_0_auc: 0.79285 |  0:01:04s\n",
            "epoch 19 | loss: 0.60345 | val_0_auc: 0.78844 |  0:01:06s\n",
            "epoch 20 | loss: 0.6155  | val_0_auc: 0.80406 |  0:01:09s\n",
            "epoch 21 | loss: 0.61607 | val_0_auc: 0.82356 |  0:01:13s\n",
            "epoch 22 | loss: 0.59494 | val_0_auc: 0.80944 |  0:01:16s\n",
            "epoch 23 | loss: 0.58966 | val_0_auc: 0.8037  |  0:01:19s\n",
            "epoch 24 | loss: 0.58942 | val_0_auc: 0.79241 |  0:01:23s\n",
            "epoch 25 | loss: 0.58441 | val_0_auc: 0.80597 |  0:01:27s\n",
            "epoch 26 | loss: 0.58167 | val_0_auc: 0.80805 |  0:01:30s\n",
            "epoch 27 | loss: 0.56944 | val_0_auc: 0.82048 |  0:01:33s\n",
            "epoch 28 | loss: 0.56738 | val_0_auc: 0.81047 |  0:01:36s\n",
            "epoch 29 | loss: 0.57265 | val_0_auc: 0.82767 |  0:01:39s\n",
            "epoch 30 | loss: 0.56168 | val_0_auc: 0.82577 |  0:01:42s\n",
            "epoch 31 | loss: 0.56426 | val_0_auc: 0.83501 |  0:01:44s\n",
            "epoch 32 | loss: 0.55366 | val_0_auc: 0.82965 |  0:01:48s\n",
            "epoch 33 | loss: 0.56052 | val_0_auc: 0.83366 |  0:01:51s\n",
            "epoch 34 | loss: 0.55896 | val_0_auc: 0.8329  |  0:01:54s\n",
            "epoch 35 | loss: 0.55399 | val_0_auc: 0.84224 |  0:01:57s\n",
            "epoch 36 | loss: 0.55755 | val_0_auc: 0.84591 |  0:02:01s\n",
            "epoch 37 | loss: 0.55948 | val_0_auc: 0.83595 |  0:02:04s\n",
            "epoch 38 | loss: 0.55091 | val_0_auc: 0.84324 |  0:02:07s\n",
            "epoch 39 | loss: 0.53295 | val_0_auc: 0.84294 |  0:02:10s\n",
            "epoch 40 | loss: 0.54422 | val_0_auc: 0.85614 |  0:02:14s\n",
            "epoch 41 | loss: 0.53003 | val_0_auc: 0.85832 |  0:02:16s\n",
            "epoch 42 | loss: 0.53947 | val_0_auc: 0.84922 |  0:02:19s\n",
            "epoch 43 | loss: 0.53571 | val_0_auc: 0.84644 |  0:02:22s\n",
            "epoch 44 | loss: 0.52279 | val_0_auc: 0.84705 |  0:02:26s\n",
            "epoch 45 | loss: 0.51947 | val_0_auc: 0.84997 |  0:02:29s\n",
            "epoch 46 | loss: 0.51958 | val_0_auc: 0.85474 |  0:02:32s\n",
            "epoch 47 | loss: 0.50807 | val_0_auc: 0.86273 |  0:02:36s\n",
            "epoch 48 | loss: 0.51249 | val_0_auc: 0.86982 |  0:02:39s\n",
            "epoch 49 | loss: 0.50392 | val_0_auc: 0.86011 |  0:02:42s\n",
            "epoch 50 | loss: 0.49949 | val_0_auc: 0.86209 |  0:02:46s\n",
            "epoch 51 | loss: 0.50024 | val_0_auc: 0.86313 |  0:02:49s\n",
            "epoch 52 | loss: 0.50057 | val_0_auc: 0.87092 |  0:02:52s\n",
            "epoch 53 | loss: 0.48524 | val_0_auc: 0.86837 |  0:02:55s\n",
            "epoch 54 | loss: 0.4906  | val_0_auc: 0.87433 |  0:02:58s\n",
            "epoch 55 | loss: 0.49565 | val_0_auc: 0.87604 |  0:03:01s\n",
            "epoch 56 | loss: 0.48351 | val_0_auc: 0.86713 |  0:03:05s\n",
            "epoch 57 | loss: 0.47951 | val_0_auc: 0.86156 |  0:03:08s\n",
            "epoch 58 | loss: 0.47694 | val_0_auc: 0.87635 |  0:03:11s\n",
            "epoch 59 | loss: 0.46949 | val_0_auc: 0.87988 |  0:03:15s\n",
            "epoch 60 | loss: 0.47558 | val_0_auc: 0.87277 |  0:03:18s\n",
            "epoch 61 | loss: 0.46748 | val_0_auc: 0.88156 |  0:03:21s\n",
            "epoch 62 | loss: 0.46306 | val_0_auc: 0.86759 |  0:03:24s\n",
            "epoch 63 | loss: 0.46303 | val_0_auc: 0.87325 |  0:03:28s\n",
            "epoch 64 | loss: 0.47544 | val_0_auc: 0.88564 |  0:03:31s\n",
            "epoch 65 | loss: 0.46394 | val_0_auc: 0.88417 |  0:03:35s\n",
            "epoch 66 | loss: 0.46193 | val_0_auc: 0.88622 |  0:03:37s\n",
            "epoch 67 | loss: 0.45849 | val_0_auc: 0.89196 |  0:03:41s\n",
            "epoch 68 | loss: 0.46155 | val_0_auc: 0.88904 |  0:03:44s\n",
            "epoch 69 | loss: 0.44838 | val_0_auc: 0.89952 |  0:03:48s\n",
            "epoch 70 | loss: 0.45011 | val_0_auc: 0.88316 |  0:03:51s\n",
            "epoch 71 | loss: 0.4573  | val_0_auc: 0.89364 |  0:03:55s\n",
            "epoch 72 | loss: 0.45922 | val_0_auc: 0.89699 |  0:03:58s\n",
            "epoch 73 | loss: 0.45413 | val_0_auc: 0.89769 |  0:04:01s\n",
            "epoch 74 | loss: 0.44292 | val_0_auc: 0.89206 |  0:04:06s\n",
            "epoch 75 | loss: 0.44187 | val_0_auc: 0.90025 |  0:04:09s\n",
            "epoch 76 | loss: 0.44438 | val_0_auc: 0.89347 |  0:04:12s\n",
            "epoch 77 | loss: 0.44756 | val_0_auc: 0.9067  |  0:04:15s\n",
            "epoch 78 | loss: 0.43471 | val_0_auc: 0.9036  |  0:04:19s\n",
            "epoch 79 | loss: 0.43798 | val_0_auc: 0.89676 |  0:04:22s\n",
            "epoch 80 | loss: 0.44464 | val_0_auc: 0.90283 |  0:04:25s\n",
            "epoch 81 | loss: 0.43675 | val_0_auc: 0.90134 |  0:04:29s\n",
            "epoch 82 | loss: 0.44128 | val_0_auc: 0.90455 |  0:04:33s\n",
            "epoch 83 | loss: 0.43013 | val_0_auc: 0.90093 |  0:04:36s\n",
            "epoch 84 | loss: 0.4326  | val_0_auc: 0.90467 |  0:04:39s\n",
            "epoch 85 | loss: 0.43647 | val_0_auc: 0.90924 |  0:04:43s\n",
            "epoch 86 | loss: 0.43396 | val_0_auc: 0.90504 |  0:04:46s\n",
            "epoch 87 | loss: 0.42972 | val_0_auc: 0.90356 |  0:04:50s\n",
            "epoch 88 | loss: 0.42396 | val_0_auc: 0.91032 |  0:04:54s\n",
            "epoch 89 | loss: 0.43954 | val_0_auc: 0.91031 |  0:04:59s\n",
            "epoch 90 | loss: 0.43395 | val_0_auc: 0.91437 |  0:05:02s\n",
            "epoch 91 | loss: 0.43735 | val_0_auc: 0.90732 |  0:05:05s\n",
            "epoch 92 | loss: 0.43222 | val_0_auc: 0.90361 |  0:05:09s\n",
            "epoch 93 | loss: 0.42385 | val_0_auc: 0.90587 |  0:05:12s\n",
            "epoch 94 | loss: 0.43353 | val_0_auc: 0.90853 |  0:05:15s\n",
            "epoch 95 | loss: 0.42212 | val_0_auc: 0.90355 |  0:05:19s\n",
            "epoch 96 | loss: 0.4225  | val_0_auc: 0.90021 |  0:05:23s\n",
            "epoch 97 | loss: 0.42426 | val_0_auc: 0.90569 |  0:05:27s\n",
            "epoch 98 | loss: 0.42484 | val_0_auc: 0.91054 |  0:05:30s\n",
            "epoch 99 | loss: 0.41848 | val_0_auc: 0.90208 |  0:05:34s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_auc = 0.91437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:18:47,713] Trial 6 finished with value: 0.9143685941421559 and parameters: {'n_d': 27, 'n_a': 52, 'n_steps': 5, 'gamma': 1.2349934593986374, 'momentum': 0.27733172709447024, 'lambda_sparse': 0.02838059290585973, 'lr': 0.0004444542349001473, 'weight_decay': 4.458601838917823e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.27701 | val_0_auc: 0.65486 |  0:00:06s\n",
            "epoch 1  | loss: 0.5216  | val_0_auc: 0.80911 |  0:00:12s\n",
            "epoch 2  | loss: 0.4681  | val_0_auc: 0.89989 |  0:00:18s\n",
            "epoch 3  | loss: 0.45635 | val_0_auc: 0.9312  |  0:00:25s\n",
            "epoch 4  | loss: 0.43496 | val_0_auc: 0.93806 |  0:00:32s\n",
            "epoch 5  | loss: 0.41855 | val_0_auc: 0.93334 |  0:00:39s\n",
            "epoch 6  | loss: 0.4134  | val_0_auc: 0.94627 |  0:00:46s\n",
            "epoch 7  | loss: 0.41688 | val_0_auc: 0.94178 |  0:00:53s\n",
            "epoch 8  | loss: 0.39803 | val_0_auc: 0.95201 |  0:01:00s\n",
            "epoch 9  | loss: 0.39695 | val_0_auc: 0.95433 |  0:01:06s\n",
            "epoch 10 | loss: 0.40355 | val_0_auc: 0.94411 |  0:01:13s\n",
            "epoch 11 | loss: 0.39019 | val_0_auc: 0.94147 |  0:01:19s\n",
            "epoch 12 | loss: 0.38451 | val_0_auc: 0.94935 |  0:01:26s\n",
            "epoch 13 | loss: 0.38286 | val_0_auc: 0.9493  |  0:01:32s\n",
            "epoch 14 | loss: 0.37747 | val_0_auc: 0.95484 |  0:01:39s\n",
            "epoch 15 | loss: 0.35761 | val_0_auc: 0.94485 |  0:01:45s\n",
            "epoch 16 | loss: 0.37471 | val_0_auc: 0.9514  |  0:01:53s\n",
            "epoch 17 | loss: 0.35375 | val_0_auc: 0.95499 |  0:02:00s\n",
            "epoch 18 | loss: 0.35122 | val_0_auc: 0.96041 |  0:02:07s\n",
            "epoch 19 | loss: 0.36665 | val_0_auc: 0.95291 |  0:02:14s\n",
            "epoch 20 | loss: 0.34906 | val_0_auc: 0.94025 |  0:02:20s\n",
            "epoch 21 | loss: 0.34955 | val_0_auc: 0.95823 |  0:02:27s\n",
            "epoch 22 | loss: 0.35407 | val_0_auc: 0.95092 |  0:02:33s\n",
            "epoch 23 | loss: 0.33845 | val_0_auc: 0.9593  |  0:02:39s\n",
            "epoch 24 | loss: 0.35587 | val_0_auc: 0.95682 |  0:02:45s\n",
            "epoch 25 | loss: 0.33581 | val_0_auc: 0.95829 |  0:02:52s\n",
            "epoch 26 | loss: 0.32965 | val_0_auc: 0.95375 |  0:02:59s\n",
            "epoch 27 | loss: 0.3473  | val_0_auc: 0.95282 |  0:03:05s\n",
            "epoch 28 | loss: 0.32771 | val_0_auc: 0.95526 |  0:03:11s\n",
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.96041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:22:02,568] Trial 7 finished with value: 0.960408862183648 and parameters: {'n_d': 54, 'n_a': 63, 'n_steps': 10, 'gamma': 0.5356732286723528, 'momentum': 0.2861220168804916, 'lambda_sparse': 0.055660765574187296, 'lr': 0.0400624876216833, 'weight_decay': 1.7562852811080303e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 4.20822 | val_0_auc: 0.5109  |  0:00:05s\n",
            "epoch 1  | loss: 3.10958 | val_0_auc: 0.55036 |  0:00:09s\n",
            "epoch 2  | loss: 2.09789 | val_0_auc: 0.58146 |  0:00:13s\n",
            "epoch 3  | loss: 1.3376  | val_0_auc: 0.68732 |  0:00:18s\n",
            "epoch 4  | loss: 0.85297 | val_0_auc: 0.75195 |  0:00:23s\n",
            "epoch 5  | loss: 0.66976 | val_0_auc: 0.78983 |  0:00:28s\n",
            "epoch 6  | loss: 0.60382 | val_0_auc: 0.81029 |  0:00:32s\n",
            "epoch 7  | loss: 0.57606 | val_0_auc: 0.82572 |  0:00:36s\n",
            "epoch 8  | loss: 0.55982 | val_0_auc: 0.84418 |  0:00:42s\n",
            "epoch 9  | loss: 0.5376  | val_0_auc: 0.84628 |  0:00:46s\n",
            "epoch 10 | loss: 0.53713 | val_0_auc: 0.86245 |  0:00:51s\n",
            "epoch 11 | loss: 0.52582 | val_0_auc: 0.84168 |  0:00:55s\n",
            "epoch 12 | loss: 0.50001 | val_0_auc: 0.86588 |  0:01:00s\n",
            "epoch 13 | loss: 0.50622 | val_0_auc: 0.8673  |  0:01:05s\n",
            "epoch 14 | loss: 0.4962  | val_0_auc: 0.8578  |  0:01:10s\n",
            "epoch 15 | loss: 0.49251 | val_0_auc: 0.87724 |  0:01:14s\n",
            "epoch 16 | loss: 0.47779 | val_0_auc: 0.87132 |  0:01:19s\n",
            "epoch 17 | loss: 0.47002 | val_0_auc: 0.88189 |  0:01:23s\n",
            "epoch 18 | loss: 0.46568 | val_0_auc: 0.89129 |  0:01:27s\n",
            "epoch 19 | loss: 0.4587  | val_0_auc: 0.88086 |  0:01:32s\n",
            "epoch 20 | loss: 0.45195 | val_0_auc: 0.88455 |  0:01:36s\n",
            "epoch 21 | loss: 0.44437 | val_0_auc: 0.89489 |  0:01:41s\n",
            "epoch 22 | loss: 0.43754 | val_0_auc: 0.8883  |  0:01:46s\n",
            "epoch 23 | loss: 0.42945 | val_0_auc: 0.90073 |  0:01:51s\n",
            "epoch 24 | loss: 0.42477 | val_0_auc: 0.90469 |  0:01:56s\n",
            "epoch 25 | loss: 0.43614 | val_0_auc: 0.90269 |  0:02:00s\n",
            "epoch 26 | loss: 0.4194  | val_0_auc: 0.90388 |  0:02:04s\n",
            "epoch 27 | loss: 0.41801 | val_0_auc: 0.8953  |  0:02:09s\n",
            "epoch 28 | loss: 0.41001 | val_0_auc: 0.90901 |  0:02:14s\n",
            "epoch 29 | loss: 0.41751 | val_0_auc: 0.89783 |  0:02:18s\n",
            "epoch 30 | loss: 0.40687 | val_0_auc: 0.89116 |  0:02:23s\n",
            "epoch 31 | loss: 0.40262 | val_0_auc: 0.90312 |  0:02:28s\n",
            "epoch 32 | loss: 0.40044 | val_0_auc: 0.9132  |  0:02:32s\n",
            "epoch 33 | loss: 0.39935 | val_0_auc: 0.90797 |  0:02:37s\n",
            "epoch 34 | loss: 0.40829 | val_0_auc: 0.91002 |  0:02:42s\n",
            "epoch 35 | loss: 0.39301 | val_0_auc: 0.91278 |  0:02:47s\n",
            "epoch 36 | loss: 0.39439 | val_0_auc: 0.91397 |  0:02:51s\n",
            "epoch 37 | loss: 0.38017 | val_0_auc: 0.90713 |  0:02:55s\n",
            "epoch 38 | loss: 0.37502 | val_0_auc: 0.91033 |  0:03:00s\n",
            "epoch 39 | loss: 0.38364 | val_0_auc: 0.91515 |  0:03:04s\n",
            "epoch 40 | loss: 0.37636 | val_0_auc: 0.9149  |  0:03:09s\n",
            "epoch 41 | loss: 0.38419 | val_0_auc: 0.9142  |  0:03:14s\n",
            "epoch 42 | loss: 0.38119 | val_0_auc: 0.92338 |  0:03:18s\n",
            "epoch 43 | loss: 0.37105 | val_0_auc: 0.92173 |  0:03:23s\n",
            "epoch 44 | loss: 0.3643  | val_0_auc: 0.92521 |  0:03:27s\n",
            "epoch 45 | loss: 0.36439 | val_0_auc: 0.92758 |  0:03:31s\n",
            "epoch 46 | loss: 0.36561 | val_0_auc: 0.92582 |  0:03:36s\n",
            "epoch 47 | loss: 0.36177 | val_0_auc: 0.92383 |  0:03:41s\n",
            "epoch 48 | loss: 0.36667 | val_0_auc: 0.92514 |  0:03:45s\n",
            "epoch 49 | loss: 0.36763 | val_0_auc: 0.92361 |  0:03:50s\n",
            "epoch 50 | loss: 0.36595 | val_0_auc: 0.92171 |  0:03:54s\n",
            "epoch 51 | loss: 0.35486 | val_0_auc: 0.91385 |  0:03:59s\n",
            "epoch 52 | loss: 0.36588 | val_0_auc: 0.92486 |  0:04:04s\n",
            "epoch 53 | loss: 0.35646 | val_0_auc: 0.92824 |  0:04:08s\n",
            "epoch 54 | loss: 0.36074 | val_0_auc: 0.91183 |  0:04:13s\n",
            "epoch 55 | loss: 0.35808 | val_0_auc: 0.92362 |  0:04:18s\n",
            "epoch 56 | loss: 0.34881 | val_0_auc: 0.92366 |  0:04:23s\n",
            "epoch 57 | loss: 0.35485 | val_0_auc: 0.9345  |  0:04:28s\n",
            "epoch 58 | loss: 0.35437 | val_0_auc: 0.92474 |  0:04:32s\n",
            "epoch 59 | loss: 0.3525  | val_0_auc: 0.92859 |  0:04:37s\n",
            "epoch 60 | loss: 0.34659 | val_0_auc: 0.93468 |  0:04:41s\n",
            "epoch 61 | loss: 0.34505 | val_0_auc: 0.93415 |  0:04:46s\n",
            "epoch 62 | loss: 0.3357  | val_0_auc: 0.93105 |  0:04:52s\n",
            "epoch 63 | loss: 0.34034 | val_0_auc: 0.93458 |  0:04:56s\n",
            "epoch 64 | loss: 0.34071 | val_0_auc: 0.92846 |  0:05:01s\n",
            "epoch 65 | loss: 0.3375  | val_0_auc: 0.93643 |  0:05:06s\n",
            "epoch 66 | loss: 0.33897 | val_0_auc: 0.93207 |  0:05:11s\n",
            "epoch 67 | loss: 0.33322 | val_0_auc: 0.93588 |  0:05:16s\n",
            "epoch 68 | loss: 0.33421 | val_0_auc: 0.93128 |  0:05:20s\n",
            "epoch 69 | loss: 0.33064 | val_0_auc: 0.9306  |  0:05:25s\n",
            "epoch 70 | loss: 0.33191 | val_0_auc: 0.93313 |  0:05:30s\n",
            "epoch 71 | loss: 0.33546 | val_0_auc: 0.93951 |  0:05:34s\n",
            "epoch 72 | loss: 0.33528 | val_0_auc: 0.93133 |  0:05:39s\n",
            "epoch 73 | loss: 0.32577 | val_0_auc: 0.93912 |  0:05:44s\n",
            "epoch 74 | loss: 0.33336 | val_0_auc: 0.93639 |  0:05:48s\n",
            "epoch 75 | loss: 0.3298  | val_0_auc: 0.94201 |  0:05:53s\n",
            "epoch 76 | loss: 0.32274 | val_0_auc: 0.93889 |  0:05:57s\n",
            "epoch 77 | loss: 0.33254 | val_0_auc: 0.93649 |  0:06:02s\n",
            "epoch 78 | loss: 0.32099 | val_0_auc: 0.93645 |  0:06:08s\n",
            "epoch 79 | loss: 0.32499 | val_0_auc: 0.94454 |  0:06:12s\n",
            "epoch 80 | loss: 0.32672 | val_0_auc: 0.93911 |  0:06:17s\n",
            "epoch 81 | loss: 0.32697 | val_0_auc: 0.9395  |  0:06:22s\n",
            "epoch 82 | loss: 0.32622 | val_0_auc: 0.93475 |  0:06:27s\n",
            "epoch 83 | loss: 0.32489 | val_0_auc: 0.93916 |  0:06:32s\n",
            "epoch 84 | loss: 0.31717 | val_0_auc: 0.93906 |  0:06:36s\n",
            "epoch 85 | loss: 0.3193  | val_0_auc: 0.94148 |  0:06:41s\n",
            "epoch 86 | loss: 0.32616 | val_0_auc: 0.94372 |  0:06:47s\n",
            "epoch 87 | loss: 0.3159  | val_0_auc: 0.94213 |  0:06:51s\n",
            "epoch 88 | loss: 0.32102 | val_0_auc: 0.94163 |  0:06:56s\n",
            "epoch 89 | loss: 0.31972 | val_0_auc: 0.94231 |  0:07:01s\n",
            "\n",
            "Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_auc = 0.94454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:29:06,015] Trial 8 finished with value: 0.9445433527440872 and parameters: {'n_d': 28, 'n_a': 18, 'n_steps': 9, 'gamma': 0.3930845189108897, 'momentum': 0.3183755471752994, 'lambda_sparse': 0.002444965496372508, 'lr': 0.00016027281285483437, 'weight_decay': 0.00037035960583629916}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.79612 | val_0_auc: 0.53913 |  0:00:02s\n",
            "epoch 1  | loss: 0.59668 | val_0_auc: 0.69465 |  0:00:05s\n",
            "epoch 2  | loss: 0.5442  | val_0_auc: 0.83857 |  0:00:07s\n",
            "epoch 3  | loss: 0.5487  | val_0_auc: 0.86146 |  0:00:10s\n",
            "epoch 4  | loss: 0.48513 | val_0_auc: 0.88367 |  0:00:12s\n",
            "epoch 5  | loss: 0.46941 | val_0_auc: 0.87904 |  0:00:15s\n",
            "epoch 6  | loss: 0.4605  | val_0_auc: 0.88777 |  0:00:18s\n",
            "epoch 7  | loss: 0.44068 | val_0_auc: 0.88692 |  0:00:20s\n",
            "epoch 8  | loss: 0.42825 | val_0_auc: 0.91737 |  0:00:22s\n",
            "epoch 9  | loss: 0.41226 | val_0_auc: 0.91331 |  0:00:24s\n",
            "epoch 10 | loss: 0.40374 | val_0_auc: 0.92145 |  0:00:27s\n",
            "epoch 11 | loss: 0.40568 | val_0_auc: 0.91691 |  0:00:30s\n",
            "epoch 12 | loss: 0.40559 | val_0_auc: 0.9365  |  0:00:32s\n",
            "epoch 13 | loss: 0.37616 | val_0_auc: 0.9248  |  0:00:34s\n",
            "epoch 14 | loss: 0.36881 | val_0_auc: 0.91985 |  0:00:37s\n",
            "epoch 15 | loss: 0.39707 | val_0_auc: 0.93369 |  0:00:39s\n",
            "epoch 16 | loss: 0.39774 | val_0_auc: 0.92402 |  0:00:42s\n",
            "epoch 17 | loss: 0.37392 | val_0_auc: 0.93386 |  0:00:45s\n",
            "epoch 18 | loss: 0.3665  | val_0_auc: 0.93814 |  0:00:47s\n",
            "epoch 19 | loss: 0.40021 | val_0_auc: 0.92334 |  0:00:50s\n",
            "epoch 20 | loss: 0.39481 | val_0_auc: 0.94032 |  0:00:53s\n",
            "epoch 21 | loss: 0.36434 | val_0_auc: 0.92697 |  0:00:56s\n",
            "epoch 22 | loss: 0.36371 | val_0_auc: 0.92612 |  0:00:59s\n",
            "epoch 23 | loss: 0.35789 | val_0_auc: 0.93473 |  0:01:02s\n",
            "epoch 24 | loss: 0.35807 | val_0_auc: 0.93084 |  0:01:04s\n",
            "epoch 25 | loss: 0.36101 | val_0_auc: 0.91978 |  0:01:07s\n",
            "epoch 26 | loss: 0.35276 | val_0_auc: 0.93426 |  0:01:09s\n",
            "epoch 27 | loss: 0.3594  | val_0_auc: 0.93968 |  0:01:12s\n",
            "epoch 28 | loss: 0.35513 | val_0_auc: 0.94215 |  0:01:14s\n",
            "epoch 29 | loss: 0.33945 | val_0_auc: 0.94317 |  0:01:17s\n",
            "epoch 30 | loss: 0.34492 | val_0_auc: 0.94084 |  0:01:20s\n",
            "epoch 31 | loss: 0.3337  | val_0_auc: 0.94416 |  0:01:24s\n",
            "epoch 32 | loss: 0.33194 | val_0_auc: 0.94341 |  0:01:28s\n",
            "epoch 33 | loss: 0.34681 | val_0_auc: 0.92212 |  0:01:33s\n",
            "epoch 34 | loss: 0.33082 | val_0_auc: 0.94531 |  0:01:37s\n",
            "epoch 35 | loss: 0.34278 | val_0_auc: 0.93125 |  0:01:41s\n",
            "epoch 36 | loss: 0.34344 | val_0_auc: 0.94091 |  0:01:46s\n",
            "epoch 37 | loss: 0.34008 | val_0_auc: 0.94454 |  0:01:51s\n",
            "epoch 38 | loss: 0.31771 | val_0_auc: 0.9492  |  0:01:56s\n",
            "epoch 39 | loss: 0.31607 | val_0_auc: 0.94625 |  0:02:00s\n",
            "epoch 40 | loss: 0.32091 | val_0_auc: 0.94797 |  0:02:05s\n",
            "epoch 41 | loss: 0.32349 | val_0_auc: 0.94826 |  0:02:09s\n",
            "epoch 42 | loss: 0.31349 | val_0_auc: 0.95486 |  0:02:13s\n",
            "epoch 43 | loss: 0.30916 | val_0_auc: 0.95449 |  0:02:18s\n",
            "epoch 44 | loss: 0.30228 | val_0_auc: 0.94973 |  0:02:22s\n",
            "epoch 45 | loss: 0.29262 | val_0_auc: 0.95203 |  0:02:27s\n",
            "epoch 46 | loss: 0.31036 | val_0_auc: 0.9511  |  0:02:31s\n",
            "epoch 47 | loss: 0.30783 | val_0_auc: 0.95551 |  0:02:35s\n",
            "epoch 48 | loss: 0.29823 | val_0_auc: 0.95404 |  0:02:39s\n",
            "epoch 49 | loss: 0.30123 | val_0_auc: 0.95398 |  0:02:44s\n",
            "epoch 50 | loss: 0.30708 | val_0_auc: 0.9455  |  0:02:48s\n",
            "epoch 51 | loss: 0.30299 | val_0_auc: 0.95138 |  0:02:53s\n",
            "epoch 52 | loss: 0.30985 | val_0_auc: 0.9442  |  0:02:57s\n",
            "epoch 53 | loss: 0.32633 | val_0_auc: 0.95446 |  0:03:02s\n",
            "epoch 54 | loss: 0.28861 | val_0_auc: 0.9484  |  0:03:06s\n",
            "epoch 55 | loss: 0.30006 | val_0_auc: 0.95756 |  0:03:11s\n",
            "epoch 56 | loss: 0.28219 | val_0_auc: 0.95438 |  0:03:15s\n",
            "epoch 57 | loss: 0.28268 | val_0_auc: 0.95309 |  0:03:20s\n",
            "epoch 58 | loss: 0.28624 | val_0_auc: 0.95584 |  0:03:25s\n",
            "epoch 59 | loss: 0.27465 | val_0_auc: 0.95249 |  0:03:29s\n",
            "epoch 60 | loss: 0.28539 | val_0_auc: 0.95925 |  0:03:33s\n",
            "epoch 61 | loss: 0.29154 | val_0_auc: 0.95029 |  0:03:37s\n",
            "epoch 62 | loss: 0.28092 | val_0_auc: 0.95797 |  0:03:42s\n",
            "epoch 63 | loss: 0.2961  | val_0_auc: 0.95425 |  0:03:46s\n",
            "epoch 64 | loss: 0.27484 | val_0_auc: 0.95454 |  0:03:51s\n",
            "epoch 65 | loss: 0.28153 | val_0_auc: 0.9493  |  0:03:55s\n",
            "epoch 66 | loss: 0.28162 | val_0_auc: 0.95596 |  0:04:00s\n",
            "epoch 67 | loss: 0.27448 | val_0_auc: 0.94769 |  0:04:04s\n",
            "epoch 68 | loss: 0.26979 | val_0_auc: 0.95647 |  0:04:08s\n",
            "epoch 69 | loss: 0.27267 | val_0_auc: 0.95501 |  0:04:13s\n",
            "epoch 70 | loss: 0.28357 | val_0_auc: 0.94553 |  0:04:17s\n",
            "\n",
            "Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_auc = 0.95925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:33:26,716] Trial 9 finished with value: 0.9592520987104831 and parameters: {'n_d': 60, 'n_a': 64, 'n_steps': 3, 'gamma': 1.7750255929062788, 'momentum': 0.32944511553135714, 'lambda_sparse': 0.07392840590413517, 'lr': 0.017435889503129506, 'weight_decay': 4.800105390377957e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.84351 | val_0_auc: 0.5227  |  0:00:02s\n",
            "epoch 1  | loss: 0.74044 | val_0_auc: 0.5591  |  0:00:05s\n",
            "epoch 2  | loss: 0.71684 | val_0_auc: 0.64408 |  0:00:07s\n",
            "epoch 3  | loss: 0.67874 | val_0_auc: 0.67988 |  0:00:09s\n",
            "epoch 4  | loss: 0.65104 | val_0_auc: 0.75061 |  0:00:11s\n",
            "epoch 5  | loss: 0.62658 | val_0_auc: 0.79178 |  0:00:13s\n",
            "epoch 6  | loss: 0.6067  | val_0_auc: 0.81543 |  0:00:16s\n",
            "epoch 7  | loss: 0.58477 | val_0_auc: 0.83676 |  0:00:18s\n",
            "epoch 8  | loss: 0.56077 | val_0_auc: 0.83692 |  0:00:21s\n",
            "epoch 9  | loss: 0.54868 | val_0_auc: 0.84531 |  0:00:23s\n",
            "epoch 10 | loss: 0.54694 | val_0_auc: 0.81094 |  0:00:25s\n",
            "epoch 11 | loss: 0.54017 | val_0_auc: 0.85431 |  0:00:28s\n",
            "epoch 12 | loss: 0.52181 | val_0_auc: 0.87266 |  0:00:30s\n",
            "epoch 13 | loss: 0.50855 | val_0_auc: 0.85838 |  0:00:33s\n",
            "epoch 14 | loss: 0.50658 | val_0_auc: 0.86302 |  0:00:35s\n",
            "epoch 15 | loss: 0.49879 | val_0_auc: 0.87152 |  0:00:37s\n",
            "epoch 16 | loss: 0.49939 | val_0_auc: 0.88584 |  0:00:39s\n",
            "epoch 17 | loss: 0.48086 | val_0_auc: 0.88086 |  0:00:41s\n",
            "epoch 18 | loss: 0.47504 | val_0_auc: 0.88745 |  0:00:44s\n",
            "epoch 19 | loss: 0.46676 | val_0_auc: 0.89444 |  0:00:46s\n",
            "epoch 20 | loss: 0.46159 | val_0_auc: 0.89365 |  0:00:48s\n",
            "epoch 21 | loss: 0.46243 | val_0_auc: 0.88674 |  0:00:50s\n",
            "epoch 22 | loss: 0.45474 | val_0_auc: 0.90094 |  0:00:53s\n",
            "epoch 23 | loss: 0.45902 | val_0_auc: 0.90303 |  0:00:55s\n",
            "epoch 24 | loss: 0.44011 | val_0_auc: 0.90948 |  0:00:58s\n",
            "epoch 25 | loss: 0.44384 | val_0_auc: 0.8957  |  0:01:00s\n",
            "epoch 26 | loss: 0.43903 | val_0_auc: 0.89248 |  0:01:02s\n",
            "epoch 27 | loss: 0.42682 | val_0_auc: 0.90644 |  0:01:05s\n",
            "epoch 28 | loss: 0.43309 | val_0_auc: 0.89512 |  0:01:07s\n",
            "epoch 29 | loss: 0.42243 | val_0_auc: 0.91073 |  0:01:09s\n",
            "epoch 30 | loss: 0.43328 | val_0_auc: 0.91028 |  0:01:12s\n",
            "epoch 31 | loss: 0.41625 | val_0_auc: 0.91514 |  0:01:14s\n",
            "epoch 32 | loss: 0.40356 | val_0_auc: 0.9097  |  0:01:17s\n",
            "epoch 33 | loss: 0.4154  | val_0_auc: 0.91461 |  0:01:20s\n",
            "epoch 34 | loss: 0.39792 | val_0_auc: 0.9106  |  0:01:23s\n",
            "epoch 35 | loss: 0.40619 | val_0_auc: 0.91296 |  0:01:27s\n",
            "epoch 36 | loss: 0.40678 | val_0_auc: 0.91431 |  0:01:31s\n",
            "epoch 37 | loss: 0.40699 | val_0_auc: 0.91457 |  0:01:34s\n",
            "epoch 38 | loss: 0.40357 | val_0_auc: 0.9071  |  0:01:37s\n",
            "epoch 39 | loss: 0.40724 | val_0_auc: 0.91389 |  0:01:41s\n",
            "epoch 40 | loss: 0.39768 | val_0_auc: 0.91419 |  0:01:44s\n",
            "epoch 41 | loss: 0.38931 | val_0_auc: 0.91801 |  0:01:47s\n",
            "epoch 42 | loss: 0.39517 | val_0_auc: 0.92018 |  0:01:50s\n",
            "epoch 43 | loss: 0.4016  | val_0_auc: 0.93241 |  0:01:53s\n",
            "epoch 44 | loss: 0.38392 | val_0_auc: 0.93062 |  0:01:57s\n",
            "epoch 45 | loss: 0.38199 | val_0_auc: 0.92303 |  0:02:00s\n",
            "epoch 46 | loss: 0.38196 | val_0_auc: 0.9272  |  0:02:03s\n",
            "epoch 47 | loss: 0.38044 | val_0_auc: 0.92611 |  0:02:07s\n",
            "epoch 48 | loss: 0.38431 | val_0_auc: 0.92806 |  0:02:11s\n",
            "epoch 49 | loss: 0.38231 | val_0_auc: 0.93229 |  0:02:14s\n",
            "epoch 50 | loss: 0.37589 | val_0_auc: 0.93415 |  0:02:17s\n",
            "epoch 51 | loss: 0.37219 | val_0_auc: 0.9363  |  0:02:21s\n",
            "epoch 52 | loss: 0.37282 | val_0_auc: 0.91455 |  0:02:24s\n",
            "epoch 53 | loss: 0.37743 | val_0_auc: 0.93459 |  0:02:27s\n",
            "epoch 54 | loss: 0.38454 | val_0_auc: 0.93449 |  0:02:31s\n",
            "epoch 55 | loss: 0.36284 | val_0_auc: 0.91473 |  0:02:34s\n",
            "epoch 56 | loss: 0.37213 | val_0_auc: 0.93129 |  0:02:38s\n",
            "epoch 57 | loss: 0.35976 | val_0_auc: 0.92572 |  0:02:41s\n",
            "epoch 58 | loss: 0.36088 | val_0_auc: 0.92646 |  0:02:45s\n",
            "epoch 59 | loss: 0.35588 | val_0_auc: 0.93657 |  0:02:48s\n",
            "epoch 60 | loss: 0.35362 | val_0_auc: 0.93908 |  0:02:51s\n",
            "epoch 61 | loss: 0.34456 | val_0_auc: 0.9388  |  0:02:54s\n",
            "epoch 62 | loss: 0.34999 | val_0_auc: 0.9396  |  0:02:58s\n",
            "epoch 63 | loss: 0.36171 | val_0_auc: 0.93325 |  0:03:02s\n",
            "epoch 64 | loss: 0.35152 | val_0_auc: 0.93024 |  0:03:05s\n",
            "epoch 65 | loss: 0.36022 | val_0_auc: 0.93592 |  0:03:08s\n",
            "epoch 66 | loss: 0.35252 | val_0_auc: 0.9351  |  0:03:12s\n",
            "epoch 67 | loss: 0.35232 | val_0_auc: 0.93864 |  0:03:15s\n",
            "epoch 68 | loss: 0.34564 | val_0_auc: 0.93075 |  0:03:18s\n",
            "epoch 69 | loss: 0.35074 | val_0_auc: 0.93524 |  0:03:22s\n",
            "epoch 70 | loss: 0.35174 | val_0_auc: 0.93291 |  0:03:26s\n",
            "epoch 71 | loss: 0.33571 | val_0_auc: 0.94008 |  0:03:29s\n",
            "epoch 72 | loss: 0.34278 | val_0_auc: 0.92927 |  0:03:33s\n",
            "epoch 73 | loss: 0.34215 | val_0_auc: 0.93764 |  0:03:37s\n",
            "epoch 74 | loss: 0.34092 | val_0_auc: 0.94294 |  0:03:40s\n",
            "epoch 75 | loss: 0.33222 | val_0_auc: 0.93774 |  0:03:43s\n",
            "epoch 76 | loss: 0.32793 | val_0_auc: 0.94589 |  0:03:47s\n",
            "epoch 77 | loss: 0.32563 | val_0_auc: 0.94286 |  0:03:50s\n",
            "epoch 78 | loss: 0.33874 | val_0_auc: 0.93614 |  0:03:54s\n",
            "epoch 79 | loss: 0.32888 | val_0_auc: 0.94301 |  0:03:57s\n",
            "epoch 80 | loss: 0.33012 | val_0_auc: 0.93944 |  0:04:01s\n",
            "epoch 81 | loss: 0.32811 | val_0_auc: 0.93615 |  0:04:04s\n",
            "epoch 82 | loss: 0.33042 | val_0_auc: 0.93462 |  0:04:07s\n",
            "epoch 83 | loss: 0.33503 | val_0_auc: 0.94006 |  0:04:11s\n",
            "epoch 84 | loss: 0.32252 | val_0_auc: 0.94223 |  0:04:14s\n",
            "epoch 85 | loss: 0.32789 | val_0_auc: 0.94061 |  0:04:18s\n",
            "epoch 86 | loss: 0.32784 | val_0_auc: 0.93653 |  0:04:21s\n",
            "\n",
            "Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_auc = 0.94589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:37:51,081] Trial 10 finished with value: 0.9458940692110827 and parameters: {'n_d': 64, 'n_a': 37, 'n_steps': 3, 'gamma': 1.2567704601948433, 'momentum': 0.49053814904449045, 'lambda_sparse': 0.09363897415427358, 'lr': 0.0010608386677375505, 'weight_decay': 2.4778819807607405e-05}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.90782 | val_0_auc: 0.57371 |  0:00:03s\n",
            "epoch 1  | loss: 0.64527 | val_0_auc: 0.64524 |  0:00:06s\n",
            "epoch 2  | loss: 0.62419 | val_0_auc: 0.77477 |  0:00:09s\n",
            "epoch 3  | loss: 0.60394 | val_0_auc: 0.78959 |  0:00:12s\n",
            "epoch 4  | loss: 0.59255 | val_0_auc: 0.77682 |  0:00:16s\n",
            "epoch 5  | loss: 0.57641 | val_0_auc: 0.78206 |  0:00:19s\n",
            "epoch 6  | loss: 0.58671 | val_0_auc: 0.79919 |  0:00:22s\n",
            "epoch 7  | loss: 0.57385 | val_0_auc: 0.80503 |  0:00:26s\n",
            "epoch 8  | loss: 0.57077 | val_0_auc: 0.81136 |  0:00:28s\n",
            "epoch 9  | loss: 0.56381 | val_0_auc: 0.82048 |  0:00:31s\n",
            "epoch 10 | loss: 0.55644 | val_0_auc: 0.82452 |  0:00:34s\n",
            "epoch 11 | loss: 0.56165 | val_0_auc: 0.79653 |  0:00:38s\n",
            "epoch 12 | loss: 0.57355 | val_0_auc: 0.82123 |  0:00:41s\n",
            "epoch 13 | loss: 0.55282 | val_0_auc: 0.81315 |  0:00:44s\n",
            "epoch 14 | loss: 0.54769 | val_0_auc: 0.82765 |  0:00:47s\n",
            "epoch 15 | loss: 0.54103 | val_0_auc: 0.84016 |  0:00:50s\n",
            "epoch 16 | loss: 0.53217 | val_0_auc: 0.77919 |  0:00:54s\n",
            "epoch 17 | loss: 0.58455 | val_0_auc: 0.82285 |  0:00:57s\n",
            "epoch 18 | loss: 0.56664 | val_0_auc: 0.82459 |  0:01:00s\n",
            "epoch 19 | loss: 0.55024 | val_0_auc: 0.83668 |  0:01:04s\n",
            "epoch 20 | loss: 0.54055 | val_0_auc: 0.84062 |  0:01:06s\n",
            "epoch 21 | loss: 0.54594 | val_0_auc: 0.81694 |  0:01:09s\n",
            "epoch 22 | loss: 0.54587 | val_0_auc: 0.83553 |  0:01:12s\n",
            "epoch 23 | loss: 0.53583 | val_0_auc: 0.84369 |  0:01:16s\n",
            "epoch 24 | loss: 0.54875 | val_0_auc: 0.83493 |  0:01:20s\n",
            "epoch 25 | loss: 0.54167 | val_0_auc: 0.8332  |  0:01:23s\n",
            "epoch 26 | loss: 0.53788 | val_0_auc: 0.83292 |  0:01:27s\n",
            "epoch 27 | loss: 0.53631 | val_0_auc: 0.84392 |  0:01:30s\n",
            "epoch 28 | loss: 0.534   | val_0_auc: 0.84666 |  0:01:34s\n",
            "epoch 29 | loss: 0.54125 | val_0_auc: 0.84466 |  0:01:36s\n",
            "epoch 30 | loss: 0.53721 | val_0_auc: 0.84621 |  0:01:40s\n",
            "epoch 31 | loss: 0.52999 | val_0_auc: 0.85233 |  0:01:44s\n",
            "epoch 32 | loss: 0.52794 | val_0_auc: 0.84524 |  0:01:48s\n",
            "epoch 33 | loss: 0.52891 | val_0_auc: 0.8546  |  0:01:52s\n",
            "epoch 34 | loss: 0.53798 | val_0_auc: 0.83741 |  0:01:56s\n",
            "epoch 35 | loss: 0.52561 | val_0_auc: 0.85275 |  0:02:00s\n",
            "epoch 36 | loss: 0.53498 | val_0_auc: 0.83003 |  0:02:05s\n",
            "epoch 37 | loss: 0.52381 | val_0_auc: 0.8382  |  0:02:09s\n",
            "epoch 38 | loss: 0.51739 | val_0_auc: 0.84224 |  0:02:13s\n",
            "epoch 39 | loss: 0.54286 | val_0_auc: 0.78045 |  0:02:18s\n",
            "epoch 40 | loss: 0.52258 | val_0_auc: 0.84845 |  0:02:22s\n",
            "epoch 41 | loss: 0.53248 | val_0_auc: 0.8388  |  0:02:26s\n",
            "epoch 42 | loss: 0.51868 | val_0_auc: 0.84523 |  0:02:31s\n",
            "epoch 43 | loss: 0.52009 | val_0_auc: 0.84911 |  0:02:35s\n",
            "\n",
            "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.8546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:40:29,364] Trial 11 finished with value: 0.8546047995252402 and parameters: {'n_d': 48, 'n_a': 40, 'n_steps': 5, 'gamma': 0.9005273622065978, 'momentum': 0.17551312516100676, 'lambda_sparse': 0.06158501991693404, 'lr': 0.06529962394606435, 'weight_decay': 1.1446444215438385e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.93845 | val_0_auc: 0.64537 |  0:00:05s\n",
            "epoch 1  | loss: 0.55001 | val_0_auc: 0.84436 |  0:00:10s\n",
            "epoch 2  | loss: 0.50473 | val_0_auc: 0.9185  |  0:00:15s\n",
            "epoch 3  | loss: 0.47584 | val_0_auc: 0.92514 |  0:00:20s\n",
            "epoch 4  | loss: 0.45246 | val_0_auc: 0.93667 |  0:00:25s\n",
            "epoch 5  | loss: 0.4572  | val_0_auc: 0.93381 |  0:00:31s\n",
            "epoch 6  | loss: 0.4386  | val_0_auc: 0.94688 |  0:00:35s\n",
            "epoch 7  | loss: 0.43228 | val_0_auc: 0.93268 |  0:00:40s\n",
            "epoch 8  | loss: 0.42095 | val_0_auc: 0.93187 |  0:00:47s\n",
            "epoch 9  | loss: 0.41466 | val_0_auc: 0.94287 |  0:00:51s\n",
            "epoch 10 | loss: 0.40741 | val_0_auc: 0.9343  |  0:00:57s\n",
            "epoch 11 | loss: 0.41624 | val_0_auc: 0.94871 |  0:01:02s\n",
            "epoch 12 | loss: 0.41373 | val_0_auc: 0.94468 |  0:01:07s\n",
            "epoch 13 | loss: 0.40408 | val_0_auc: 0.94474 |  0:01:12s\n",
            "epoch 14 | loss: 0.41113 | val_0_auc: 0.94588 |  0:01:17s\n",
            "epoch 15 | loss: 0.37465 | val_0_auc: 0.95597 |  0:01:22s\n",
            "epoch 16 | loss: 0.395   | val_0_auc: 0.94245 |  0:01:27s\n",
            "epoch 17 | loss: 0.39324 | val_0_auc: 0.95548 |  0:01:33s\n",
            "epoch 18 | loss: 0.37744 | val_0_auc: 0.95327 |  0:01:38s\n",
            "epoch 19 | loss: 0.38356 | val_0_auc: 0.95771 |  0:01:44s\n",
            "epoch 20 | loss: 0.37608 | val_0_auc: 0.95767 |  0:01:49s\n",
            "epoch 21 | loss: 0.37879 | val_0_auc: 0.95544 |  0:01:54s\n",
            "epoch 22 | loss: 0.38832 | val_0_auc: 0.95312 |  0:01:59s\n",
            "epoch 23 | loss: 0.38424 | val_0_auc: 0.93451 |  0:02:03s\n",
            "epoch 24 | loss: 0.38428 | val_0_auc: 0.9542  |  0:02:08s\n",
            "epoch 25 | loss: 0.37283 | val_0_auc: 0.95131 |  0:02:13s\n",
            "epoch 26 | loss: 0.37755 | val_0_auc: 0.9561  |  0:02:18s\n",
            "epoch 27 | loss: 0.36626 | val_0_auc: 0.9506  |  0:02:23s\n",
            "epoch 28 | loss: 0.38427 | val_0_auc: 0.95375 |  0:02:28s\n",
            "epoch 29 | loss: 0.36455 | val_0_auc: 0.95514 |  0:02:34s\n",
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.95771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:43:06,189] Trial 12 finished with value: 0.9577105201340207 and parameters: {'n_d': 53, 'n_a': 44, 'n_steps': 8, 'gamma': 0.14565248402286335, 'momentum': 0.4083464097642313, 'lambda_sparse': 0.07880962509100795, 'lr': 0.028690877422704295, 'weight_decay': 1.4206666505548226e-05}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.77445 | val_0_auc: 0.52108 |  0:00:02s\n",
            "epoch 1  | loss: 0.61952 | val_0_auc: 0.64221 |  0:00:05s\n",
            "epoch 2  | loss: 0.57191 | val_0_auc: 0.73156 |  0:00:07s\n",
            "epoch 3  | loss: 0.54679 | val_0_auc: 0.81428 |  0:00:11s\n",
            "epoch 4  | loss: 0.52425 | val_0_auc: 0.8377  |  0:00:14s\n",
            "epoch 5  | loss: 0.53055 | val_0_auc: 0.84466 |  0:00:16s\n",
            "epoch 6  | loss: 0.52373 | val_0_auc: 0.84594 |  0:00:19s\n",
            "epoch 7  | loss: 0.51998 | val_0_auc: 0.87948 |  0:00:22s\n",
            "epoch 8  | loss: 0.47375 | val_0_auc: 0.89729 |  0:00:24s\n",
            "epoch 9  | loss: 0.47268 | val_0_auc: 0.87517 |  0:00:27s\n",
            "epoch 10 | loss: 0.4786  | val_0_auc: 0.82587 |  0:00:29s\n",
            "epoch 11 | loss: 0.48734 | val_0_auc: 0.89469 |  0:00:32s\n",
            "epoch 12 | loss: 0.47029 | val_0_auc: 0.85831 |  0:00:35s\n",
            "epoch 13 | loss: 0.48118 | val_0_auc: 0.88885 |  0:00:37s\n",
            "epoch 14 | loss: 0.47917 | val_0_auc: 0.85232 |  0:00:39s\n",
            "epoch 15 | loss: 0.48886 | val_0_auc: 0.87177 |  0:00:42s\n",
            "epoch 16 | loss: 0.45897 | val_0_auc: 0.91025 |  0:00:44s\n",
            "epoch 17 | loss: 0.4342  | val_0_auc: 0.90603 |  0:00:47s\n",
            "epoch 18 | loss: 0.45124 | val_0_auc: 0.9035  |  0:00:50s\n",
            "epoch 19 | loss: 0.44679 | val_0_auc: 0.92034 |  0:00:52s\n",
            "epoch 20 | loss: 0.40744 | val_0_auc: 0.91427 |  0:00:55s\n",
            "epoch 21 | loss: 0.40936 | val_0_auc: 0.92315 |  0:00:58s\n",
            "epoch 22 | loss: 0.40338 | val_0_auc: 0.92759 |  0:01:01s\n",
            "epoch 23 | loss: 0.42017 | val_0_auc: 0.88721 |  0:01:03s\n",
            "epoch 24 | loss: 0.43231 | val_0_auc: 0.91752 |  0:01:06s\n",
            "epoch 25 | loss: 0.4143  | val_0_auc: 0.9377  |  0:01:09s\n",
            "epoch 26 | loss: 0.38464 | val_0_auc: 0.93545 |  0:01:12s\n",
            "epoch 27 | loss: 0.38522 | val_0_auc: 0.92821 |  0:01:14s\n",
            "epoch 28 | loss: 0.3856  | val_0_auc: 0.936   |  0:01:17s\n",
            "epoch 29 | loss: 0.39029 | val_0_auc: 0.92025 |  0:01:19s\n",
            "epoch 30 | loss: 0.43647 | val_0_auc: 0.89479 |  0:01:22s\n",
            "epoch 31 | loss: 0.42184 | val_0_auc: 0.92284 |  0:01:25s\n",
            "epoch 32 | loss: 0.39324 | val_0_auc: 0.92236 |  0:01:28s\n",
            "epoch 33 | loss: 0.40328 | val_0_auc: 0.91199 |  0:01:31s\n",
            "epoch 34 | loss: 0.40762 | val_0_auc: 0.90593 |  0:01:33s\n",
            "epoch 35 | loss: 0.39538 | val_0_auc: 0.93267 |  0:01:37s\n",
            "\n",
            "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.9377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:44:44,861] Trial 13 finished with value: 0.9377001347625582 and parameters: {'n_d': 40, 'n_a': 27, 'n_steps': 4, 'gamma': 0.9144812252970839, 'momentum': 0.18718480297333834, 'lambda_sparse': 0.04297026680808199, 'lr': 0.0328321540944076, 'weight_decay': 1.0187413604070002e-06}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.44552 | val_0_auc: 0.55926 |  0:00:05s\n",
            "epoch 1  | loss: 0.64851 | val_0_auc: 0.59838 |  0:00:12s\n",
            "epoch 2  | loss: 0.65788 | val_0_auc: 0.64203 |  0:00:18s\n",
            "epoch 3  | loss: 0.64709 | val_0_auc: 0.63107 |  0:00:25s\n",
            "epoch 4  | loss: 0.63687 | val_0_auc: 0.71747 |  0:00:31s\n",
            "epoch 5  | loss: 0.6244  | val_0_auc: 0.73139 |  0:00:39s\n",
            "epoch 6  | loss: 0.61158 | val_0_auc: 0.72243 |  0:00:45s\n",
            "epoch 7  | loss: 0.64248 | val_0_auc: 0.70777 |  0:00:50s\n",
            "epoch 8  | loss: 0.62848 | val_0_auc: 0.72353 |  0:00:56s\n",
            "epoch 9  | loss: 0.6449  | val_0_auc: 0.75163 |  0:01:02s\n",
            "epoch 10 | loss: 0.62581 | val_0_auc: 0.73794 |  0:01:08s\n",
            "epoch 11 | loss: 0.616   | val_0_auc: 0.77047 |  0:01:14s\n",
            "epoch 12 | loss: 0.59807 | val_0_auc: 0.75505 |  0:01:20s\n",
            "epoch 13 | loss: 0.59867 | val_0_auc: 0.76493 |  0:01:26s\n",
            "epoch 14 | loss: 0.60033 | val_0_auc: 0.47469 |  0:01:33s\n",
            "epoch 15 | loss: 0.59168 | val_0_auc: 0.7958  |  0:01:39s\n",
            "epoch 16 | loss: 0.56987 | val_0_auc: 0.76725 |  0:01:44s\n",
            "epoch 17 | loss: 0.58549 | val_0_auc: 0.77896 |  0:01:50s\n",
            "epoch 18 | loss: 0.58356 | val_0_auc: 0.77917 |  0:01:56s\n",
            "epoch 19 | loss: 0.58622 | val_0_auc: 0.80037 |  0:02:01s\n",
            "epoch 20 | loss: 0.60782 | val_0_auc: 0.75761 |  0:02:07s\n",
            "epoch 21 | loss: 0.59516 | val_0_auc: 0.59121 |  0:02:14s\n",
            "epoch 22 | loss: 0.58679 | val_0_auc: 0.80967 |  0:02:20s\n",
            "epoch 23 | loss: 0.57008 | val_0_auc: 0.8032  |  0:02:25s\n",
            "epoch 24 | loss: 0.58298 | val_0_auc: 0.77044 |  0:02:32s\n",
            "epoch 25 | loss: 0.5638  | val_0_auc: 0.80812 |  0:02:38s\n",
            "epoch 26 | loss: 0.56827 | val_0_auc: 0.81671 |  0:02:45s\n",
            "epoch 27 | loss: 0.5494  | val_0_auc: 0.7709  |  0:02:51s\n",
            "epoch 28 | loss: 0.54829 | val_0_auc: 0.8116  |  0:02:57s\n",
            "epoch 29 | loss: 0.52459 | val_0_auc: 0.84179 |  0:03:03s\n",
            "epoch 30 | loss: 0.52591 | val_0_auc: 0.84275 |  0:03:09s\n",
            "epoch 31 | loss: 0.52168 | val_0_auc: 0.82564 |  0:03:16s\n",
            "epoch 32 | loss: 0.5274  | val_0_auc: 0.85363 |  0:03:23s\n",
            "epoch 33 | loss: 0.51294 | val_0_auc: 0.83823 |  0:03:30s\n",
            "epoch 34 | loss: 0.50709 | val_0_auc: 0.74348 |  0:03:38s\n",
            "epoch 35 | loss: 0.51782 | val_0_auc: 0.65174 |  0:03:45s\n",
            "epoch 36 | loss: 0.50205 | val_0_auc: 0.83826 |  0:03:52s\n",
            "epoch 37 | loss: 0.47065 | val_0_auc: 0.86649 |  0:03:59s\n",
            "epoch 38 | loss: 0.46493 | val_0_auc: 0.89094 |  0:04:06s\n",
            "epoch 39 | loss: 0.46149 | val_0_auc: 0.86908 |  0:04:14s\n",
            "epoch 40 | loss: 0.44802 | val_0_auc: 0.77741 |  0:04:21s\n",
            "epoch 41 | loss: 0.44196 | val_0_auc: 0.84424 |  0:04:28s\n",
            "epoch 42 | loss: 0.43564 | val_0_auc: 0.88639 |  0:04:36s\n",
            "epoch 43 | loss: 0.42559 | val_0_auc: 0.90664 |  0:04:43s\n",
            "epoch 44 | loss: 0.41998 | val_0_auc: 0.85421 |  0:04:52s\n",
            "epoch 45 | loss: 0.44399 | val_0_auc: 0.8963  |  0:05:00s\n",
            "epoch 46 | loss: 0.41458 | val_0_auc: 0.87947 |  0:05:07s\n",
            "epoch 47 | loss: 0.41176 | val_0_auc: 0.81128 |  0:05:15s\n",
            "epoch 48 | loss: 0.40416 | val_0_auc: 0.87308 |  0:05:23s\n",
            "epoch 49 | loss: 0.41731 | val_0_auc: 0.90022 |  0:05:32s\n",
            "epoch 50 | loss: 0.42391 | val_0_auc: 0.91713 |  0:05:40s\n",
            "epoch 51 | loss: 0.42221 | val_0_auc: 0.89099 |  0:05:48s\n",
            "epoch 52 | loss: 0.42418 | val_0_auc: 0.90846 |  0:05:56s\n",
            "epoch 53 | loss: 0.38752 | val_0_auc: 0.91698 |  0:06:05s\n",
            "epoch 54 | loss: 0.408   | val_0_auc: 0.70625 |  0:06:13s\n",
            "epoch 55 | loss: 0.40055 | val_0_auc: 0.88086 |  0:06:20s\n",
            "epoch 56 | loss: 0.41942 | val_0_auc: 0.90157 |  0:06:29s\n",
            "epoch 57 | loss: 0.39948 | val_0_auc: 0.90569 |  0:06:37s\n",
            "epoch 58 | loss: 0.4     | val_0_auc: 0.84046 |  0:06:46s\n",
            "epoch 59 | loss: 0.40262 | val_0_auc: 0.91592 |  0:06:54s\n",
            "epoch 60 | loss: 0.40711 | val_0_auc: 0.91426 |  0:07:03s\n",
            "\n",
            "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_auc = 0.91713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:51:53,670] Trial 14 finished with value: 0.9171333902056055 and parameters: {'n_d': 56, 'n_a': 30, 'n_steps': 10, 'gamma': 1.410612533819618, 'momentum': 0.4121043796363292, 'lambda_sparse': 0.06620884748189071, 'lr': 0.09686718778642563, 'weight_decay': 7.687874094297746e-05}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.92359 | val_0_auc: 0.54085 |  0:00:04s\n",
            "epoch 1  | loss: 0.70329 | val_0_auc: 0.59923 |  0:00:09s\n",
            "epoch 2  | loss: 0.59037 | val_0_auc: 0.76623 |  0:00:13s\n",
            "epoch 3  | loss: 0.56553 | val_0_auc: 0.80334 |  0:00:18s\n",
            "epoch 4  | loss: 0.53998 | val_0_auc: 0.84466 |  0:00:23s\n",
            "epoch 5  | loss: 0.52207 | val_0_auc: 0.85825 |  0:00:28s\n",
            "epoch 6  | loss: 0.51797 | val_0_auc: 0.8822  |  0:00:33s\n",
            "epoch 7  | loss: 0.51176 | val_0_auc: 0.88067 |  0:00:38s\n",
            "epoch 8  | loss: 0.49009 | val_0_auc: 0.90048 |  0:00:42s\n",
            "epoch 9  | loss: 0.47402 | val_0_auc: 0.90199 |  0:00:47s\n",
            "epoch 10 | loss: 0.46756 | val_0_auc: 0.90957 |  0:00:51s\n",
            "epoch 11 | loss: 0.46257 | val_0_auc: 0.89901 |  0:00:55s\n",
            "epoch 12 | loss: 0.44925 | val_0_auc: 0.91443 |  0:01:00s\n",
            "epoch 13 | loss: 0.43821 | val_0_auc: 0.91751 |  0:01:04s\n",
            "epoch 14 | loss: 0.43111 | val_0_auc: 0.91286 |  0:01:08s\n",
            "epoch 15 | loss: 0.44252 | val_0_auc: 0.91985 |  0:01:13s\n",
            "epoch 16 | loss: 0.42214 | val_0_auc: 0.91486 |  0:01:18s\n",
            "epoch 17 | loss: 0.41629 | val_0_auc: 0.9195  |  0:01:23s\n",
            "epoch 18 | loss: 0.42861 | val_0_auc: 0.92061 |  0:01:28s\n",
            "epoch 19 | loss: 0.41455 | val_0_auc: 0.92527 |  0:01:33s\n",
            "epoch 20 | loss: 0.41595 | val_0_auc: 0.92041 |  0:01:37s\n",
            "epoch 21 | loss: 0.40628 | val_0_auc: 0.92671 |  0:01:42s\n",
            "epoch 22 | loss: 0.40581 | val_0_auc: 0.93084 |  0:01:47s\n",
            "epoch 23 | loss: 0.39073 | val_0_auc: 0.92766 |  0:01:51s\n",
            "epoch 24 | loss: 0.4135  | val_0_auc: 0.91949 |  0:01:56s\n",
            "epoch 25 | loss: 0.3946  | val_0_auc: 0.93239 |  0:02:02s\n",
            "epoch 26 | loss: 0.38382 | val_0_auc: 0.93308 |  0:02:06s\n",
            "epoch 27 | loss: 0.37996 | val_0_auc: 0.93242 |  0:02:11s\n",
            "epoch 28 | loss: 0.38071 | val_0_auc: 0.92971 |  0:02:15s\n",
            "epoch 29 | loss: 0.37019 | val_0_auc: 0.94083 |  0:02:20s\n",
            "epoch 30 | loss: 0.35896 | val_0_auc: 0.94271 |  0:02:26s\n",
            "epoch 31 | loss: 0.37051 | val_0_auc: 0.93883 |  0:02:32s\n",
            "epoch 32 | loss: 0.35832 | val_0_auc: 0.94703 |  0:02:38s\n",
            "epoch 33 | loss: 0.35956 | val_0_auc: 0.94545 |  0:02:44s\n",
            "epoch 34 | loss: 0.37156 | val_0_auc: 0.94101 |  0:02:51s\n",
            "epoch 35 | loss: 0.36429 | val_0_auc: 0.9438  |  0:02:57s\n",
            "epoch 36 | loss: 0.35428 | val_0_auc: 0.94287 |  0:03:03s\n",
            "epoch 37 | loss: 0.34703 | val_0_auc: 0.94539 |  0:03:09s\n",
            "epoch 38 | loss: 0.35109 | val_0_auc: 0.94301 |  0:03:16s\n",
            "epoch 39 | loss: 0.34804 | val_0_auc: 0.94989 |  0:03:22s\n",
            "epoch 40 | loss: 0.33906 | val_0_auc: 0.94534 |  0:03:29s\n",
            "epoch 41 | loss: 0.34558 | val_0_auc: 0.93691 |  0:03:35s\n",
            "epoch 42 | loss: 0.34886 | val_0_auc: 0.94676 |  0:03:42s\n",
            "epoch 43 | loss: 0.34846 | val_0_auc: 0.94513 |  0:03:48s\n",
            "epoch 44 | loss: 0.35483 | val_0_auc: 0.92885 |  0:03:55s\n",
            "epoch 45 | loss: 0.35431 | val_0_auc: 0.94278 |  0:04:02s\n",
            "epoch 46 | loss: 0.35071 | val_0_auc: 0.94181 |  0:04:08s\n",
            "epoch 47 | loss: 0.36446 | val_0_auc: 0.9363  |  0:04:15s\n",
            "epoch 48 | loss: 0.34665 | val_0_auc: 0.94641 |  0:04:21s\n",
            "epoch 49 | loss: 0.34301 | val_0_auc: 0.94478 |  0:04:28s\n",
            "\n",
            "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.94989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 05:56:25,627] Trial 15 finished with value: 0.949893673577884 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 6, 'gamma': 0.8379813976316084, 'momentum': 0.18063194043050526, 'lambda_sparse': 0.03619986084432182, 'lr': 0.008548637768392582, 'weight_decay': 1.1627199371441654e-05}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.09256 | val_0_auc: 0.59663 |  0:00:04s\n",
            "epoch 1  | loss: 0.675   | val_0_auc: 0.65439 |  0:00:10s\n",
            "epoch 2  | loss: 0.62112 | val_0_auc: 0.70995 |  0:00:14s\n",
            "epoch 3  | loss: 0.61422 | val_0_auc: 0.72306 |  0:00:20s\n",
            "epoch 4  | loss: 0.61971 | val_0_auc: 0.74463 |  0:00:25s\n",
            "epoch 5  | loss: 0.60981 | val_0_auc: 0.74732 |  0:00:29s\n",
            "epoch 6  | loss: 0.61047 | val_0_auc: 0.76329 |  0:00:35s\n",
            "epoch 7  | loss: 0.60986 | val_0_auc: 0.75775 |  0:00:40s\n",
            "epoch 8  | loss: 0.60445 | val_0_auc: 0.75948 |  0:00:45s\n",
            "epoch 9  | loss: 0.6069  | val_0_auc: 0.7501  |  0:00:50s\n",
            "epoch 10 | loss: 0.60687 | val_0_auc: 0.77837 |  0:00:55s\n",
            "epoch 11 | loss: 0.59965 | val_0_auc: 0.76997 |  0:01:00s\n",
            "epoch 12 | loss: 0.59107 | val_0_auc: 0.77353 |  0:01:05s\n",
            "epoch 13 | loss: 0.58508 | val_0_auc: 0.77351 |  0:01:10s\n",
            "epoch 14 | loss: 0.59318 | val_0_auc: 0.78592 |  0:01:15s\n",
            "epoch 15 | loss: 0.59007 | val_0_auc: 0.76404 |  0:01:19s\n",
            "epoch 16 | loss: 0.58699 | val_0_auc: 0.76536 |  0:01:26s\n",
            "epoch 17 | loss: 0.57456 | val_0_auc: 0.78243 |  0:01:30s\n",
            "epoch 18 | loss: 0.57589 | val_0_auc: 0.79592 |  0:01:36s\n",
            "epoch 19 | loss: 0.56455 | val_0_auc: 0.80466 |  0:01:41s\n",
            "epoch 20 | loss: 0.54219 | val_0_auc: 0.82717 |  0:01:46s\n",
            "epoch 21 | loss: 0.55826 | val_0_auc: 0.81008 |  0:01:51s\n",
            "epoch 22 | loss: 0.54644 | val_0_auc: 0.78629 |  0:01:56s\n",
            "epoch 23 | loss: 0.56469 | val_0_auc: 0.81414 |  0:02:02s\n",
            "epoch 24 | loss: 0.52767 | val_0_auc: 0.84239 |  0:02:07s\n",
            "epoch 25 | loss: 0.51001 | val_0_auc: 0.85572 |  0:02:13s\n",
            "epoch 26 | loss: 0.49738 | val_0_auc: 0.82691 |  0:02:18s\n",
            "epoch 27 | loss: 0.50993 | val_0_auc: 0.85481 |  0:02:23s\n",
            "epoch 28 | loss: 0.49534 | val_0_auc: 0.84972 |  0:02:29s\n",
            "epoch 29 | loss: 0.48645 | val_0_auc: 0.83229 |  0:02:34s\n",
            "epoch 30 | loss: 0.46795 | val_0_auc: 0.89118 |  0:02:40s\n",
            "epoch 31 | loss: 0.42629 | val_0_auc: 0.88834 |  0:02:46s\n",
            "epoch 32 | loss: 0.42624 | val_0_auc: 0.90226 |  0:02:53s\n",
            "epoch 33 | loss: 0.41578 | val_0_auc: 0.9121  |  0:02:59s\n",
            "epoch 34 | loss: 0.40218 | val_0_auc: 0.90673 |  0:03:06s\n",
            "epoch 35 | loss: 0.39744 | val_0_auc: 0.91588 |  0:03:13s\n",
            "epoch 36 | loss: 0.38998 | val_0_auc: 0.91971 |  0:03:20s\n",
            "epoch 37 | loss: 0.40356 | val_0_auc: 0.91639 |  0:03:27s\n",
            "epoch 38 | loss: 0.39269 | val_0_auc: 0.89872 |  0:03:33s\n",
            "epoch 39 | loss: 0.3961  | val_0_auc: 0.91637 |  0:03:41s\n",
            "epoch 40 | loss: 0.37808 | val_0_auc: 0.9001  |  0:03:47s\n",
            "epoch 41 | loss: 0.38609 | val_0_auc: 0.91755 |  0:03:55s\n",
            "epoch 42 | loss: 0.38672 | val_0_auc: 0.92903 |  0:04:02s\n",
            "epoch 43 | loss: 0.38235 | val_0_auc: 0.8782  |  0:04:09s\n",
            "epoch 44 | loss: 0.37623 | val_0_auc: 0.92074 |  0:04:15s\n",
            "epoch 45 | loss: 0.37736 | val_0_auc: 0.91543 |  0:04:22s\n",
            "epoch 46 | loss: 0.36956 | val_0_auc: 0.92294 |  0:04:28s\n",
            "epoch 47 | loss: 0.37739 | val_0_auc: 0.93102 |  0:04:35s\n",
            "epoch 48 | loss: 0.36073 | val_0_auc: 0.91056 |  0:04:41s\n",
            "epoch 49 | loss: 0.36978 | val_0_auc: 0.92701 |  0:04:48s\n",
            "epoch 50 | loss: 0.36421 | val_0_auc: 0.93213 |  0:04:55s\n",
            "epoch 51 | loss: 0.36523 | val_0_auc: 0.93071 |  0:05:02s\n",
            "epoch 52 | loss: 0.37079 | val_0_auc: 0.9243  |  0:05:10s\n",
            "epoch 53 | loss: 0.35599 | val_0_auc: 0.93457 |  0:05:18s\n",
            "epoch 54 | loss: 0.35944 | val_0_auc: 0.9312  |  0:05:26s\n",
            "epoch 55 | loss: 0.35902 | val_0_auc: 0.93325 |  0:05:34s\n",
            "epoch 56 | loss: 0.35371 | val_0_auc: 0.92623 |  0:05:42s\n",
            "epoch 57 | loss: 0.35948 | val_0_auc: 0.92956 |  0:05:51s\n",
            "epoch 58 | loss: 0.36285 | val_0_auc: 0.92318 |  0:05:59s\n",
            "epoch 59 | loss: 0.35537 | val_0_auc: 0.9366  |  0:06:09s\n",
            "epoch 60 | loss: 0.35777 | val_0_auc: 0.93707 |  0:06:18s\n",
            "epoch 61 | loss: 0.36583 | val_0_auc: 0.93683 |  0:06:27s\n",
            "epoch 62 | loss: 0.35776 | val_0_auc: 0.93838 |  0:06:36s\n",
            "epoch 63 | loss: 0.35768 | val_0_auc: 0.91462 |  0:06:45s\n",
            "epoch 64 | loss: 0.38152 | val_0_auc: 0.9207  |  0:06:54s\n",
            "epoch 65 | loss: 0.36357 | val_0_auc: 0.93273 |  0:07:03s\n",
            "epoch 66 | loss: 0.35749 | val_0_auc: 0.93478 |  0:07:13s\n",
            "epoch 67 | loss: 0.35711 | val_0_auc: 0.93604 |  0:07:23s\n",
            "epoch 68 | loss: 0.34563 | val_0_auc: 0.91956 |  0:07:33s\n",
            "epoch 69 | loss: 0.35935 | val_0_auc: 0.94041 |  0:07:43s\n",
            "epoch 70 | loss: 0.34835 | val_0_auc: 0.93407 |  0:07:54s\n",
            "epoch 71 | loss: 0.35737 | val_0_auc: 0.93556 |  0:08:05s\n",
            "epoch 72 | loss: 0.35671 | val_0_auc: 0.93441 |  0:08:17s\n",
            "epoch 73 | loss: 0.35273 | val_0_auc: 0.93575 |  0:08:28s\n",
            "epoch 74 | loss: 0.34877 | val_0_auc: 0.9383  |  0:08:40s\n",
            "epoch 75 | loss: 0.35172 | val_0_auc: 0.92813 |  0:08:52s\n",
            "epoch 76 | loss: 0.34832 | val_0_auc: 0.93944 |  0:09:04s\n",
            "epoch 77 | loss: 0.34787 | val_0_auc: 0.91849 |  0:09:16s\n",
            "epoch 78 | loss: 0.35039 | val_0_auc: 0.93924 |  0:09:29s\n",
            "epoch 79 | loss: 0.35429 | val_0_auc: 0.91852 |  0:09:41s\n",
            "\n",
            "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_auc = 0.94041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:06:14,348] Trial 16 finished with value: 0.9404123857918227 and parameters: {'n_d': 51, 'n_a': 44, 'n_steps': 8, 'gamma': 1.5011901112099317, 'momentum': 0.24776400893147724, 'lambda_sparse': 0.08876653705122431, 'lr': 0.03262756663475054, 'weight_decay': 8.690617158106397e-05}. Best is trial 3 with value: 0.9627007529394311.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.05611 | val_0_auc: 0.41695 |  0:00:03s\n",
            "epoch 1  | loss: 0.57527 | val_0_auc: 0.76756 |  0:00:05s\n",
            "epoch 2  | loss: 0.50556 | val_0_auc: 0.86631 |  0:00:08s\n",
            "epoch 3  | loss: 0.47754 | val_0_auc: 0.92462 |  0:00:11s\n",
            "epoch 4  | loss: 0.44974 | val_0_auc: 0.9381  |  0:00:13s\n",
            "epoch 5  | loss: 0.44978 | val_0_auc: 0.94003 |  0:00:17s\n",
            "epoch 6  | loss: 0.42915 | val_0_auc: 0.94586 |  0:00:19s\n",
            "epoch 7  | loss: 0.42279 | val_0_auc: 0.94531 |  0:00:22s\n",
            "epoch 8  | loss: 0.40793 | val_0_auc: 0.94588 |  0:00:24s\n",
            "epoch 9  | loss: 0.40854 | val_0_auc: 0.94867 |  0:00:27s\n",
            "epoch 10 | loss: 0.38865 | val_0_auc: 0.94567 |  0:00:30s\n",
            "epoch 11 | loss: 0.39362 | val_0_auc: 0.95208 |  0:00:32s\n",
            "epoch 12 | loss: 0.38935 | val_0_auc: 0.94763 |  0:00:35s\n",
            "epoch 13 | loss: 0.38822 | val_0_auc: 0.95029 |  0:00:38s\n",
            "epoch 14 | loss: 0.37705 | val_0_auc: 0.95003 |  0:00:42s\n",
            "epoch 15 | loss: 0.3731  | val_0_auc: 0.95373 |  0:00:45s\n",
            "epoch 16 | loss: 0.37218 | val_0_auc: 0.95587 |  0:00:47s\n",
            "epoch 17 | loss: 0.36201 | val_0_auc: 0.953   |  0:00:50s\n",
            "epoch 18 | loss: 0.36836 | val_0_auc: 0.95389 |  0:00:54s\n",
            "epoch 19 | loss: 0.35695 | val_0_auc: 0.95422 |  0:00:56s\n",
            "epoch 20 | loss: 0.36082 | val_0_auc: 0.95933 |  0:00:59s\n",
            "epoch 21 | loss: 0.35325 | val_0_auc: 0.95751 |  0:01:02s\n",
            "epoch 22 | loss: 0.3562  | val_0_auc: 0.95392 |  0:01:05s\n",
            "epoch 23 | loss: 0.3598  | val_0_auc: 0.94825 |  0:01:08s\n",
            "epoch 24 | loss: 0.35299 | val_0_auc: 0.95655 |  0:01:10s\n",
            "epoch 25 | loss: 0.34129 | val_0_auc: 0.96116 |  0:01:13s\n",
            "epoch 26 | loss: 0.35773 | val_0_auc: 0.95312 |  0:01:16s\n",
            "epoch 27 | loss: 0.34731 | val_0_auc: 0.9632  |  0:01:19s\n",
            "epoch 28 | loss: 0.33823 | val_0_auc: 0.95816 |  0:01:22s\n",
            "epoch 29 | loss: 0.34245 | val_0_auc: 0.95368 |  0:01:25s\n",
            "epoch 30 | loss: 0.34029 | val_0_auc: 0.95589 |  0:01:28s\n",
            "epoch 31 | loss: 0.34526 | val_0_auc: 0.95955 |  0:01:31s\n",
            "epoch 32 | loss: 0.32916 | val_0_auc: 0.95865 |  0:01:34s\n",
            "epoch 33 | loss: 0.33187 | val_0_auc: 0.95922 |  0:01:37s\n",
            "epoch 34 | loss: 0.32407 | val_0_auc: 0.96336 |  0:01:40s\n",
            "epoch 35 | loss: 0.31595 | val_0_auc: 0.96613 |  0:01:43s\n",
            "epoch 36 | loss: 0.32443 | val_0_auc: 0.9653  |  0:01:46s\n",
            "epoch 37 | loss: 0.31561 | val_0_auc: 0.95956 |  0:01:49s\n",
            "epoch 38 | loss: 0.32954 | val_0_auc: 0.95815 |  0:01:52s\n",
            "epoch 39 | loss: 0.31718 | val_0_auc: 0.96531 |  0:01:56s\n",
            "epoch 40 | loss: 0.32074 | val_0_auc: 0.96458 |  0:01:59s\n",
            "epoch 41 | loss: 0.31209 | val_0_auc: 0.96509 |  0:02:02s\n",
            "epoch 42 | loss: 0.31353 | val_0_auc: 0.96594 |  0:02:04s\n",
            "epoch 43 | loss: 0.30295 | val_0_auc: 0.96515 |  0:02:08s\n",
            "epoch 44 | loss: 0.31087 | val_0_auc: 0.96571 |  0:02:11s\n",
            "epoch 45 | loss: 0.30854 | val_0_auc: 0.96534 |  0:02:14s\n",
            "\n",
            "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.96613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:08:30,962] Trial 17 finished with value: 0.9661254528145593 and parameters: {'n_d': 42, 'n_a': 48, 'n_steps': 4, 'gamma': 0.13921205251232993, 'momentum': 0.10534929940186938, 'lambda_sparse': 0.055235495517907914, 'lr': 0.001801434503690883, 'weight_decay': 2.3304040836744913e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.9134  | val_0_auc: 0.50725 |  0:00:02s\n",
            "epoch 1  | loss: 0.59952 | val_0_auc: 0.70441 |  0:00:05s\n",
            "epoch 2  | loss: 0.51886 | val_0_auc: 0.85624 |  0:00:07s\n",
            "epoch 3  | loss: 0.48627 | val_0_auc: 0.88799 |  0:00:09s\n",
            "epoch 4  | loss: 0.45431 | val_0_auc: 0.91893 |  0:00:12s\n",
            "epoch 5  | loss: 0.44079 | val_0_auc: 0.92166 |  0:00:15s\n",
            "epoch 6  | loss: 0.42322 | val_0_auc: 0.92715 |  0:00:18s\n",
            "epoch 7  | loss: 0.41505 | val_0_auc: 0.93122 |  0:00:20s\n",
            "epoch 8  | loss: 0.39478 | val_0_auc: 0.93701 |  0:00:23s\n",
            "epoch 9  | loss: 0.39746 | val_0_auc: 0.93423 |  0:00:25s\n",
            "epoch 10 | loss: 0.39193 | val_0_auc: 0.93704 |  0:00:29s\n",
            "epoch 11 | loss: 0.38703 | val_0_auc: 0.93915 |  0:00:32s\n",
            "epoch 12 | loss: 0.37709 | val_0_auc: 0.94193 |  0:00:35s\n",
            "epoch 13 | loss: 0.38206 | val_0_auc: 0.9454  |  0:00:37s\n",
            "epoch 14 | loss: 0.38229 | val_0_auc: 0.94607 |  0:00:39s\n",
            "epoch 15 | loss: 0.36939 | val_0_auc: 0.94803 |  0:00:42s\n",
            "epoch 16 | loss: 0.36684 | val_0_auc: 0.94653 |  0:00:44s\n",
            "epoch 17 | loss: 0.35817 | val_0_auc: 0.94759 |  0:00:47s\n",
            "epoch 18 | loss: 0.35241 | val_0_auc: 0.95051 |  0:00:49s\n",
            "epoch 19 | loss: 0.34741 | val_0_auc: 0.9503  |  0:00:51s\n",
            "epoch 20 | loss: 0.35344 | val_0_auc: 0.9506  |  0:00:53s\n",
            "epoch 21 | loss: 0.34729 | val_0_auc: 0.95331 |  0:00:56s\n",
            "epoch 22 | loss: 0.34841 | val_0_auc: 0.95421 |  0:00:58s\n",
            "epoch 23 | loss: 0.33223 | val_0_auc: 0.95147 |  0:01:00s\n",
            "epoch 24 | loss: 0.3353  | val_0_auc: 0.95322 |  0:01:03s\n",
            "epoch 25 | loss: 0.33625 | val_0_auc: 0.95676 |  0:01:05s\n",
            "epoch 26 | loss: 0.33791 | val_0_auc: 0.95535 |  0:01:08s\n",
            "epoch 27 | loss: 0.33403 | val_0_auc: 0.94768 |  0:01:10s\n",
            "epoch 28 | loss: 0.33762 | val_0_auc: 0.95822 |  0:01:13s\n",
            "epoch 29 | loss: 0.32353 | val_0_auc: 0.95912 |  0:01:15s\n",
            "epoch 30 | loss: 0.31925 | val_0_auc: 0.95824 |  0:01:18s\n",
            "epoch 31 | loss: 0.32466 | val_0_auc: 0.95859 |  0:01:21s\n",
            "epoch 32 | loss: 0.31698 | val_0_auc: 0.95799 |  0:01:23s\n",
            "epoch 33 | loss: 0.31427 | val_0_auc: 0.95789 |  0:01:26s\n",
            "epoch 34 | loss: 0.31708 | val_0_auc: 0.95729 |  0:01:28s\n",
            "epoch 35 | loss: 0.31198 | val_0_auc: 0.96164 |  0:01:32s\n",
            "epoch 36 | loss: 0.3151  | val_0_auc: 0.9595  |  0:01:35s\n",
            "epoch 37 | loss: 0.30472 | val_0_auc: 0.96167 |  0:01:37s\n",
            "epoch 38 | loss: 0.30286 | val_0_auc: 0.96306 |  0:01:40s\n",
            "epoch 39 | loss: 0.30689 | val_0_auc: 0.96099 |  0:01:43s\n",
            "epoch 40 | loss: 0.30734 | val_0_auc: 0.96303 |  0:01:46s\n",
            "epoch 41 | loss: 0.29348 | val_0_auc: 0.96206 |  0:01:48s\n",
            "epoch 42 | loss: 0.30571 | val_0_auc: 0.96006 |  0:01:51s\n",
            "epoch 43 | loss: 0.30357 | val_0_auc: 0.96092 |  0:01:53s\n",
            "epoch 44 | loss: 0.29235 | val_0_auc: 0.95594 |  0:01:56s\n",
            "epoch 45 | loss: 0.2971  | val_0_auc: 0.96168 |  0:01:59s\n",
            "epoch 46 | loss: 0.29635 | val_0_auc: 0.96282 |  0:02:01s\n",
            "epoch 47 | loss: 0.28287 | val_0_auc: 0.96297 |  0:02:04s\n",
            "epoch 48 | loss: 0.28559 | val_0_auc: 0.96428 |  0:02:07s\n",
            "epoch 49 | loss: 0.2885  | val_0_auc: 0.96174 |  0:02:10s\n",
            "epoch 50 | loss: 0.29391 | val_0_auc: 0.96146 |  0:02:13s\n",
            "epoch 51 | loss: 0.28479 | val_0_auc: 0.9619  |  0:02:15s\n",
            "epoch 52 | loss: 0.28025 | val_0_auc: 0.96584 |  0:02:18s\n",
            "epoch 53 | loss: 0.28184 | val_0_auc: 0.9659  |  0:02:21s\n",
            "epoch 54 | loss: 0.27885 | val_0_auc: 0.96163 |  0:02:24s\n",
            "epoch 55 | loss: 0.27397 | val_0_auc: 0.9604  |  0:02:27s\n",
            "epoch 56 | loss: 0.27025 | val_0_auc: 0.96313 |  0:02:29s\n",
            "epoch 57 | loss: 0.27694 | val_0_auc: 0.96427 |  0:02:32s\n",
            "epoch 58 | loss: 0.27562 | val_0_auc: 0.96474 |  0:02:35s\n",
            "epoch 59 | loss: 0.27505 | val_0_auc: 0.96047 |  0:02:38s\n",
            "epoch 60 | loss: 0.27405 | val_0_auc: 0.96134 |  0:02:41s\n",
            "epoch 61 | loss: 0.27613 | val_0_auc: 0.9657  |  0:02:44s\n",
            "epoch 62 | loss: 0.27833 | val_0_auc: 0.96516 |  0:02:47s\n",
            "epoch 63 | loss: 0.26534 | val_0_auc: 0.96408 |  0:02:50s\n",
            "\n",
            "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.9659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:11:22,953] Trial 18 finished with value: 0.9658967273716356 and parameters: {'n_d': 35, 'n_a': 28, 'n_steps': 4, 'gamma': 0.12798170697098754, 'momentum': 0.11896026755714201, 'lambda_sparse': 0.027837488394031756, 'lr': 0.001187439694151625, 'weight_decay': 5.526526875985477e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.79512 | val_0_auc: 0.61027 |  0:00:02s\n",
            "epoch 1  | loss: 0.61397 | val_0_auc: 0.71084 |  0:00:04s\n",
            "epoch 2  | loss: 0.55143 | val_0_auc: 0.8079  |  0:00:07s\n",
            "epoch 3  | loss: 0.52718 | val_0_auc: 0.86856 |  0:00:09s\n",
            "epoch 4  | loss: 0.50602 | val_0_auc: 0.87937 |  0:00:12s\n",
            "epoch 5  | loss: 0.48822 | val_0_auc: 0.90181 |  0:00:14s\n",
            "epoch 6  | loss: 0.46802 | val_0_auc: 0.91259 |  0:00:16s\n",
            "epoch 7  | loss: 0.45958 | val_0_auc: 0.9146  |  0:00:19s\n",
            "epoch 8  | loss: 0.44583 | val_0_auc: 0.92086 |  0:00:21s\n",
            "epoch 9  | loss: 0.43286 | val_0_auc: 0.91699 |  0:00:23s\n",
            "epoch 10 | loss: 0.42166 | val_0_auc: 0.92417 |  0:00:26s\n",
            "epoch 11 | loss: 0.41685 | val_0_auc: 0.92508 |  0:00:28s\n",
            "epoch 12 | loss: 0.40354 | val_0_auc: 0.93021 |  0:00:31s\n",
            "epoch 13 | loss: 0.4045  | val_0_auc: 0.94199 |  0:00:33s\n",
            "epoch 14 | loss: 0.39952 | val_0_auc: 0.94037 |  0:00:35s\n",
            "epoch 15 | loss: 0.40005 | val_0_auc: 0.94058 |  0:00:37s\n",
            "epoch 16 | loss: 0.39724 | val_0_auc: 0.94467 |  0:00:39s\n",
            "epoch 17 | loss: 0.38164 | val_0_auc: 0.94731 |  0:00:41s\n",
            "epoch 18 | loss: 0.37362 | val_0_auc: 0.94214 |  0:00:44s\n",
            "epoch 19 | loss: 0.39398 | val_0_auc: 0.94565 |  0:00:47s\n",
            "epoch 20 | loss: 0.37961 | val_0_auc: 0.94607 |  0:00:49s\n",
            "epoch 21 | loss: 0.37505 | val_0_auc: 0.94655 |  0:00:51s\n",
            "epoch 22 | loss: 0.37368 | val_0_auc: 0.94716 |  0:00:53s\n",
            "epoch 23 | loss: 0.3744  | val_0_auc: 0.94402 |  0:00:56s\n",
            "epoch 24 | loss: 0.36726 | val_0_auc: 0.94662 |  0:00:58s\n",
            "epoch 25 | loss: 0.36906 | val_0_auc: 0.94792 |  0:01:01s\n",
            "epoch 26 | loss: 0.36582 | val_0_auc: 0.94974 |  0:01:03s\n",
            "epoch 27 | loss: 0.36582 | val_0_auc: 0.9515  |  0:01:05s\n",
            "epoch 28 | loss: 0.36165 | val_0_auc: 0.9486  |  0:01:08s\n",
            "epoch 29 | loss: 0.36387 | val_0_auc: 0.94917 |  0:01:10s\n",
            "epoch 30 | loss: 0.35835 | val_0_auc: 0.94421 |  0:01:12s\n",
            "epoch 31 | loss: 0.35067 | val_0_auc: 0.95102 |  0:01:14s\n",
            "epoch 32 | loss: 0.34942 | val_0_auc: 0.9494  |  0:01:16s\n",
            "epoch 33 | loss: 0.35557 | val_0_auc: 0.95039 |  0:01:19s\n",
            "epoch 34 | loss: 0.35356 | val_0_auc: 0.95491 |  0:01:22s\n",
            "epoch 35 | loss: 0.34263 | val_0_auc: 0.95339 |  0:01:24s\n",
            "epoch 36 | loss: 0.33842 | val_0_auc: 0.95399 |  0:01:26s\n",
            "epoch 37 | loss: 0.34334 | val_0_auc: 0.95615 |  0:01:29s\n",
            "epoch 38 | loss: 0.32949 | val_0_auc: 0.95531 |  0:01:31s\n",
            "epoch 39 | loss: 0.34076 | val_0_auc: 0.95813 |  0:01:34s\n",
            "epoch 40 | loss: 0.34009 | val_0_auc: 0.95685 |  0:01:36s\n",
            "epoch 41 | loss: 0.33117 | val_0_auc: 0.95926 |  0:01:39s\n",
            "epoch 42 | loss: 0.32908 | val_0_auc: 0.95662 |  0:01:41s\n",
            "epoch 43 | loss: 0.33045 | val_0_auc: 0.95857 |  0:01:44s\n",
            "epoch 44 | loss: 0.3344  | val_0_auc: 0.95581 |  0:01:46s\n",
            "epoch 45 | loss: 0.34152 | val_0_auc: 0.96077 |  0:01:49s\n",
            "epoch 46 | loss: 0.34078 | val_0_auc: 0.95564 |  0:01:51s\n",
            "epoch 47 | loss: 0.32348 | val_0_auc: 0.95806 |  0:01:54s\n",
            "epoch 48 | loss: 0.33507 | val_0_auc: 0.95733 |  0:01:56s\n",
            "epoch 49 | loss: 0.32804 | val_0_auc: 0.95914 |  0:01:59s\n",
            "epoch 50 | loss: 0.32632 | val_0_auc: 0.95719 |  0:02:02s\n",
            "epoch 51 | loss: 0.31977 | val_0_auc: 0.95897 |  0:02:04s\n",
            "epoch 52 | loss: 0.32597 | val_0_auc: 0.95814 |  0:02:06s\n",
            "epoch 53 | loss: 0.33113 | val_0_auc: 0.95852 |  0:02:09s\n",
            "epoch 54 | loss: 0.32559 | val_0_auc: 0.96045 |  0:02:11s\n",
            "epoch 55 | loss: 0.32021 | val_0_auc: 0.95698 |  0:02:14s\n",
            "\n",
            "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_auc = 0.96077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:13:38,754] Trial 19 finished with value: 0.9607735865385805 and parameters: {'n_d': 36, 'n_a': 9, 'n_steps': 4, 'gamma': 0.12154885862596737, 'momentum': 0.09262834942616885, 'lambda_sparse': 0.0258661620490394, 'lr': 0.0012204552542616574, 'weight_decay': 6.628382868601062e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.80735 | val_0_auc: 0.52622 |  0:00:02s\n",
            "epoch 1  | loss: 0.62729 | val_0_auc: 0.62584 |  0:00:04s\n",
            "epoch 2  | loss: 0.57633 | val_0_auc: 0.77764 |  0:00:06s\n",
            "epoch 3  | loss: 0.54107 | val_0_auc: 0.83354 |  0:00:09s\n",
            "epoch 4  | loss: 0.53201 | val_0_auc: 0.868   |  0:00:11s\n",
            "epoch 5  | loss: 0.50792 | val_0_auc: 0.89632 |  0:00:14s\n",
            "epoch 6  | loss: 0.48299 | val_0_auc: 0.9115  |  0:00:16s\n",
            "epoch 7  | loss: 0.45366 | val_0_auc: 0.92033 |  0:00:18s\n",
            "epoch 8  | loss: 0.44056 | val_0_auc: 0.92465 |  0:00:20s\n",
            "epoch 9  | loss: 0.4447  | val_0_auc: 0.92469 |  0:00:23s\n",
            "epoch 10 | loss: 0.42737 | val_0_auc: 0.92133 |  0:00:26s\n",
            "epoch 11 | loss: 0.41454 | val_0_auc: 0.93067 |  0:00:28s\n",
            "epoch 12 | loss: 0.41127 | val_0_auc: 0.92862 |  0:00:30s\n",
            "epoch 13 | loss: 0.40453 | val_0_auc: 0.93963 |  0:00:33s\n",
            "epoch 14 | loss: 0.393   | val_0_auc: 0.94086 |  0:00:36s\n",
            "epoch 15 | loss: 0.38286 | val_0_auc: 0.93853 |  0:00:39s\n",
            "epoch 16 | loss: 0.38929 | val_0_auc: 0.93926 |  0:00:42s\n",
            "epoch 17 | loss: 0.37695 | val_0_auc: 0.93384 |  0:00:44s\n",
            "epoch 18 | loss: 0.37635 | val_0_auc: 0.93851 |  0:00:47s\n",
            "epoch 19 | loss: 0.37655 | val_0_auc: 0.94078 |  0:00:49s\n",
            "epoch 20 | loss: 0.36786 | val_0_auc: 0.94239 |  0:00:51s\n",
            "epoch 21 | loss: 0.35767 | val_0_auc: 0.94868 |  0:00:54s\n",
            "epoch 22 | loss: 0.36094 | val_0_auc: 0.94798 |  0:00:56s\n",
            "epoch 23 | loss: 0.35077 | val_0_auc: 0.94879 |  0:01:00s\n",
            "epoch 24 | loss: 0.34453 | val_0_auc: 0.94841 |  0:01:02s\n",
            "epoch 25 | loss: 0.3436  | val_0_auc: 0.94692 |  0:01:04s\n",
            "epoch 26 | loss: 0.3449  | val_0_auc: 0.95043 |  0:01:07s\n",
            "epoch 27 | loss: 0.337   | val_0_auc: 0.95472 |  0:01:09s\n",
            "epoch 28 | loss: 0.33828 | val_0_auc: 0.95185 |  0:01:12s\n",
            "epoch 29 | loss: 0.33772 | val_0_auc: 0.95128 |  0:01:14s\n",
            "epoch 30 | loss: 0.32727 | val_0_auc: 0.95456 |  0:01:17s\n",
            "epoch 31 | loss: 0.33083 | val_0_auc: 0.95035 |  0:01:19s\n",
            "epoch 32 | loss: 0.32279 | val_0_auc: 0.95344 |  0:01:22s\n",
            "epoch 33 | loss: 0.32322 | val_0_auc: 0.95015 |  0:01:25s\n",
            "epoch 34 | loss: 0.3242  | val_0_auc: 0.95181 |  0:01:28s\n",
            "epoch 35 | loss: 0.32011 | val_0_auc: 0.95455 |  0:01:30s\n",
            "epoch 36 | loss: 0.31691 | val_0_auc: 0.95286 |  0:01:34s\n",
            "epoch 37 | loss: 0.31583 | val_0_auc: 0.95423 |  0:01:37s\n",
            "\n",
            "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.95472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:15:17,675] Trial 20 finished with value: 0.9547185440698293 and parameters: {'n_d': 39, 'n_a': 29, 'n_steps': 4, 'gamma': 0.3236115047672733, 'momentum': 0.12559234673720238, 'lambda_sparse': 0.026155842075431836, 'lr': 0.0011944206224549254, 'weight_decay': 5.317559387357636e-05}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.76252 | val_0_auc: 0.53653 |  0:00:01s\n",
            "epoch 1  | loss: 0.65044 | val_0_auc: 0.69294 |  0:00:04s\n",
            "epoch 2  | loss: 0.60783 | val_0_auc: 0.77776 |  0:00:06s\n",
            "epoch 3  | loss: 0.59026 | val_0_auc: 0.80663 |  0:00:08s\n",
            "epoch 4  | loss: 0.54694 | val_0_auc: 0.83829 |  0:00:11s\n",
            "epoch 5  | loss: 0.51402 | val_0_auc: 0.85384 |  0:00:13s\n",
            "epoch 6  | loss: 0.48182 | val_0_auc: 0.87124 |  0:00:15s\n",
            "epoch 7  | loss: 0.46307 | val_0_auc: 0.88899 |  0:00:17s\n",
            "epoch 8  | loss: 0.43975 | val_0_auc: 0.89344 |  0:00:19s\n",
            "epoch 9  | loss: 0.44163 | val_0_auc: 0.89574 |  0:00:21s\n",
            "epoch 10 | loss: 0.43638 | val_0_auc: 0.89967 |  0:00:24s\n",
            "epoch 11 | loss: 0.4304  | val_0_auc: 0.89056 |  0:00:26s\n",
            "epoch 12 | loss: 0.43291 | val_0_auc: 0.90416 |  0:00:28s\n",
            "epoch 13 | loss: 0.40275 | val_0_auc: 0.91772 |  0:00:30s\n",
            "epoch 14 | loss: 0.42201 | val_0_auc: 0.91299 |  0:00:32s\n",
            "epoch 15 | loss: 0.40721 | val_0_auc: 0.92138 |  0:00:34s\n",
            "epoch 16 | loss: 0.41106 | val_0_auc: 0.91166 |  0:00:37s\n",
            "epoch 17 | loss: 0.40347 | val_0_auc: 0.91431 |  0:00:39s\n",
            "epoch 18 | loss: 0.40132 | val_0_auc: 0.9228  |  0:00:41s\n",
            "epoch 19 | loss: 0.38947 | val_0_auc: 0.92245 |  0:00:43s\n",
            "epoch 20 | loss: 0.39156 | val_0_auc: 0.92727 |  0:00:45s\n",
            "epoch 21 | loss: 0.38003 | val_0_auc: 0.93323 |  0:00:48s\n",
            "epoch 22 | loss: 0.37649 | val_0_auc: 0.93327 |  0:00:50s\n",
            "epoch 23 | loss: 0.36449 | val_0_auc: 0.92459 |  0:00:52s\n",
            "epoch 24 | loss: 0.36966 | val_0_auc: 0.93396 |  0:00:54s\n",
            "epoch 25 | loss: 0.36925 | val_0_auc: 0.93024 |  0:00:56s\n",
            "epoch 26 | loss: 0.36393 | val_0_auc: 0.93801 |  0:00:59s\n",
            "epoch 27 | loss: 0.3626  | val_0_auc: 0.94158 |  0:01:01s\n",
            "epoch 28 | loss: 0.35772 | val_0_auc: 0.93639 |  0:01:03s\n",
            "epoch 29 | loss: 0.35886 | val_0_auc: 0.93634 |  0:01:05s\n",
            "epoch 30 | loss: 0.34434 | val_0_auc: 0.93569 |  0:01:07s\n",
            "epoch 31 | loss: 0.34865 | val_0_auc: 0.94799 |  0:01:10s\n",
            "epoch 32 | loss: 0.34463 | val_0_auc: 0.9459  |  0:01:13s\n",
            "epoch 33 | loss: 0.35172 | val_0_auc: 0.94195 |  0:01:15s\n",
            "epoch 34 | loss: 0.33589 | val_0_auc: 0.9442  |  0:01:18s\n",
            "epoch 35 | loss: 0.33405 | val_0_auc: 0.94235 |  0:01:20s\n",
            "epoch 36 | loss: 0.32541 | val_0_auc: 0.94265 |  0:01:22s\n",
            "epoch 37 | loss: 0.32959 | val_0_auc: 0.94137 |  0:01:25s\n",
            "epoch 38 | loss: 0.32879 | val_0_auc: 0.94823 |  0:01:28s\n",
            "epoch 39 | loss: 0.32545 | val_0_auc: 0.94596 |  0:01:31s\n",
            "epoch 40 | loss: 0.33482 | val_0_auc: 0.94436 |  0:01:33s\n",
            "epoch 41 | loss: 0.31828 | val_0_auc: 0.94143 |  0:01:36s\n",
            "epoch 42 | loss: 0.3257  | val_0_auc: 0.95048 |  0:01:39s\n",
            "epoch 43 | loss: 0.31917 | val_0_auc: 0.94777 |  0:01:42s\n",
            "epoch 44 | loss: 0.32256 | val_0_auc: 0.94926 |  0:01:45s\n",
            "epoch 45 | loss: 0.3321  | val_0_auc: 0.94592 |  0:01:47s\n",
            "epoch 46 | loss: 0.32944 | val_0_auc: 0.94864 |  0:01:50s\n",
            "epoch 47 | loss: 0.31951 | val_0_auc: 0.94945 |  0:01:53s\n",
            "epoch 48 | loss: 0.31109 | val_0_auc: 0.95086 |  0:01:56s\n",
            "epoch 49 | loss: 0.31815 | val_0_auc: 0.95013 |  0:01:58s\n",
            "epoch 50 | loss: 0.31405 | val_0_auc: 0.9527  |  0:02:01s\n",
            "epoch 51 | loss: 0.30558 | val_0_auc: 0.95443 |  0:02:04s\n",
            "epoch 52 | loss: 0.30399 | val_0_auc: 0.94894 |  0:02:07s\n",
            "epoch 53 | loss: 0.29818 | val_0_auc: 0.94585 |  0:02:10s\n",
            "epoch 54 | loss: 0.296   | val_0_auc: 0.95199 |  0:02:12s\n",
            "epoch 55 | loss: 0.29991 | val_0_auc: 0.95232 |  0:02:15s\n",
            "epoch 56 | loss: 0.30256 | val_0_auc: 0.95464 |  0:02:18s\n",
            "epoch 57 | loss: 0.29821 | val_0_auc: 0.95395 |  0:02:21s\n",
            "epoch 58 | loss: 0.27758 | val_0_auc: 0.95295 |  0:02:24s\n",
            "epoch 59 | loss: 0.28615 | val_0_auc: 0.95497 |  0:02:28s\n",
            "epoch 60 | loss: 0.2943  | val_0_auc: 0.95072 |  0:02:31s\n",
            "epoch 61 | loss: 0.29222 | val_0_auc: 0.94605 |  0:02:34s\n",
            "epoch 62 | loss: 0.29813 | val_0_auc: 0.95175 |  0:02:36s\n",
            "epoch 63 | loss: 0.29089 | val_0_auc: 0.95362 |  0:02:40s\n",
            "epoch 64 | loss: 0.28981 | val_0_auc: 0.95524 |  0:02:42s\n",
            "epoch 65 | loss: 0.28059 | val_0_auc: 0.95727 |  0:02:45s\n",
            "epoch 66 | loss: 0.28593 | val_0_auc: 0.95869 |  0:02:48s\n",
            "epoch 67 | loss: 0.28081 | val_0_auc: 0.95102 |  0:02:52s\n",
            "epoch 68 | loss: 0.28267 | val_0_auc: 0.95387 |  0:02:55s\n",
            "epoch 69 | loss: 0.28125 | val_0_auc: 0.9563  |  0:02:58s\n",
            "epoch 70 | loss: 0.2808  | val_0_auc: 0.95505 |  0:03:00s\n",
            "epoch 71 | loss: 0.28123 | val_0_auc: 0.9599  |  0:03:04s\n",
            "epoch 72 | loss: 0.27334 | val_0_auc: 0.95626 |  0:03:07s\n",
            "epoch 73 | loss: 0.2753  | val_0_auc: 0.95373 |  0:03:10s\n",
            "epoch 74 | loss: 0.27581 | val_0_auc: 0.95226 |  0:03:12s\n",
            "epoch 75 | loss: 0.28012 | val_0_auc: 0.95596 |  0:03:16s\n",
            "epoch 76 | loss: 0.2703  | val_0_auc: 0.95963 |  0:03:19s\n",
            "epoch 77 | loss: 0.27181 | val_0_auc: 0.96187 |  0:03:21s\n",
            "epoch 78 | loss: 0.25755 | val_0_auc: 0.95291 |  0:03:24s\n",
            "epoch 79 | loss: 0.26136 | val_0_auc: 0.95677 |  0:03:27s\n",
            "epoch 80 | loss: 0.26254 | val_0_auc: 0.9636  |  0:03:30s\n",
            "epoch 81 | loss: 0.26471 | val_0_auc: 0.96173 |  0:03:33s\n",
            "epoch 82 | loss: 0.26419 | val_0_auc: 0.96041 |  0:03:36s\n",
            "epoch 83 | loss: 0.26049 | val_0_auc: 0.96174 |  0:03:40s\n",
            "epoch 84 | loss: 0.25535 | val_0_auc: 0.95799 |  0:03:43s\n",
            "epoch 85 | loss: 0.25519 | val_0_auc: 0.96319 |  0:03:46s\n",
            "epoch 86 | loss: 0.25283 | val_0_auc: 0.96156 |  0:03:49s\n",
            "epoch 87 | loss: 0.26184 | val_0_auc: 0.96339 |  0:03:52s\n",
            "epoch 88 | loss: 0.25691 | val_0_auc: 0.96253 |  0:03:55s\n",
            "epoch 89 | loss: 0.25063 | val_0_auc: 0.96306 |  0:03:58s\n",
            "epoch 90 | loss: 0.25179 | val_0_auc: 0.96124 |  0:04:00s\n",
            "\n",
            "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_auc = 0.9636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:19:20,473] Trial 21 finished with value: 0.9636017457314886 and parameters: {'n_d': 33, 'n_a': 46, 'n_steps': 3, 'gamma': 1.9712052406492957, 'momentum': 0.1321542486040016, 'lambda_sparse': 0.04678852675054278, 'lr': 0.0033434273916256637, 'weight_decay': 2.968743972311006e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.0107  | val_0_auc: 0.45853 |  0:00:03s\n",
            "epoch 1  | loss: 0.73747 | val_0_auc: 0.55774 |  0:00:05s\n",
            "epoch 2  | loss: 0.71631 | val_0_auc: 0.63784 |  0:00:09s\n",
            "epoch 3  | loss: 0.69586 | val_0_auc: 0.65786 |  0:00:11s\n",
            "epoch 4  | loss: 0.67093 | val_0_auc: 0.72163 |  0:00:14s\n",
            "epoch 5  | loss: 0.64491 | val_0_auc: 0.74142 |  0:00:17s\n",
            "epoch 6  | loss: 0.64403 | val_0_auc: 0.76614 |  0:00:20s\n",
            "epoch 7  | loss: 0.64232 | val_0_auc: 0.74274 |  0:00:22s\n",
            "epoch 8  | loss: 0.63298 | val_0_auc: 0.77866 |  0:00:25s\n",
            "epoch 9  | loss: 0.63408 | val_0_auc: 0.77252 |  0:00:28s\n",
            "epoch 10 | loss: 0.60257 | val_0_auc: 0.78456 |  0:00:31s\n",
            "epoch 11 | loss: 0.58349 | val_0_auc: 0.82061 |  0:00:33s\n",
            "epoch 12 | loss: 0.57406 | val_0_auc: 0.80041 |  0:00:36s\n",
            "epoch 13 | loss: 0.57167 | val_0_auc: 0.82519 |  0:00:39s\n",
            "epoch 14 | loss: 0.57105 | val_0_auc: 0.83046 |  0:00:43s\n",
            "epoch 15 | loss: 0.55844 | val_0_auc: 0.83911 |  0:00:46s\n",
            "epoch 16 | loss: 0.53208 | val_0_auc: 0.83511 |  0:00:49s\n",
            "epoch 17 | loss: 0.54586 | val_0_auc: 0.82879 |  0:00:52s\n",
            "epoch 18 | loss: 0.52401 | val_0_auc: 0.85189 |  0:00:55s\n",
            "epoch 19 | loss: 0.49955 | val_0_auc: 0.86086 |  0:00:58s\n",
            "epoch 20 | loss: 0.49448 | val_0_auc: 0.86028 |  0:01:01s\n",
            "epoch 21 | loss: 0.49957 | val_0_auc: 0.87152 |  0:01:04s\n",
            "epoch 22 | loss: 0.48057 | val_0_auc: 0.85542 |  0:01:08s\n",
            "epoch 23 | loss: 0.49024 | val_0_auc: 0.87805 |  0:01:11s\n",
            "epoch 24 | loss: 0.48081 | val_0_auc: 0.88222 |  0:01:14s\n",
            "epoch 25 | loss: 0.48299 | val_0_auc: 0.87939 |  0:01:16s\n",
            "epoch 26 | loss: 0.46836 | val_0_auc: 0.88938 |  0:01:20s\n",
            "epoch 27 | loss: 0.46728 | val_0_auc: 0.88745 |  0:01:23s\n",
            "epoch 28 | loss: 0.46526 | val_0_auc: 0.89948 |  0:01:25s\n",
            "epoch 29 | loss: 0.46517 | val_0_auc: 0.89662 |  0:01:29s\n",
            "epoch 30 | loss: 0.45692 | val_0_auc: 0.9027  |  0:01:32s\n",
            "epoch 31 | loss: 0.45715 | val_0_auc: 0.90568 |  0:01:35s\n",
            "epoch 32 | loss: 0.44011 | val_0_auc: 0.89806 |  0:01:38s\n",
            "epoch 33 | loss: 0.44803 | val_0_auc: 0.91389 |  0:01:41s\n",
            "epoch 34 | loss: 0.43592 | val_0_auc: 0.9178  |  0:01:45s\n",
            "epoch 35 | loss: 0.4376  | val_0_auc: 0.90881 |  0:01:48s\n",
            "epoch 36 | loss: 0.43189 | val_0_auc: 0.91729 |  0:01:51s\n",
            "epoch 37 | loss: 0.42728 | val_0_auc: 0.90851 |  0:01:54s\n",
            "epoch 38 | loss: 0.43668 | val_0_auc: 0.91212 |  0:01:58s\n",
            "epoch 39 | loss: 0.42829 | val_0_auc: 0.91426 |  0:02:01s\n",
            "epoch 40 | loss: 0.42539 | val_0_auc: 0.9186  |  0:02:04s\n",
            "epoch 41 | loss: 0.42094 | val_0_auc: 0.91235 |  0:02:07s\n",
            "epoch 42 | loss: 0.41663 | val_0_auc: 0.91478 |  0:02:11s\n",
            "epoch 43 | loss: 0.4048  | val_0_auc: 0.9197  |  0:02:14s\n",
            "epoch 44 | loss: 0.40536 | val_0_auc: 0.92311 |  0:02:17s\n",
            "epoch 45 | loss: 0.40874 | val_0_auc: 0.92438 |  0:02:20s\n",
            "epoch 46 | loss: 0.40076 | val_0_auc: 0.92065 |  0:02:23s\n",
            "epoch 47 | loss: 0.40788 | val_0_auc: 0.9207  |  0:02:27s\n",
            "epoch 48 | loss: 0.40589 | val_0_auc: 0.92031 |  0:02:30s\n",
            "epoch 49 | loss: 0.41988 | val_0_auc: 0.92501 |  0:02:34s\n",
            "epoch 50 | loss: 0.39697 | val_0_auc: 0.92193 |  0:02:38s\n",
            "epoch 51 | loss: 0.40397 | val_0_auc: 0.924   |  0:02:41s\n",
            "epoch 52 | loss: 0.41247 | val_0_auc: 0.92418 |  0:02:44s\n",
            "epoch 53 | loss: 0.39405 | val_0_auc: 0.92151 |  0:02:47s\n",
            "epoch 54 | loss: 0.40227 | val_0_auc: 0.93145 |  0:02:51s\n",
            "epoch 55 | loss: 0.39732 | val_0_auc: 0.92629 |  0:02:55s\n",
            "epoch 56 | loss: 0.38735 | val_0_auc: 0.9306  |  0:02:59s\n",
            "epoch 57 | loss: 0.39075 | val_0_auc: 0.92971 |  0:03:02s\n",
            "epoch 58 | loss: 0.38652 | val_0_auc: 0.92781 |  0:03:05s\n",
            "epoch 59 | loss: 0.39023 | val_0_auc: 0.92821 |  0:03:09s\n",
            "epoch 60 | loss: 0.37552 | val_0_auc: 0.93216 |  0:03:13s\n",
            "epoch 61 | loss: 0.37356 | val_0_auc: 0.92482 |  0:03:16s\n",
            "epoch 62 | loss: 0.37201 | val_0_auc: 0.92771 |  0:03:20s\n",
            "epoch 63 | loss: 0.37442 | val_0_auc: 0.93381 |  0:03:23s\n",
            "epoch 64 | loss: 0.36183 | val_0_auc: 0.93337 |  0:03:27s\n",
            "epoch 65 | loss: 0.37362 | val_0_auc: 0.93321 |  0:03:30s\n",
            "epoch 66 | loss: 0.36387 | val_0_auc: 0.93508 |  0:03:34s\n",
            "epoch 67 | loss: 0.36138 | val_0_auc: 0.9379  |  0:03:37s\n",
            "epoch 68 | loss: 0.36343 | val_0_auc: 0.93943 |  0:03:41s\n",
            "epoch 69 | loss: 0.35586 | val_0_auc: 0.93967 |  0:03:44s\n",
            "epoch 70 | loss: 0.35095 | val_0_auc: 0.94171 |  0:03:48s\n",
            "epoch 71 | loss: 0.35758 | val_0_auc: 0.93607 |  0:03:51s\n",
            "epoch 72 | loss: 0.35738 | val_0_auc: 0.92948 |  0:03:55s\n",
            "epoch 73 | loss: 0.35167 | val_0_auc: 0.93732 |  0:03:58s\n",
            "epoch 74 | loss: 0.34407 | val_0_auc: 0.93799 |  0:04:01s\n",
            "epoch 75 | loss: 0.36556 | val_0_auc: 0.93699 |  0:04:05s\n",
            "epoch 76 | loss: 0.35671 | val_0_auc: 0.93382 |  0:04:08s\n",
            "epoch 77 | loss: 0.35784 | val_0_auc: 0.93696 |  0:04:12s\n",
            "epoch 78 | loss: 0.33792 | val_0_auc: 0.93921 |  0:04:15s\n",
            "epoch 79 | loss: 0.34016 | val_0_auc: 0.94709 |  0:04:18s\n",
            "epoch 80 | loss: 0.33971 | val_0_auc: 0.94155 |  0:04:22s\n",
            "epoch 81 | loss: 0.33826 | val_0_auc: 0.9425  |  0:04:26s\n",
            "epoch 82 | loss: 0.33428 | val_0_auc: 0.94171 |  0:04:30s\n",
            "epoch 83 | loss: 0.35033 | val_0_auc: 0.94612 |  0:04:33s\n",
            "epoch 84 | loss: 0.33078 | val_0_auc: 0.94182 |  0:04:36s\n",
            "epoch 85 | loss: 0.33842 | val_0_auc: 0.94554 |  0:04:40s\n",
            "epoch 86 | loss: 0.33655 | val_0_auc: 0.94598 |  0:04:43s\n",
            "epoch 87 | loss: 0.33977 | val_0_auc: 0.94486 |  0:04:46s\n",
            "epoch 88 | loss: 0.33266 | val_0_auc: 0.94459 |  0:04:50s\n",
            "epoch 89 | loss: 0.34055 | val_0_auc: 0.9487  |  0:04:53s\n",
            "epoch 90 | loss: 0.3334  | val_0_auc: 0.94602 |  0:04:57s\n",
            "epoch 91 | loss: 0.3377  | val_0_auc: 0.94559 |  0:05:00s\n",
            "epoch 92 | loss: 0.33525 | val_0_auc: 0.94422 |  0:05:04s\n",
            "epoch 93 | loss: 0.33648 | val_0_auc: 0.94568 |  0:05:08s\n",
            "epoch 94 | loss: 0.33507 | val_0_auc: 0.94491 |  0:05:11s\n",
            "epoch 95 | loss: 0.31907 | val_0_auc: 0.94772 |  0:05:15s\n",
            "epoch 96 | loss: 0.33234 | val_0_auc: 0.94169 |  0:05:18s\n",
            "epoch 97 | loss: 0.32712 | val_0_auc: 0.94706 |  0:05:21s\n",
            "epoch 98 | loss: 0.32143 | val_0_auc: 0.94241 |  0:05:24s\n",
            "epoch 99 | loss: 0.31712 | val_0_auc: 0.95158 |  0:05:28s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_auc = 0.95158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:24:51,228] Trial 22 finished with value: 0.9515797509983558 and parameters: {'n_d': 32, 'n_a': 34, 'n_steps': 5, 'gamma': 1.6120639995087762, 'momentum': 0.12572478489985076, 'lambda_sparse': 0.04502804599001524, 'lr': 0.00271030284630211, 'weight_decay': 2.7339517691159375e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.94541 | val_0_auc: 0.47167 |  0:00:02s\n",
            "epoch 1  | loss: 0.70435 | val_0_auc: 0.62803 |  0:00:04s\n",
            "epoch 2  | loss: 0.65526 | val_0_auc: 0.72044 |  0:00:07s\n",
            "epoch 3  | loss: 0.63741 | val_0_auc: 0.76615 |  0:00:09s\n",
            "epoch 4  | loss: 0.61199 | val_0_auc: 0.80527 |  0:00:12s\n",
            "epoch 5  | loss: 0.58322 | val_0_auc: 0.83013 |  0:00:14s\n",
            "epoch 6  | loss: 0.56909 | val_0_auc: 0.8429  |  0:00:16s\n",
            "epoch 7  | loss: 0.5484  | val_0_auc: 0.87048 |  0:00:19s\n",
            "epoch 8  | loss: 0.52537 | val_0_auc: 0.873   |  0:00:22s\n",
            "epoch 9  | loss: 0.50196 | val_0_auc: 0.88312 |  0:00:24s\n",
            "epoch 10 | loss: 0.50103 | val_0_auc: 0.89342 |  0:00:26s\n",
            "epoch 11 | loss: 0.48334 | val_0_auc: 0.89043 |  0:00:29s\n",
            "epoch 12 | loss: 0.4629  | val_0_auc: 0.89682 |  0:00:31s\n",
            "epoch 13 | loss: 0.47321 | val_0_auc: 0.89989 |  0:00:34s\n",
            "epoch 14 | loss: 0.45454 | val_0_auc: 0.90074 |  0:00:37s\n",
            "epoch 15 | loss: 0.43721 | val_0_auc: 0.91125 |  0:00:39s\n",
            "epoch 16 | loss: 0.44366 | val_0_auc: 0.91093 |  0:00:42s\n",
            "epoch 17 | loss: 0.44051 | val_0_auc: 0.91123 |  0:00:44s\n",
            "epoch 18 | loss: 0.44445 | val_0_auc: 0.9164  |  0:00:47s\n",
            "epoch 19 | loss: 0.43076 | val_0_auc: 0.91618 |  0:00:50s\n",
            "epoch 20 | loss: 0.42718 | val_0_auc: 0.92083 |  0:00:52s\n",
            "epoch 21 | loss: 0.42    | val_0_auc: 0.9232  |  0:00:54s\n",
            "epoch 22 | loss: 0.41381 | val_0_auc: 0.91879 |  0:00:57s\n",
            "epoch 23 | loss: 0.40977 | val_0_auc: 0.9191  |  0:01:00s\n",
            "epoch 24 | loss: 0.41059 | val_0_auc: 0.91745 |  0:01:02s\n",
            "epoch 25 | loss: 0.39559 | val_0_auc: 0.92335 |  0:01:04s\n",
            "epoch 26 | loss: 0.39126 | val_0_auc: 0.92779 |  0:01:06s\n",
            "epoch 27 | loss: 0.38605 | val_0_auc: 0.92368 |  0:01:08s\n",
            "epoch 28 | loss: 0.37885 | val_0_auc: 0.93523 |  0:01:11s\n",
            "epoch 29 | loss: 0.38826 | val_0_auc: 0.9227  |  0:01:14s\n",
            "epoch 30 | loss: 0.38533 | val_0_auc: 0.93243 |  0:01:17s\n",
            "epoch 31 | loss: 0.38001 | val_0_auc: 0.93066 |  0:01:19s\n",
            "epoch 32 | loss: 0.38066 | val_0_auc: 0.93957 |  0:01:22s\n",
            "epoch 33 | loss: 0.36838 | val_0_auc: 0.937   |  0:01:25s\n",
            "epoch 34 | loss: 0.36677 | val_0_auc: 0.93356 |  0:01:28s\n",
            "epoch 35 | loss: 0.36865 | val_0_auc: 0.94124 |  0:01:31s\n",
            "epoch 36 | loss: 0.37734 | val_0_auc: 0.93431 |  0:01:33s\n",
            "epoch 37 | loss: 0.37055 | val_0_auc: 0.93917 |  0:01:37s\n",
            "epoch 38 | loss: 0.36488 | val_0_auc: 0.94393 |  0:01:40s\n",
            "epoch 39 | loss: 0.36906 | val_0_auc: 0.9417  |  0:01:42s\n",
            "epoch 40 | loss: 0.35266 | val_0_auc: 0.93889 |  0:01:45s\n",
            "epoch 41 | loss: 0.35608 | val_0_auc: 0.94195 |  0:01:49s\n",
            "epoch 42 | loss: 0.3483  | val_0_auc: 0.94225 |  0:01:52s\n",
            "epoch 43 | loss: 0.34279 | val_0_auc: 0.947   |  0:01:55s\n",
            "epoch 44 | loss: 0.33569 | val_0_auc: 0.95105 |  0:01:58s\n",
            "epoch 45 | loss: 0.33351 | val_0_auc: 0.94929 |  0:02:02s\n",
            "epoch 46 | loss: 0.33886 | val_0_auc: 0.94593 |  0:02:04s\n",
            "epoch 47 | loss: 0.33615 | val_0_auc: 0.94196 |  0:02:07s\n",
            "epoch 48 | loss: 0.33064 | val_0_auc: 0.95075 |  0:02:10s\n",
            "epoch 49 | loss: 0.33558 | val_0_auc: 0.95081 |  0:02:14s\n",
            "epoch 50 | loss: 0.31955 | val_0_auc: 0.95054 |  0:02:16s\n",
            "epoch 51 | loss: 0.32141 | val_0_auc: 0.94939 |  0:02:19s\n",
            "epoch 52 | loss: 0.31984 | val_0_auc: 0.94819 |  0:02:22s\n",
            "epoch 53 | loss: 0.3279  | val_0_auc: 0.95085 |  0:02:25s\n",
            "epoch 54 | loss: 0.32486 | val_0_auc: 0.94988 |  0:02:28s\n",
            "\n",
            "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.95105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:27:21,276] Trial 23 finished with value: 0.9510496643299582 and parameters: {'n_d': 40, 'n_a': 21, 'n_steps': 4, 'gamma': 0.7500314094837284, 'momentum': 0.22540713127113393, 'lambda_sparse': 0.03884954045937437, 'lr': 0.00282534258297606, 'weight_decay': 9.583938944228588e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.58768 | val_0_auc: 0.52543 |  0:00:02s\n",
            "epoch 1  | loss: 0.81706 | val_0_auc: 0.54674 |  0:00:04s\n",
            "epoch 2  | loss: 0.72048 | val_0_auc: 0.64379 |  0:00:07s\n",
            "epoch 3  | loss: 0.6799  | val_0_auc: 0.69238 |  0:00:10s\n",
            "epoch 4  | loss: 0.66032 | val_0_auc: 0.71408 |  0:00:12s\n",
            "epoch 5  | loss: 0.64158 | val_0_auc: 0.75159 |  0:00:14s\n",
            "epoch 6  | loss: 0.62423 | val_0_auc: 0.77148 |  0:00:15s\n",
            "epoch 7  | loss: 0.62413 | val_0_auc: 0.78692 |  0:00:17s\n",
            "epoch 8  | loss: 0.61644 | val_0_auc: 0.79437 |  0:00:20s\n",
            "epoch 9  | loss: 0.60392 | val_0_auc: 0.79691 |  0:00:22s\n",
            "epoch 10 | loss: 0.59088 | val_0_auc: 0.80586 |  0:00:24s\n",
            "epoch 11 | loss: 0.58132 | val_0_auc: 0.81477 |  0:00:26s\n",
            "epoch 12 | loss: 0.57557 | val_0_auc: 0.8233  |  0:00:28s\n",
            "epoch 13 | loss: 0.5698  | val_0_auc: 0.82917 |  0:00:30s\n",
            "epoch 14 | loss: 0.55554 | val_0_auc: 0.82627 |  0:00:33s\n",
            "epoch 15 | loss: 0.54437 | val_0_auc: 0.84082 |  0:00:35s\n",
            "epoch 16 | loss: 0.5395  | val_0_auc: 0.85077 |  0:00:37s\n",
            "epoch 17 | loss: 0.53225 | val_0_auc: 0.86293 |  0:00:40s\n",
            "epoch 18 | loss: 0.52278 | val_0_auc: 0.86965 |  0:00:42s\n",
            "epoch 19 | loss: 0.50908 | val_0_auc: 0.87648 |  0:00:45s\n",
            "epoch 20 | loss: 0.49385 | val_0_auc: 0.87715 |  0:00:47s\n",
            "epoch 21 | loss: 0.50103 | val_0_auc: 0.87745 |  0:00:49s\n",
            "epoch 22 | loss: 0.49206 | val_0_auc: 0.8853  |  0:00:51s\n",
            "epoch 23 | loss: 0.48261 | val_0_auc: 0.88397 |  0:00:53s\n",
            "epoch 24 | loss: 0.48188 | val_0_auc: 0.8872  |  0:00:56s\n",
            "epoch 25 | loss: 0.4777  | val_0_auc: 0.89182 |  0:00:58s\n",
            "epoch 26 | loss: 0.47187 | val_0_auc: 0.8965  |  0:01:00s\n",
            "epoch 27 | loss: 0.46066 | val_0_auc: 0.89885 |  0:01:03s\n",
            "epoch 28 | loss: 0.4597  | val_0_auc: 0.89574 |  0:01:05s\n",
            "epoch 29 | loss: 0.45797 | val_0_auc: 0.89346 |  0:01:07s\n",
            "epoch 30 | loss: 0.44889 | val_0_auc: 0.88937 |  0:01:09s\n",
            "epoch 31 | loss: 0.45659 | val_0_auc: 0.90207 |  0:01:12s\n",
            "epoch 32 | loss: 0.45093 | val_0_auc: 0.89949 |  0:01:14s\n",
            "epoch 33 | loss: 0.44591 | val_0_auc: 0.89976 |  0:01:16s\n",
            "epoch 34 | loss: 0.44191 | val_0_auc: 0.89944 |  0:01:18s\n",
            "epoch 35 | loss: 0.43574 | val_0_auc: 0.90303 |  0:01:20s\n",
            "epoch 36 | loss: 0.42836 | val_0_auc: 0.9063  |  0:01:22s\n",
            "epoch 37 | loss: 0.42572 | val_0_auc: 0.90601 |  0:01:25s\n",
            "epoch 38 | loss: 0.43656 | val_0_auc: 0.9106  |  0:01:27s\n",
            "epoch 39 | loss: 0.42515 | val_0_auc: 0.90364 |  0:01:29s\n",
            "epoch 40 | loss: 0.42875 | val_0_auc: 0.91195 |  0:01:31s\n",
            "epoch 41 | loss: 0.41342 | val_0_auc: 0.91602 |  0:01:34s\n",
            "epoch 42 | loss: 0.4195  | val_0_auc: 0.91497 |  0:01:37s\n",
            "epoch 43 | loss: 0.41975 | val_0_auc: 0.91251 |  0:01:39s\n",
            "epoch 44 | loss: 0.40853 | val_0_auc: 0.9135  |  0:01:41s\n",
            "epoch 45 | loss: 0.42258 | val_0_auc: 0.91831 |  0:01:43s\n",
            "epoch 46 | loss: 0.40402 | val_0_auc: 0.91538 |  0:01:45s\n",
            "epoch 47 | loss: 0.40632 | val_0_auc: 0.91718 |  0:01:48s\n",
            "epoch 48 | loss: 0.40234 | val_0_auc: 0.917   |  0:01:50s\n",
            "epoch 49 | loss: 0.40057 | val_0_auc: 0.92563 |  0:01:52s\n",
            "epoch 50 | loss: 0.39866 | val_0_auc: 0.92781 |  0:01:54s\n",
            "epoch 51 | loss: 0.38701 | val_0_auc: 0.91975 |  0:01:56s\n",
            "epoch 52 | loss: 0.39773 | val_0_auc: 0.92869 |  0:01:58s\n",
            "epoch 53 | loss: 0.38715 | val_0_auc: 0.93027 |  0:02:01s\n",
            "epoch 54 | loss: 0.38561 | val_0_auc: 0.92728 |  0:02:03s\n",
            "epoch 55 | loss: 0.37722 | val_0_auc: 0.93095 |  0:02:06s\n",
            "epoch 56 | loss: 0.38446 | val_0_auc: 0.92431 |  0:02:08s\n",
            "epoch 57 | loss: 0.37881 | val_0_auc: 0.9265  |  0:02:10s\n",
            "epoch 58 | loss: 0.38418 | val_0_auc: 0.92814 |  0:02:13s\n",
            "epoch 59 | loss: 0.37252 | val_0_auc: 0.9322  |  0:02:15s\n",
            "epoch 60 | loss: 0.38184 | val_0_auc: 0.93578 |  0:02:17s\n",
            "epoch 61 | loss: 0.37099 | val_0_auc: 0.93312 |  0:02:19s\n",
            "epoch 62 | loss: 0.36868 | val_0_auc: 0.93359 |  0:02:22s\n",
            "epoch 63 | loss: 0.36658 | val_0_auc: 0.93555 |  0:02:24s\n",
            "epoch 64 | loss: 0.36483 | val_0_auc: 0.93553 |  0:02:27s\n",
            "epoch 65 | loss: 0.37365 | val_0_auc: 0.9369  |  0:02:29s\n",
            "epoch 66 | loss: 0.36498 | val_0_auc: 0.93689 |  0:02:31s\n",
            "epoch 67 | loss: 0.36986 | val_0_auc: 0.9372  |  0:02:33s\n",
            "epoch 68 | loss: 0.36474 | val_0_auc: 0.93513 |  0:02:35s\n",
            "epoch 69 | loss: 0.3607  | val_0_auc: 0.9378  |  0:02:38s\n",
            "epoch 70 | loss: 0.36584 | val_0_auc: 0.93515 |  0:02:41s\n",
            "epoch 71 | loss: 0.36639 | val_0_auc: 0.93205 |  0:02:43s\n",
            "epoch 72 | loss: 0.3716  | val_0_auc: 0.93218 |  0:02:45s\n",
            "epoch 73 | loss: 0.36129 | val_0_auc: 0.93653 |  0:02:47s\n",
            "epoch 74 | loss: 0.36359 | val_0_auc: 0.93521 |  0:02:50s\n",
            "epoch 75 | loss: 0.36277 | val_0_auc: 0.93499 |  0:02:52s\n",
            "epoch 76 | loss: 0.34921 | val_0_auc: 0.93016 |  0:02:55s\n",
            "epoch 77 | loss: 0.3602  | val_0_auc: 0.93129 |  0:02:57s\n",
            "epoch 78 | loss: 0.35784 | val_0_auc: 0.93916 |  0:02:59s\n",
            "epoch 79 | loss: 0.36011 | val_0_auc: 0.93913 |  0:03:01s\n",
            "epoch 80 | loss: 0.35286 | val_0_auc: 0.93986 |  0:03:04s\n",
            "epoch 81 | loss: 0.35786 | val_0_auc: 0.94063 |  0:03:07s\n",
            "epoch 82 | loss: 0.34776 | val_0_auc: 0.9398  |  0:03:09s\n",
            "epoch 83 | loss: 0.35394 | val_0_auc: 0.94345 |  0:03:11s\n",
            "epoch 84 | loss: 0.34326 | val_0_auc: 0.94062 |  0:03:15s\n",
            "epoch 85 | loss: 0.34787 | val_0_auc: 0.93513 |  0:03:17s\n",
            "epoch 86 | loss: 0.34026 | val_0_auc: 0.93477 |  0:03:19s\n",
            "epoch 87 | loss: 0.33834 | val_0_auc: 0.93951 |  0:03:21s\n",
            "epoch 88 | loss: 0.34319 | val_0_auc: 0.93797 |  0:03:24s\n",
            "epoch 89 | loss: 0.33909 | val_0_auc: 0.9405  |  0:03:26s\n",
            "epoch 90 | loss: 0.3482  | val_0_auc: 0.93846 |  0:03:29s\n",
            "epoch 91 | loss: 0.35488 | val_0_auc: 0.94113 |  0:03:31s\n",
            "epoch 92 | loss: 0.3329  | val_0_auc: 0.94157 |  0:03:33s\n",
            "epoch 93 | loss: 0.33985 | val_0_auc: 0.94025 |  0:03:35s\n",
            "\n",
            "Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_auc = 0.94345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:30:58,336] Trial 24 finished with value: 0.943448406958199 and parameters: {'n_d': 45, 'n_a': 42, 'n_steps': 3, 'gamma': 1.9305018292540566, 'momentum': 0.109770813318324, 'lambda_sparse': 0.03004444417756313, 'lr': 0.0005645694932551933, 'weight_decay': 2.9632939384396477e-06}. Best is trial 17 with value: 0.9661254528145593.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.00216 | val_0_auc: 0.61223 |  0:00:03s\n",
            "epoch 1  | loss: 0.71126 | val_0_auc: 0.6883  |  0:00:06s\n",
            "epoch 2  | loss: 0.61699 | val_0_auc: 0.80536 |  0:00:09s\n",
            "epoch 3  | loss: 0.57594 | val_0_auc: 0.85556 |  0:00:12s\n",
            "epoch 4  | loss: 0.53337 | val_0_auc: 0.88563 |  0:00:16s\n",
            "epoch 5  | loss: 0.52385 | val_0_auc: 0.89829 |  0:00:19s\n",
            "epoch 6  | loss: 0.50426 | val_0_auc: 0.9094  |  0:00:21s\n",
            "epoch 7  | loss: 0.48494 | val_0_auc: 0.92046 |  0:00:24s\n",
            "epoch 8  | loss: 0.46943 | val_0_auc: 0.93086 |  0:00:27s\n",
            "epoch 9  | loss: 0.46343 | val_0_auc: 0.92659 |  0:00:30s\n",
            "epoch 10 | loss: 0.4593  | val_0_auc: 0.92539 |  0:00:33s\n",
            "epoch 11 | loss: 0.4478  | val_0_auc: 0.92922 |  0:00:36s\n",
            "epoch 12 | loss: 0.4484  | val_0_auc: 0.93254 |  0:00:41s\n",
            "epoch 13 | loss: 0.43532 | val_0_auc: 0.93403 |  0:00:43s\n",
            "epoch 14 | loss: 0.43072 | val_0_auc: 0.93572 |  0:00:46s\n",
            "epoch 15 | loss: 0.42468 | val_0_auc: 0.94114 |  0:00:49s\n",
            "epoch 16 | loss: 0.4198  | val_0_auc: 0.93934 |  0:00:53s\n",
            "epoch 17 | loss: 0.42071 | val_0_auc: 0.94051 |  0:00:56s\n",
            "epoch 18 | loss: 0.42274 | val_0_auc: 0.94411 |  0:00:58s\n",
            "epoch 19 | loss: 0.42031 | val_0_auc: 0.94648 |  0:01:01s\n",
            "epoch 20 | loss: 0.40939 | val_0_auc: 0.9426  |  0:01:04s\n",
            "epoch 21 | loss: 0.40395 | val_0_auc: 0.94701 |  0:01:07s\n",
            "epoch 22 | loss: 0.40029 | val_0_auc: 0.94996 |  0:01:10s\n",
            "epoch 23 | loss: 0.40214 | val_0_auc: 0.94655 |  0:01:13s\n",
            "epoch 24 | loss: 0.39491 | val_0_auc: 0.94699 |  0:01:15s\n",
            "epoch 25 | loss: 0.3938  | val_0_auc: 0.94892 |  0:01:19s\n",
            "epoch 26 | loss: 0.40152 | val_0_auc: 0.95074 |  0:01:22s\n",
            "epoch 27 | loss: 0.39426 | val_0_auc: 0.94834 |  0:01:25s\n",
            "epoch 28 | loss: 0.38853 | val_0_auc: 0.94958 |  0:01:28s\n",
            "epoch 29 | loss: 0.38483 | val_0_auc: 0.95319 |  0:01:32s\n",
            "epoch 30 | loss: 0.3798  | val_0_auc: 0.95138 |  0:01:35s\n",
            "epoch 31 | loss: 0.38069 | val_0_auc: 0.9525  |  0:01:38s\n",
            "epoch 32 | loss: 0.37969 | val_0_auc: 0.95129 |  0:01:41s\n",
            "epoch 33 | loss: 0.37924 | val_0_auc: 0.95335 |  0:01:44s\n",
            "epoch 34 | loss: 0.38281 | val_0_auc: 0.95163 |  0:01:47s\n",
            "epoch 35 | loss: 0.37248 | val_0_auc: 0.9535  |  0:01:50s\n",
            "epoch 36 | loss: 0.36893 | val_0_auc: 0.95188 |  0:01:53s\n",
            "epoch 37 | loss: 0.37813 | val_0_auc: 0.95332 |  0:01:56s\n",
            "epoch 38 | loss: 0.36291 | val_0_auc: 0.95397 |  0:01:59s\n",
            "epoch 39 | loss: 0.36861 | val_0_auc: 0.95694 |  0:02:02s\n",
            "epoch 40 | loss: 0.35784 | val_0_auc: 0.9568  |  0:02:05s\n",
            "epoch 41 | loss: 0.36292 | val_0_auc: 0.95277 |  0:02:09s\n",
            "epoch 42 | loss: 0.36219 | val_0_auc: 0.95607 |  0:02:12s\n",
            "epoch 43 | loss: 0.3626  | val_0_auc: 0.95693 |  0:02:14s\n",
            "epoch 44 | loss: 0.36793 | val_0_auc: 0.9574  |  0:02:17s\n",
            "epoch 45 | loss: 0.35829 | val_0_auc: 0.9575  |  0:02:21s\n",
            "epoch 46 | loss: 0.35543 | val_0_auc: 0.95924 |  0:02:24s\n",
            "epoch 47 | loss: 0.35964 | val_0_auc: 0.9607  |  0:02:27s\n",
            "epoch 48 | loss: 0.35106 | val_0_auc: 0.95969 |  0:02:31s\n",
            "epoch 49 | loss: 0.35044 | val_0_auc: 0.9548  |  0:02:34s\n",
            "epoch 50 | loss: 0.36015 | val_0_auc: 0.95948 |  0:02:37s\n",
            "epoch 51 | loss: 0.35378 | val_0_auc: 0.95962 |  0:02:40s\n",
            "epoch 52 | loss: 0.35217 | val_0_auc: 0.95711 |  0:02:43s\n",
            "epoch 53 | loss: 0.34248 | val_0_auc: 0.95985 |  0:02:47s\n",
            "epoch 54 | loss: 0.34807 | val_0_auc: 0.96126 |  0:02:51s\n",
            "epoch 55 | loss: 0.3463  | val_0_auc: 0.95867 |  0:02:54s\n",
            "epoch 56 | loss: 0.35567 | val_0_auc: 0.95755 |  0:02:58s\n",
            "epoch 57 | loss: 0.35017 | val_0_auc: 0.95817 |  0:03:01s\n",
            "epoch 58 | loss: 0.34574 | val_0_auc: 0.96078 |  0:03:04s\n",
            "epoch 59 | loss: 0.33906 | val_0_auc: 0.96001 |  0:03:07s\n",
            "epoch 60 | loss: 0.34386 | val_0_auc: 0.96009 |  0:03:10s\n",
            "epoch 61 | loss: 0.34059 | val_0_auc: 0.96233 |  0:03:14s\n",
            "epoch 62 | loss: 0.34171 | val_0_auc: 0.96382 |  0:03:17s\n",
            "epoch 63 | loss: 0.3316  | val_0_auc: 0.96245 |  0:03:20s\n",
            "epoch 64 | loss: 0.33066 | val_0_auc: 0.96181 |  0:03:24s\n",
            "epoch 65 | loss: 0.33199 | val_0_auc: 0.96161 |  0:03:27s\n",
            "epoch 66 | loss: 0.33376 | val_0_auc: 0.96079 |  0:03:30s\n",
            "epoch 67 | loss: 0.33344 | val_0_auc: 0.96388 |  0:03:33s\n",
            "epoch 68 | loss: 0.3331  | val_0_auc: 0.96468 |  0:03:37s\n",
            "epoch 69 | loss: 0.32654 | val_0_auc: 0.96375 |  0:03:40s\n",
            "epoch 70 | loss: 0.32553 | val_0_auc: 0.96376 |  0:03:43s\n",
            "epoch 71 | loss: 0.32968 | val_0_auc: 0.96241 |  0:03:46s\n",
            "epoch 72 | loss: 0.32277 | val_0_auc: 0.96349 |  0:03:50s\n",
            "epoch 73 | loss: 0.3312  | val_0_auc: 0.96529 |  0:03:53s\n",
            "epoch 74 | loss: 0.322   | val_0_auc: 0.96587 |  0:03:56s\n",
            "epoch 75 | loss: 0.31964 | val_0_auc: 0.96308 |  0:04:00s\n",
            "epoch 76 | loss: 0.32526 | val_0_auc: 0.96345 |  0:04:04s\n",
            "epoch 77 | loss: 0.31454 | val_0_auc: 0.96246 |  0:04:07s\n",
            "epoch 78 | loss: 0.32406 | val_0_auc: 0.96601 |  0:04:10s\n",
            "epoch 79 | loss: 0.31502 | val_0_auc: 0.96573 |  0:04:14s\n",
            "epoch 80 | loss: 0.31865 | val_0_auc: 0.96473 |  0:04:17s\n",
            "epoch 81 | loss: 0.32369 | val_0_auc: 0.96736 |  0:04:21s\n",
            "epoch 82 | loss: 0.31747 | val_0_auc: 0.96612 |  0:04:24s\n",
            "epoch 83 | loss: 0.31654 | val_0_auc: 0.96886 |  0:04:28s\n",
            "epoch 84 | loss: 0.31663 | val_0_auc: 0.96423 |  0:04:31s\n",
            "epoch 85 | loss: 0.31409 | val_0_auc: 0.966   |  0:04:34s\n",
            "epoch 86 | loss: 0.31341 | val_0_auc: 0.96615 |  0:04:37s\n",
            "epoch 87 | loss: 0.31474 | val_0_auc: 0.96459 |  0:04:41s\n",
            "epoch 88 | loss: 0.3179  | val_0_auc: 0.96727 |  0:04:44s\n",
            "epoch 89 | loss: 0.31114 | val_0_auc: 0.96428 |  0:04:48s\n",
            "epoch 90 | loss: 0.31333 | val_0_auc: 0.9659  |  0:04:52s\n",
            "epoch 91 | loss: 0.31262 | val_0_auc: 0.96534 |  0:04:55s\n",
            "epoch 92 | loss: 0.31059 | val_0_auc: 0.96557 |  0:04:58s\n",
            "epoch 93 | loss: 0.30456 | val_0_auc: 0.96632 |  0:05:02s\n",
            "\n",
            "Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_auc = 0.96886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:36:02,720] Trial 25 finished with value: 0.9688608854765526 and parameters: {'n_d': 33, 'n_a': 35, 'n_steps': 5, 'gamma': 0.23149950422767696, 'momentum': 0.07278207405552037, 'lambda_sparse': 0.04854615006208493, 'lr': 0.0005736498619619034, 'weight_decay': 2.457130588962263e-05}. Best is trial 25 with value: 0.9688608854765526.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.66746 | val_0_auc: 0.48245 |  0:00:02s\n",
            "epoch 1  | loss: 0.89653 | val_0_auc: 0.56907 |  0:00:05s\n",
            "epoch 2  | loss: 0.6879  | val_0_auc: 0.70849 |  0:00:08s\n",
            "epoch 3  | loss: 0.61022 | val_0_auc: 0.80079 |  0:00:11s\n",
            "epoch 4  | loss: 0.56477 | val_0_auc: 0.86025 |  0:00:14s\n",
            "epoch 5  | loss: 0.52967 | val_0_auc: 0.87204 |  0:00:17s\n",
            "epoch 6  | loss: 0.51869 | val_0_auc: 0.88108 |  0:00:20s\n",
            "epoch 7  | loss: 0.49282 | val_0_auc: 0.88423 |  0:00:22s\n",
            "epoch 8  | loss: 0.48072 | val_0_auc: 0.8996  |  0:00:25s\n",
            "epoch 9  | loss: 0.467   | val_0_auc: 0.90915 |  0:00:28s\n",
            "epoch 10 | loss: 0.46064 | val_0_auc: 0.91382 |  0:00:30s\n",
            "epoch 11 | loss: 0.45935 | val_0_auc: 0.91156 |  0:00:33s\n",
            "epoch 12 | loss: 0.44456 | val_0_auc: 0.90556 |  0:00:36s\n",
            "epoch 13 | loss: 0.43722 | val_0_auc: 0.91549 |  0:00:39s\n",
            "epoch 14 | loss: 0.42499 | val_0_auc: 0.91524 |  0:00:42s\n",
            "epoch 15 | loss: 0.4255  | val_0_auc: 0.91708 |  0:00:44s\n",
            "epoch 16 | loss: 0.42796 | val_0_auc: 0.92147 |  0:00:47s\n",
            "epoch 17 | loss: 0.41993 | val_0_auc: 0.92561 |  0:00:50s\n",
            "epoch 18 | loss: 0.41025 | val_0_auc: 0.92399 |  0:00:54s\n",
            "epoch 19 | loss: 0.39808 | val_0_auc: 0.92789 |  0:00:56s\n",
            "epoch 20 | loss: 0.39656 | val_0_auc: 0.9284  |  0:00:59s\n",
            "epoch 21 | loss: 0.38783 | val_0_auc: 0.93176 |  0:01:03s\n",
            "epoch 22 | loss: 0.39359 | val_0_auc: 0.93389 |  0:01:05s\n",
            "epoch 23 | loss: 0.38993 | val_0_auc: 0.93604 |  0:01:08s\n",
            "epoch 24 | loss: 0.38243 | val_0_auc: 0.93474 |  0:01:10s\n",
            "epoch 25 | loss: 0.38756 | val_0_auc: 0.93385 |  0:01:13s\n",
            "epoch 26 | loss: 0.38441 | val_0_auc: 0.92884 |  0:01:16s\n",
            "epoch 27 | loss: 0.37622 | val_0_auc: 0.9333  |  0:01:19s\n",
            "epoch 28 | loss: 0.37712 | val_0_auc: 0.93682 |  0:01:21s\n",
            "epoch 29 | loss: 0.37076 | val_0_auc: 0.93867 |  0:01:24s\n",
            "epoch 30 | loss: 0.37532 | val_0_auc: 0.94284 |  0:01:27s\n",
            "epoch 31 | loss: 0.38026 | val_0_auc: 0.94469 |  0:01:30s\n",
            "epoch 32 | loss: 0.36873 | val_0_auc: 0.94305 |  0:01:32s\n",
            "epoch 33 | loss: 0.36662 | val_0_auc: 0.94156 |  0:01:35s\n",
            "epoch 34 | loss: 0.35584 | val_0_auc: 0.94743 |  0:01:38s\n",
            "epoch 35 | loss: 0.36948 | val_0_auc: 0.94645 |  0:01:41s\n",
            "epoch 36 | loss: 0.35594 | val_0_auc: 0.94362 |  0:01:44s\n",
            "epoch 37 | loss: 0.35751 | val_0_auc: 0.94309 |  0:01:47s\n",
            "epoch 38 | loss: 0.3587  | val_0_auc: 0.94252 |  0:01:50s\n",
            "epoch 39 | loss: 0.36013 | val_0_auc: 0.9463  |  0:01:53s\n",
            "epoch 40 | loss: 0.35721 | val_0_auc: 0.94309 |  0:01:57s\n",
            "epoch 41 | loss: 0.35202 | val_0_auc: 0.94545 |  0:02:00s\n",
            "epoch 42 | loss: 0.35    | val_0_auc: 0.94561 |  0:02:03s\n",
            "epoch 43 | loss: 0.34198 | val_0_auc: 0.94691 |  0:02:06s\n",
            "epoch 44 | loss: 0.34603 | val_0_auc: 0.94675 |  0:02:09s\n",
            "\n",
            "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.94743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:38:13,265] Trial 26 finished with value: 0.9474286932977263 and parameters: {'n_d': 26, 'n_a': 34, 'n_steps': 5, 'gamma': 0.26366711898230827, 'momentum': 0.07582644377403229, 'lambda_sparse': 0.018516128081664834, 'lr': 0.00034911126915324525, 'weight_decay': 2.355649710696435e-05}. Best is trial 25 with value: 0.9688608854765526.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.33874 | val_0_auc: 0.54737 |  0:00:03s\n",
            "epoch 1  | loss: 0.72017 | val_0_auc: 0.6946  |  0:00:07s\n",
            "epoch 2  | loss: 0.63569 | val_0_auc: 0.79936 |  0:00:11s\n",
            "epoch 3  | loss: 0.59361 | val_0_auc: 0.8644  |  0:00:14s\n",
            "epoch 4  | loss: 0.5604  | val_0_auc: 0.89678 |  0:00:18s\n",
            "epoch 5  | loss: 0.53766 | val_0_auc: 0.91323 |  0:00:22s\n",
            "epoch 6  | loss: 0.5153  | val_0_auc: 0.91558 |  0:00:25s\n",
            "epoch 7  | loss: 0.52425 | val_0_auc: 0.9273  |  0:00:28s\n",
            "epoch 8  | loss: 0.51548 | val_0_auc: 0.92812 |  0:00:32s\n",
            "epoch 9  | loss: 0.50173 | val_0_auc: 0.93598 |  0:00:35s\n",
            "epoch 10 | loss: 0.48791 | val_0_auc: 0.94147 |  0:00:38s\n",
            "epoch 11 | loss: 0.48959 | val_0_auc: 0.92869 |  0:00:42s\n",
            "epoch 12 | loss: 0.46038 | val_0_auc: 0.93614 |  0:00:46s\n",
            "epoch 13 | loss: 0.47282 | val_0_auc: 0.93624 |  0:00:49s\n",
            "epoch 14 | loss: 0.45859 | val_0_auc: 0.94268 |  0:00:53s\n",
            "epoch 15 | loss: 0.45042 | val_0_auc: 0.94738 |  0:00:57s\n",
            "epoch 16 | loss: 0.45141 | val_0_auc: 0.94389 |  0:01:00s\n",
            "epoch 17 | loss: 0.44654 | val_0_auc: 0.9462  |  0:01:04s\n",
            "epoch 18 | loss: 0.44295 | val_0_auc: 0.9494  |  0:01:07s\n",
            "epoch 19 | loss: 0.43507 | val_0_auc: 0.9521  |  0:01:11s\n",
            "epoch 20 | loss: 0.43018 | val_0_auc: 0.95605 |  0:01:15s\n",
            "epoch 21 | loss: 0.42859 | val_0_auc: 0.95549 |  0:01:18s\n",
            "epoch 22 | loss: 0.42339 | val_0_auc: 0.95541 |  0:01:22s\n",
            "epoch 23 | loss: 0.42281 | val_0_auc: 0.95442 |  0:01:25s\n",
            "epoch 24 | loss: 0.42636 | val_0_auc: 0.95346 |  0:01:29s\n",
            "epoch 25 | loss: 0.42118 | val_0_auc: 0.95591 |  0:01:33s\n",
            "epoch 26 | loss: 0.41478 | val_0_auc: 0.95946 |  0:01:36s\n",
            "epoch 27 | loss: 0.41307 | val_0_auc: 0.95369 |  0:01:40s\n",
            "epoch 28 | loss: 0.41888 | val_0_auc: 0.961   |  0:01:44s\n",
            "epoch 29 | loss: 0.40672 | val_0_auc: 0.95619 |  0:01:48s\n",
            "epoch 30 | loss: 0.4085  | val_0_auc: 0.95685 |  0:01:51s\n",
            "epoch 31 | loss: 0.40237 | val_0_auc: 0.9578  |  0:01:56s\n",
            "epoch 32 | loss: 0.41001 | val_0_auc: 0.95943 |  0:02:00s\n",
            "epoch 33 | loss: 0.39736 | val_0_auc: 0.95952 |  0:02:04s\n",
            "epoch 34 | loss: 0.39537 | val_0_auc: 0.95706 |  0:02:09s\n",
            "epoch 35 | loss: 0.39921 | val_0_auc: 0.95961 |  0:02:13s\n",
            "epoch 36 | loss: 0.39233 | val_0_auc: 0.96123 |  0:02:17s\n",
            "epoch 37 | loss: 0.39644 | val_0_auc: 0.95641 |  0:02:21s\n",
            "epoch 38 | loss: 0.39225 | val_0_auc: 0.95806 |  0:02:25s\n",
            "epoch 39 | loss: 0.38403 | val_0_auc: 0.96035 |  0:02:29s\n",
            "epoch 40 | loss: 0.39448 | val_0_auc: 0.95689 |  0:02:34s\n",
            "epoch 41 | loss: 0.38066 | val_0_auc: 0.96141 |  0:02:37s\n",
            "epoch 42 | loss: 0.38459 | val_0_auc: 0.96522 |  0:02:41s\n",
            "epoch 43 | loss: 0.38025 | val_0_auc: 0.96049 |  0:02:46s\n",
            "epoch 44 | loss: 0.37878 | val_0_auc: 0.96042 |  0:02:51s\n",
            "epoch 45 | loss: 0.37717 | val_0_auc: 0.95922 |  0:02:55s\n",
            "epoch 46 | loss: 0.38101 | val_0_auc: 0.95625 |  0:03:00s\n",
            "epoch 47 | loss: 0.3843  | val_0_auc: 0.96237 |  0:03:04s\n",
            "epoch 48 | loss: 0.37759 | val_0_auc: 0.96129 |  0:03:08s\n",
            "epoch 49 | loss: 0.38219 | val_0_auc: 0.96234 |  0:03:13s\n",
            "epoch 50 | loss: 0.37753 | val_0_auc: 0.96293 |  0:03:17s\n",
            "epoch 51 | loss: 0.36648 | val_0_auc: 0.96125 |  0:03:21s\n",
            "epoch 52 | loss: 0.37697 | val_0_auc: 0.96214 |  0:03:26s\n",
            "\n",
            "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.96522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:41:41,685] Trial 27 finished with value: 0.9652229145803196 and parameters: {'n_d': 44, 'n_a': 38, 'n_steps': 6, 'gamma': 0.18757937074616227, 'momentum': 0.0517197822172106, 'lambda_sparse': 0.0732733411296172, 'lr': 0.0006354079658040633, 'weight_decay': 0.0001359602550098496}. Best is trial 25 with value: 0.9688608854765526.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.00935 | val_0_auc: 0.46737 |  0:00:02s\n",
            "epoch 1  | loss: 0.86062 | val_0_auc: 0.47607 |  0:00:04s\n",
            "epoch 2  | loss: 0.79346 | val_0_auc: 0.59608 |  0:00:06s\n",
            "epoch 3  | loss: 0.76131 | val_0_auc: 0.67371 |  0:00:09s\n",
            "epoch 4  | loss: 0.72852 | val_0_auc: 0.70337 |  0:00:11s\n",
            "epoch 5  | loss: 0.72136 | val_0_auc: 0.72421 |  0:00:13s\n",
            "epoch 6  | loss: 0.70894 | val_0_auc: 0.75172 |  0:00:15s\n",
            "epoch 7  | loss: 0.69481 | val_0_auc: 0.73939 |  0:00:17s\n",
            "epoch 8  | loss: 0.67232 | val_0_auc: 0.77401 |  0:00:20s\n",
            "epoch 9  | loss: 0.67182 | val_0_auc: 0.76832 |  0:00:22s\n",
            "epoch 10 | loss: 0.65367 | val_0_auc: 0.78115 |  0:00:25s\n",
            "epoch 11 | loss: 0.65934 | val_0_auc: 0.79132 |  0:00:27s\n",
            "epoch 12 | loss: 0.63986 | val_0_auc: 0.79964 |  0:00:29s\n",
            "epoch 13 | loss: 0.63574 | val_0_auc: 0.80055 |  0:00:32s\n",
            "epoch 14 | loss: 0.63159 | val_0_auc: 0.81713 |  0:00:34s\n",
            "epoch 15 | loss: 0.62293 | val_0_auc: 0.81019 |  0:00:36s\n",
            "epoch 16 | loss: 0.61046 | val_0_auc: 0.81299 |  0:00:39s\n",
            "epoch 17 | loss: 0.60117 | val_0_auc: 0.82329 |  0:00:41s\n",
            "epoch 18 | loss: 0.59632 | val_0_auc: 0.82488 |  0:00:43s\n",
            "epoch 19 | loss: 0.59625 | val_0_auc: 0.82791 |  0:00:46s\n",
            "epoch 20 | loss: 0.59452 | val_0_auc: 0.83667 |  0:00:48s\n",
            "epoch 21 | loss: 0.58592 | val_0_auc: 0.84701 |  0:00:51s\n",
            "epoch 22 | loss: 0.57106 | val_0_auc: 0.84062 |  0:00:53s\n",
            "epoch 23 | loss: 0.5691  | val_0_auc: 0.842   |  0:00:55s\n",
            "epoch 24 | loss: 0.57103 | val_0_auc: 0.84231 |  0:00:58s\n",
            "epoch 25 | loss: 0.55388 | val_0_auc: 0.85806 |  0:01:00s\n",
            "epoch 26 | loss: 0.56321 | val_0_auc: 0.85661 |  0:01:02s\n",
            "epoch 27 | loss: 0.55289 | val_0_auc: 0.86353 |  0:01:04s\n",
            "epoch 28 | loss: 0.54698 | val_0_auc: 0.86004 |  0:01:07s\n",
            "epoch 29 | loss: 0.54026 | val_0_auc: 0.86539 |  0:01:09s\n",
            "epoch 30 | loss: 0.53941 | val_0_auc: 0.86623 |  0:01:12s\n",
            "epoch 31 | loss: 0.54023 | val_0_auc: 0.87755 |  0:01:14s\n",
            "epoch 32 | loss: 0.53517 | val_0_auc: 0.86961 |  0:01:16s\n",
            "epoch 33 | loss: 0.53048 | val_0_auc: 0.87375 |  0:01:18s\n",
            "epoch 34 | loss: 0.52551 | val_0_auc: 0.88477 |  0:01:21s\n",
            "epoch 35 | loss: 0.52247 | val_0_auc: 0.87986 |  0:01:23s\n",
            "epoch 36 | loss: 0.53177 | val_0_auc: 0.88309 |  0:01:26s\n",
            "epoch 37 | loss: 0.5204  | val_0_auc: 0.8813  |  0:01:28s\n",
            "epoch 38 | loss: 0.51505 | val_0_auc: 0.887   |  0:01:30s\n",
            "epoch 39 | loss: 0.5172  | val_0_auc: 0.88452 |  0:01:32s\n",
            "epoch 40 | loss: 0.51062 | val_0_auc: 0.89119 |  0:01:35s\n",
            "epoch 41 | loss: 0.50265 | val_0_auc: 0.88119 |  0:01:37s\n",
            "epoch 42 | loss: 0.5011  | val_0_auc: 0.89461 |  0:01:39s\n",
            "epoch 43 | loss: 0.5084  | val_0_auc: 0.89753 |  0:01:41s\n",
            "epoch 44 | loss: 0.49793 | val_0_auc: 0.89073 |  0:01:43s\n",
            "epoch 45 | loss: 0.49154 | val_0_auc: 0.90143 |  0:01:46s\n",
            "epoch 46 | loss: 0.50224 | val_0_auc: 0.89639 |  0:01:48s\n",
            "epoch 47 | loss: 0.49284 | val_0_auc: 0.89798 |  0:01:50s\n",
            "epoch 48 | loss: 0.49563 | val_0_auc: 0.89988 |  0:01:53s\n",
            "epoch 49 | loss: 0.48732 | val_0_auc: 0.90355 |  0:01:55s\n",
            "epoch 50 | loss: 0.48633 | val_0_auc: 0.90836 |  0:01:57s\n",
            "epoch 51 | loss: 0.48394 | val_0_auc: 0.90073 |  0:02:00s\n",
            "epoch 52 | loss: 0.47962 | val_0_auc: 0.90998 |  0:02:02s\n",
            "epoch 53 | loss: 0.47801 | val_0_auc: 0.90713 |  0:02:05s\n",
            "epoch 54 | loss: 0.47859 | val_0_auc: 0.90712 |  0:02:07s\n",
            "epoch 55 | loss: 0.47612 | val_0_auc: 0.90362 |  0:02:09s\n",
            "epoch 56 | loss: 0.48221 | val_0_auc: 0.91214 |  0:02:12s\n",
            "epoch 57 | loss: 0.47138 | val_0_auc: 0.90511 |  0:02:14s\n",
            "epoch 58 | loss: 0.46699 | val_0_auc: 0.90735 |  0:02:16s\n",
            "epoch 59 | loss: 0.46547 | val_0_auc: 0.91542 |  0:02:18s\n",
            "epoch 60 | loss: 0.46346 | val_0_auc: 0.91152 |  0:02:21s\n",
            "epoch 61 | loss: 0.46232 | val_0_auc: 0.90748 |  0:02:24s\n",
            "epoch 62 | loss: 0.46815 | val_0_auc: 0.90486 |  0:02:26s\n",
            "epoch 63 | loss: 0.45861 | val_0_auc: 0.91079 |  0:02:28s\n",
            "epoch 64 | loss: 0.45934 | val_0_auc: 0.9102  |  0:02:31s\n",
            "epoch 65 | loss: 0.45693 | val_0_auc: 0.90479 |  0:02:33s\n",
            "epoch 66 | loss: 0.45997 | val_0_auc: 0.91416 |  0:02:35s\n",
            "epoch 67 | loss: 0.45638 | val_0_auc: 0.90835 |  0:02:37s\n",
            "epoch 68 | loss: 0.44713 | val_0_auc: 0.90743 |  0:02:40s\n",
            "epoch 69 | loss: 0.44266 | val_0_auc: 0.91727 |  0:02:42s\n",
            "epoch 70 | loss: 0.44846 | val_0_auc: 0.91112 |  0:02:45s\n",
            "epoch 71 | loss: 0.45071 | val_0_auc: 0.91409 |  0:02:47s\n",
            "epoch 72 | loss: 0.44723 | val_0_auc: 0.91482 |  0:02:50s\n",
            "epoch 73 | loss: 0.43515 | val_0_auc: 0.9159  |  0:02:52s\n",
            "epoch 74 | loss: 0.43205 | val_0_auc: 0.91744 |  0:02:54s\n",
            "epoch 75 | loss: 0.44456 | val_0_auc: 0.91854 |  0:02:56s\n",
            "epoch 76 | loss: 0.45083 | val_0_auc: 0.91726 |  0:02:59s\n",
            "epoch 77 | loss: 0.43721 | val_0_auc: 0.91933 |  0:03:01s\n",
            "epoch 78 | loss: 0.43757 | val_0_auc: 0.91977 |  0:03:03s\n",
            "epoch 79 | loss: 0.43322 | val_0_auc: 0.92151 |  0:03:06s\n",
            "epoch 80 | loss: 0.44406 | val_0_auc: 0.92197 |  0:03:08s\n",
            "epoch 81 | loss: 0.44194 | val_0_auc: 0.92419 |  0:03:11s\n",
            "epoch 82 | loss: 0.4352  | val_0_auc: 0.9206  |  0:03:14s\n",
            "epoch 83 | loss: 0.43629 | val_0_auc: 0.92102 |  0:03:16s\n",
            "epoch 84 | loss: 0.42764 | val_0_auc: 0.91815 |  0:03:18s\n",
            "epoch 85 | loss: 0.431   | val_0_auc: 0.92171 |  0:03:21s\n",
            "epoch 86 | loss: 0.42629 | val_0_auc: 0.92555 |  0:03:23s\n",
            "epoch 87 | loss: 0.42502 | val_0_auc: 0.92393 |  0:03:26s\n",
            "epoch 88 | loss: 0.42695 | val_0_auc: 0.92846 |  0:03:28s\n",
            "epoch 89 | loss: 0.42785 | val_0_auc: 0.92189 |  0:03:31s\n",
            "epoch 90 | loss: 0.42339 | val_0_auc: 0.92255 |  0:03:33s\n",
            "epoch 91 | loss: 0.42935 | val_0_auc: 0.92449 |  0:03:35s\n",
            "epoch 92 | loss: 0.42787 | val_0_auc: 0.92144 |  0:03:38s\n",
            "epoch 93 | loss: 0.42144 | val_0_auc: 0.92738 |  0:03:40s\n",
            "epoch 94 | loss: 0.42161 | val_0_auc: 0.92835 |  0:03:43s\n",
            "epoch 95 | loss: 0.41456 | val_0_auc: 0.93088 |  0:03:45s\n",
            "epoch 96 | loss: 0.42542 | val_0_auc: 0.9298  |  0:03:47s\n",
            "epoch 97 | loss: 0.4174  | val_0_auc: 0.9258  |  0:03:49s\n",
            "epoch 98 | loss: 0.42083 | val_0_auc: 0.92857 |  0:03:52s\n",
            "epoch 99 | loss: 0.41633 | val_0_auc: 0.92983 |  0:03:54s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_auc = 0.93088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:45:37,673] Trial 28 finished with value: 0.930883189298122 and parameters: {'n_d': 23, 'n_a': 24, 'n_steps': 4, 'gamma': 0.42149911813615415, 'momentum': 0.1624622433293294, 'lambda_sparse': 0.03489028388839569, 'lr': 0.00026058875987261233, 'weight_decay': 6.575141564935179e-06}. Best is trial 25 with value: 0.9688608854765526.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.85972 | val_0_auc: 0.49957 |  0:00:02s\n",
            "epoch 1  | loss: 0.59724 | val_0_auc: 0.73423 |  0:00:05s\n",
            "epoch 2  | loss: 0.53937 | val_0_auc: 0.86362 |  0:00:09s\n",
            "epoch 3  | loss: 0.51259 | val_0_auc: 0.90379 |  0:00:12s\n",
            "epoch 4  | loss: 0.49419 | val_0_auc: 0.9278  |  0:00:15s\n",
            "epoch 5  | loss: 0.49073 | val_0_auc: 0.9285  |  0:00:18s\n",
            "epoch 6  | loss: 0.46544 | val_0_auc: 0.93396 |  0:00:22s\n",
            "epoch 7  | loss: 0.4589  | val_0_auc: 0.94132 |  0:00:25s\n",
            "epoch 8  | loss: 0.43803 | val_0_auc: 0.93979 |  0:00:28s\n",
            "epoch 9  | loss: 0.44441 | val_0_auc: 0.94315 |  0:00:31s\n",
            "epoch 10 | loss: 0.43582 | val_0_auc: 0.94704 |  0:00:35s\n",
            "epoch 11 | loss: 0.4318  | val_0_auc: 0.94076 |  0:00:38s\n",
            "epoch 12 | loss: 0.41979 | val_0_auc: 0.95251 |  0:00:41s\n",
            "epoch 13 | loss: 0.42656 | val_0_auc: 0.94714 |  0:00:44s\n",
            "epoch 14 | loss: 0.41698 | val_0_auc: 0.95214 |  0:00:48s\n",
            "epoch 15 | loss: 0.40344 | val_0_auc: 0.95232 |  0:00:51s\n",
            "epoch 16 | loss: 0.41027 | val_0_auc: 0.94997 |  0:00:53s\n",
            "epoch 17 | loss: 0.40179 | val_0_auc: 0.9544  |  0:00:56s\n",
            "epoch 18 | loss: 0.40213 | val_0_auc: 0.95154 |  0:01:00s\n",
            "epoch 19 | loss: 0.39284 | val_0_auc: 0.95369 |  0:01:02s\n",
            "epoch 20 | loss: 0.3978  | val_0_auc: 0.95875 |  0:01:05s\n",
            "epoch 21 | loss: 0.3883  | val_0_auc: 0.96171 |  0:01:08s\n",
            "epoch 22 | loss: 0.39241 | val_0_auc: 0.95748 |  0:01:12s\n",
            "epoch 23 | loss: 0.38467 | val_0_auc: 0.95637 |  0:01:15s\n",
            "epoch 24 | loss: 0.38833 | val_0_auc: 0.95769 |  0:01:18s\n",
            "epoch 25 | loss: 0.38393 | val_0_auc: 0.95852 |  0:01:20s\n",
            "epoch 26 | loss: 0.36941 | val_0_auc: 0.95705 |  0:01:24s\n",
            "epoch 27 | loss: 0.36644 | val_0_auc: 0.95809 |  0:01:27s\n",
            "epoch 28 | loss: 0.36721 | val_0_auc: 0.95507 |  0:01:31s\n",
            "epoch 29 | loss: 0.36925 | val_0_auc: 0.96221 |  0:01:34s\n",
            "epoch 30 | loss: 0.35834 | val_0_auc: 0.96002 |  0:01:38s\n",
            "epoch 31 | loss: 0.36403 | val_0_auc: 0.95079 |  0:01:41s\n",
            "epoch 32 | loss: 0.35938 | val_0_auc: 0.96113 |  0:01:44s\n",
            "epoch 33 | loss: 0.34989 | val_0_auc: 0.96166 |  0:01:47s\n",
            "epoch 34 | loss: 0.35145 | val_0_auc: 0.96042 |  0:01:51s\n",
            "epoch 35 | loss: 0.35413 | val_0_auc: 0.96308 |  0:01:54s\n",
            "epoch 36 | loss: 0.34404 | val_0_auc: 0.96314 |  0:01:57s\n",
            "epoch 37 | loss: 0.34296 | val_0_auc: 0.96492 |  0:02:01s\n",
            "epoch 38 | loss: 0.344   | val_0_auc: 0.96761 |  0:02:05s\n",
            "epoch 39 | loss: 0.33662 | val_0_auc: 0.96632 |  0:02:08s\n",
            "epoch 40 | loss: 0.34765 | val_0_auc: 0.96455 |  0:02:11s\n",
            "epoch 41 | loss: 0.33743 | val_0_auc: 0.96239 |  0:02:15s\n",
            "epoch 42 | loss: 0.34107 | val_0_auc: 0.96189 |  0:02:19s\n",
            "epoch 43 | loss: 0.33945 | val_0_auc: 0.96418 |  0:02:22s\n",
            "epoch 44 | loss: 0.33966 | val_0_auc: 0.96647 |  0:02:26s\n",
            "epoch 45 | loss: 0.33091 | val_0_auc: 0.96392 |  0:02:29s\n",
            "epoch 46 | loss: 0.33266 | val_0_auc: 0.96739 |  0:02:33s\n",
            "epoch 47 | loss: 0.33038 | val_0_auc: 0.96759 |  0:02:37s\n",
            "epoch 48 | loss: 0.33325 | val_0_auc: 0.96705 |  0:02:41s\n",
            "\n",
            "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.96761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:48:20,970] Trial 29 finished with value: 0.9676121681935635 and parameters: {'n_d': 33, 'n_a': 13, 'n_steps': 6, 'gamma': 0.2449142079602216, 'momentum': 0.05526714171621909, 'lambda_sparse': 0.05269315150862769, 'lr': 0.0017433215344193971, 'weight_decay': 4.4434088695485745e-05}. Best is trial 25 with value: 0.9688608854765526.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.00355 | val_0_auc: 0.52365 |  0:00:02s\n",
            "epoch 1  | loss: 0.68305 | val_0_auc: 0.68602 |  0:00:05s\n",
            "epoch 2  | loss: 0.63173 | val_0_auc: 0.79031 |  0:00:09s\n",
            "epoch 3  | loss: 0.59152 | val_0_auc: 0.86232 |  0:00:12s\n",
            "epoch 4  | loss: 0.58309 | val_0_auc: 0.87875 |  0:00:15s\n",
            "epoch 5  | loss: 0.54719 | val_0_auc: 0.89755 |  0:00:18s\n",
            "epoch 6  | loss: 0.53718 | val_0_auc: 0.9061  |  0:00:21s\n",
            "epoch 7  | loss: 0.51891 | val_0_auc: 0.91808 |  0:00:24s\n",
            "epoch 8  | loss: 0.49967 | val_0_auc: 0.92008 |  0:00:27s\n",
            "epoch 9  | loss: 0.49313 | val_0_auc: 0.92866 |  0:00:30s\n",
            "epoch 10 | loss: 0.48163 | val_0_auc: 0.92812 |  0:00:34s\n",
            "epoch 11 | loss: 0.47202 | val_0_auc: 0.9319  |  0:00:36s\n",
            "epoch 12 | loss: 0.45892 | val_0_auc: 0.93592 |  0:00:39s\n",
            "epoch 13 | loss: 0.47305 | val_0_auc: 0.93492 |  0:00:42s\n",
            "epoch 14 | loss: 0.45356 | val_0_auc: 0.94244 |  0:00:46s\n",
            "epoch 15 | loss: 0.44984 | val_0_auc: 0.9432  |  0:00:49s\n",
            "epoch 16 | loss: 0.44462 | val_0_auc: 0.94225 |  0:00:52s\n",
            "epoch 17 | loss: 0.43879 | val_0_auc: 0.94083 |  0:00:56s\n",
            "epoch 18 | loss: 0.43487 | val_0_auc: 0.94576 |  0:00:59s\n",
            "epoch 19 | loss: 0.43137 | val_0_auc: 0.94767 |  0:01:02s\n",
            "epoch 20 | loss: 0.42822 | val_0_auc: 0.94568 |  0:01:05s\n",
            "epoch 21 | loss: 0.43348 | val_0_auc: 0.94692 |  0:01:08s\n",
            "epoch 22 | loss: 0.43254 | val_0_auc: 0.94552 |  0:01:11s\n",
            "epoch 23 | loss: 0.42522 | val_0_auc: 0.94954 |  0:01:14s\n",
            "epoch 24 | loss: 0.42591 | val_0_auc: 0.94956 |  0:01:17s\n",
            "epoch 25 | loss: 0.41226 | val_0_auc: 0.94819 |  0:01:19s\n",
            "epoch 26 | loss: 0.4199  | val_0_auc: 0.94893 |  0:01:23s\n",
            "epoch 27 | loss: 0.40993 | val_0_auc: 0.95017 |  0:01:25s\n",
            "epoch 28 | loss: 0.41475 | val_0_auc: 0.94847 |  0:01:28s\n",
            "epoch 29 | loss: 0.4048  | val_0_auc: 0.95116 |  0:01:31s\n",
            "epoch 30 | loss: 0.41091 | val_0_auc: 0.95063 |  0:01:35s\n",
            "epoch 31 | loss: 0.39897 | val_0_auc: 0.95049 |  0:01:38s\n",
            "epoch 32 | loss: 0.40345 | val_0_auc: 0.95437 |  0:01:41s\n",
            "epoch 33 | loss: 0.39681 | val_0_auc: 0.95296 |  0:01:44s\n",
            "epoch 34 | loss: 0.38984 | val_0_auc: 0.95035 |  0:01:47s\n",
            "epoch 35 | loss: 0.3897  | val_0_auc: 0.95309 |  0:01:51s\n",
            "epoch 36 | loss: 0.39524 | val_0_auc: 0.95363 |  0:01:54s\n",
            "epoch 37 | loss: 0.38808 | val_0_auc: 0.95398 |  0:01:57s\n",
            "epoch 38 | loss: 0.3967  | val_0_auc: 0.9555  |  0:02:01s\n",
            "epoch 39 | loss: 0.38626 | val_0_auc: 0.95455 |  0:02:04s\n",
            "epoch 40 | loss: 0.38397 | val_0_auc: 0.95717 |  0:02:08s\n",
            "epoch 41 | loss: 0.38526 | val_0_auc: 0.95609 |  0:02:12s\n",
            "epoch 42 | loss: 0.38021 | val_0_auc: 0.95459 |  0:02:14s\n",
            "epoch 43 | loss: 0.37516 | val_0_auc: 0.95593 |  0:02:18s\n",
            "epoch 44 | loss: 0.38685 | val_0_auc: 0.95683 |  0:02:21s\n",
            "epoch 45 | loss: 0.37646 | val_0_auc: 0.95495 |  0:02:24s\n",
            "epoch 46 | loss: 0.38624 | val_0_auc: 0.95742 |  0:02:27s\n",
            "epoch 47 | loss: 0.37826 | val_0_auc: 0.95774 |  0:02:30s\n",
            "epoch 48 | loss: 0.38035 | val_0_auc: 0.95701 |  0:02:33s\n",
            "epoch 49 | loss: 0.37468 | val_0_auc: 0.95501 |  0:02:37s\n",
            "epoch 50 | loss: 0.3734  | val_0_auc: 0.95777 |  0:02:40s\n",
            "epoch 51 | loss: 0.37844 | val_0_auc: 0.95592 |  0:02:43s\n",
            "epoch 52 | loss: 0.37352 | val_0_auc: 0.95842 |  0:02:46s\n",
            "epoch 53 | loss: 0.3689  | val_0_auc: 0.96026 |  0:02:50s\n",
            "epoch 54 | loss: 0.36297 | val_0_auc: 0.96053 |  0:02:53s\n",
            "epoch 55 | loss: 0.3668  | val_0_auc: 0.95869 |  0:02:56s\n",
            "epoch 56 | loss: 0.36537 | val_0_auc: 0.9612  |  0:02:59s\n",
            "epoch 57 | loss: 0.35645 | val_0_auc: 0.95912 |  0:03:03s\n",
            "epoch 58 | loss: 0.36006 | val_0_auc: 0.95958 |  0:03:06s\n",
            "epoch 59 | loss: 0.36622 | val_0_auc: 0.95943 |  0:03:09s\n",
            "epoch 60 | loss: 0.36057 | val_0_auc: 0.95978 |  0:03:13s\n",
            "epoch 61 | loss: 0.36688 | val_0_auc: 0.96093 |  0:03:17s\n",
            "epoch 62 | loss: 0.36324 | val_0_auc: 0.96245 |  0:03:20s\n",
            "epoch 63 | loss: 0.34851 | val_0_auc: 0.96135 |  0:03:23s\n",
            "epoch 64 | loss: 0.35059 | val_0_auc: 0.96072 |  0:03:27s\n",
            "epoch 65 | loss: 0.35315 | val_0_auc: 0.96141 |  0:03:31s\n",
            "epoch 66 | loss: 0.35156 | val_0_auc: 0.9595  |  0:03:34s\n",
            "epoch 67 | loss: 0.34874 | val_0_auc: 0.95851 |  0:03:37s\n",
            "epoch 68 | loss: 0.35772 | val_0_auc: 0.95816 |  0:03:40s\n",
            "epoch 69 | loss: 0.34286 | val_0_auc: 0.95906 |  0:03:43s\n",
            "epoch 70 | loss: 0.34633 | val_0_auc: 0.96176 |  0:03:46s\n",
            "epoch 71 | loss: 0.34239 | val_0_auc: 0.96355 |  0:03:50s\n",
            "epoch 72 | loss: 0.3487  | val_0_auc: 0.96219 |  0:03:53s\n",
            "epoch 73 | loss: 0.35168 | val_0_auc: 0.95967 |  0:03:56s\n",
            "epoch 74 | loss: 0.33623 | val_0_auc: 0.96385 |  0:03:59s\n",
            "epoch 75 | loss: 0.33925 | val_0_auc: 0.96437 |  0:04:03s\n",
            "epoch 76 | loss: 0.34134 | val_0_auc: 0.96212 |  0:04:06s\n",
            "epoch 77 | loss: 0.33869 | val_0_auc: 0.96216 |  0:04:10s\n",
            "epoch 78 | loss: 0.34525 | val_0_auc: 0.96399 |  0:04:13s\n",
            "epoch 79 | loss: 0.34085 | val_0_auc: 0.96427 |  0:04:17s\n",
            "epoch 80 | loss: 0.34325 | val_0_auc: 0.96496 |  0:04:20s\n",
            "epoch 81 | loss: 0.33925 | val_0_auc: 0.96702 |  0:04:23s\n",
            "epoch 82 | loss: 0.34454 | val_0_auc: 0.96448 |  0:04:27s\n",
            "epoch 83 | loss: 0.34159 | val_0_auc: 0.96447 |  0:04:30s\n",
            "epoch 84 | loss: 0.33943 | val_0_auc: 0.96265 |  0:04:33s\n",
            "epoch 85 | loss: 0.34012 | val_0_auc: 0.96418 |  0:04:36s\n",
            "epoch 86 | loss: 0.32555 | val_0_auc: 0.96543 |  0:04:39s\n",
            "epoch 87 | loss: 0.33621 | val_0_auc: 0.96758 |  0:04:43s\n",
            "epoch 88 | loss: 0.33353 | val_0_auc: 0.96613 |  0:04:46s\n",
            "epoch 89 | loss: 0.32921 | val_0_auc: 0.96588 |  0:04:49s\n",
            "epoch 90 | loss: 0.32778 | val_0_auc: 0.96607 |  0:04:53s\n",
            "epoch 91 | loss: 0.32292 | val_0_auc: 0.96697 |  0:04:56s\n",
            "epoch 92 | loss: 0.33297 | val_0_auc: 0.96613 |  0:04:59s\n",
            "epoch 93 | loss: 0.33065 | val_0_auc: 0.96659 |  0:05:02s\n",
            "epoch 94 | loss: 0.33015 | val_0_auc: 0.96814 |  0:05:06s\n",
            "epoch 95 | loss: 0.33555 | val_0_auc: 0.96819 |  0:05:09s\n",
            "epoch 96 | loss: 0.32436 | val_0_auc: 0.96543 |  0:05:13s\n",
            "epoch 97 | loss: 0.32179 | val_0_auc: 0.96484 |  0:05:16s\n",
            "epoch 98 | loss: 0.32634 | val_0_auc: 0.96878 |  0:05:19s\n",
            "epoch 99 | loss: 0.32712 | val_0_auc: 0.96532 |  0:05:22s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_auc = 0.96878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:53:45,570] Trial 30 finished with value: 0.9687836133674568 and parameters: {'n_d': 31, 'n_a': 9, 'n_steps': 6, 'gamma': 0.27252328735090847, 'momentum': 0.061472991309286656, 'lambda_sparse': 0.05399181545091379, 'lr': 0.0007898836703663313, 'weight_decay': 0.00015130363310058743}. Best is trial 25 with value: 0.9688608854765526.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.12879 | val_0_auc: 0.48937 |  0:00:02s\n",
            "epoch 1  | loss: 0.70766 | val_0_auc: 0.61985 |  0:00:06s\n",
            "epoch 2  | loss: 0.61784 | val_0_auc: 0.76001 |  0:00:09s\n",
            "epoch 3  | loss: 0.56949 | val_0_auc: 0.83815 |  0:00:12s\n",
            "epoch 4  | loss: 0.53403 | val_0_auc: 0.89127 |  0:00:15s\n",
            "epoch 5  | loss: 0.51171 | val_0_auc: 0.90676 |  0:00:19s\n",
            "epoch 6  | loss: 0.4969  | val_0_auc: 0.91696 |  0:00:22s\n",
            "epoch 7  | loss: 0.48598 | val_0_auc: 0.92536 |  0:00:24s\n",
            "epoch 8  | loss: 0.46428 | val_0_auc: 0.92886 |  0:00:27s\n",
            "epoch 9  | loss: 0.45781 | val_0_auc: 0.93647 |  0:00:31s\n",
            "epoch 10 | loss: 0.44253 | val_0_auc: 0.92854 |  0:00:34s\n",
            "epoch 11 | loss: 0.43909 | val_0_auc: 0.93651 |  0:00:37s\n",
            "epoch 12 | loss: 0.43862 | val_0_auc: 0.9435  |  0:00:40s\n",
            "epoch 13 | loss: 0.43845 | val_0_auc: 0.94419 |  0:00:44s\n",
            "epoch 14 | loss: 0.41656 | val_0_auc: 0.94082 |  0:00:47s\n",
            "epoch 15 | loss: 0.4109  | val_0_auc: 0.94663 |  0:00:50s\n",
            "epoch 16 | loss: 0.41613 | val_0_auc: 0.9392  |  0:00:53s\n",
            "epoch 17 | loss: 0.40455 | val_0_auc: 0.94684 |  0:00:57s\n",
            "epoch 18 | loss: 0.40665 | val_0_auc: 0.95056 |  0:01:00s\n",
            "epoch 19 | loss: 0.39105 | val_0_auc: 0.94811 |  0:01:03s\n",
            "epoch 20 | loss: 0.39341 | val_0_auc: 0.94982 |  0:01:06s\n",
            "epoch 21 | loss: 0.39012 | val_0_auc: 0.94687 |  0:01:09s\n",
            "epoch 22 | loss: 0.39541 | val_0_auc: 0.95044 |  0:01:12s\n",
            "epoch 23 | loss: 0.38319 | val_0_auc: 0.95167 |  0:01:15s\n",
            "epoch 24 | loss: 0.37652 | val_0_auc: 0.95468 |  0:01:19s\n",
            "epoch 25 | loss: 0.37916 | val_0_auc: 0.95329 |  0:01:22s\n",
            "epoch 26 | loss: 0.37907 | val_0_auc: 0.95346 |  0:01:25s\n",
            "epoch 27 | loss: 0.37603 | val_0_auc: 0.95612 |  0:01:28s\n",
            "epoch 28 | loss: 0.37922 | val_0_auc: 0.95396 |  0:01:31s\n",
            "epoch 29 | loss: 0.37517 | val_0_auc: 0.95667 |  0:01:34s\n",
            "epoch 30 | loss: 0.35775 | val_0_auc: 0.95239 |  0:01:37s\n",
            "epoch 31 | loss: 0.36452 | val_0_auc: 0.95251 |  0:01:40s\n",
            "epoch 32 | loss: 0.36771 | val_0_auc: 0.95182 |  0:01:44s\n",
            "epoch 33 | loss: 0.35611 | val_0_auc: 0.94941 |  0:01:47s\n",
            "epoch 34 | loss: 0.37087 | val_0_auc: 0.95322 |  0:01:50s\n",
            "epoch 35 | loss: 0.36116 | val_0_auc: 0.96228 |  0:01:53s\n",
            "epoch 36 | loss: 0.35619 | val_0_auc: 0.9589  |  0:01:57s\n",
            "epoch 37 | loss: 0.36008 | val_0_auc: 0.95464 |  0:02:00s\n",
            "epoch 38 | loss: 0.35524 | val_0_auc: 0.95933 |  0:02:03s\n",
            "epoch 39 | loss: 0.36523 | val_0_auc: 0.95329 |  0:02:07s\n",
            "epoch 40 | loss: 0.3586  | val_0_auc: 0.96194 |  0:02:10s\n",
            "epoch 41 | loss: 0.34904 | val_0_auc: 0.95934 |  0:02:13s\n",
            "epoch 42 | loss: 0.34827 | val_0_auc: 0.96369 |  0:02:17s\n",
            "epoch 43 | loss: 0.35697 | val_0_auc: 0.9604  |  0:02:20s\n",
            "epoch 44 | loss: 0.35027 | val_0_auc: 0.95335 |  0:02:24s\n",
            "epoch 45 | loss: 0.35077 | val_0_auc: 0.95631 |  0:02:26s\n",
            "epoch 46 | loss: 0.3461  | val_0_auc: 0.96198 |  0:02:30s\n",
            "epoch 47 | loss: 0.34107 | val_0_auc: 0.96091 |  0:02:33s\n",
            "epoch 48 | loss: 0.33815 | val_0_auc: 0.96119 |  0:02:37s\n",
            "epoch 49 | loss: 0.34136 | val_0_auc: 0.96454 |  0:02:41s\n",
            "epoch 50 | loss: 0.33573 | val_0_auc: 0.96198 |  0:02:44s\n",
            "epoch 51 | loss: 0.33768 | val_0_auc: 0.96181 |  0:02:48s\n",
            "epoch 52 | loss: 0.34143 | val_0_auc: 0.95818 |  0:02:52s\n",
            "epoch 53 | loss: 0.34128 | val_0_auc: 0.96343 |  0:02:55s\n",
            "epoch 54 | loss: 0.32885 | val_0_auc: 0.96303 |  0:02:58s\n",
            "epoch 55 | loss: 0.33996 | val_0_auc: 0.96424 |  0:03:02s\n",
            "epoch 56 | loss: 0.33196 | val_0_auc: 0.95662 |  0:03:05s\n",
            "epoch 57 | loss: 0.33381 | val_0_auc: 0.96457 |  0:03:08s\n",
            "epoch 58 | loss: 0.32823 | val_0_auc: 0.95852 |  0:03:11s\n",
            "epoch 59 | loss: 0.33187 | val_0_auc: 0.96375 |  0:03:15s\n",
            "epoch 60 | loss: 0.32585 | val_0_auc: 0.95675 |  0:03:19s\n",
            "epoch 61 | loss: 0.33213 | val_0_auc: 0.95808 |  0:03:22s\n",
            "epoch 62 | loss: 0.33273 | val_0_auc: 0.96319 |  0:03:26s\n",
            "epoch 63 | loss: 0.31885 | val_0_auc: 0.95816 |  0:03:29s\n",
            "epoch 64 | loss: 0.33154 | val_0_auc: 0.96622 |  0:03:32s\n",
            "epoch 65 | loss: 0.32369 | val_0_auc: 0.96588 |  0:03:35s\n",
            "epoch 66 | loss: 0.31945 | val_0_auc: 0.96335 |  0:03:39s\n",
            "epoch 67 | loss: 0.32243 | val_0_auc: 0.96566 |  0:03:42s\n",
            "epoch 68 | loss: 0.31715 | val_0_auc: 0.96819 |  0:03:45s\n",
            "epoch 69 | loss: 0.32006 | val_0_auc: 0.96682 |  0:03:48s\n",
            "epoch 70 | loss: 0.31249 | val_0_auc: 0.96592 |  0:03:52s\n",
            "epoch 71 | loss: 0.31295 | val_0_auc: 0.96887 |  0:03:55s\n",
            "epoch 72 | loss: 0.32753 | val_0_auc: 0.96543 |  0:03:58s\n",
            "epoch 73 | loss: 0.30939 | val_0_auc: 0.964   |  0:04:02s\n",
            "epoch 74 | loss: 0.31883 | val_0_auc: 0.96438 |  0:04:06s\n",
            "epoch 75 | loss: 0.3138  | val_0_auc: 0.96313 |  0:04:09s\n",
            "epoch 76 | loss: 0.31134 | val_0_auc: 0.96442 |  0:04:12s\n",
            "epoch 77 | loss: 0.31297 | val_0_auc: 0.96786 |  0:04:16s\n",
            "epoch 78 | loss: 0.31287 | val_0_auc: 0.96935 |  0:04:19s\n",
            "epoch 79 | loss: 0.30532 | val_0_auc: 0.96999 |  0:04:22s\n",
            "epoch 80 | loss: 0.30696 | val_0_auc: 0.96788 |  0:04:26s\n",
            "epoch 81 | loss: 0.3082  | val_0_auc: 0.96691 |  0:04:30s\n",
            "epoch 82 | loss: 0.31635 | val_0_auc: 0.96519 |  0:04:33s\n",
            "epoch 83 | loss: 0.3047  | val_0_auc: 0.96856 |  0:04:36s\n",
            "epoch 84 | loss: 0.31049 | val_0_auc: 0.96581 |  0:04:40s\n",
            "epoch 85 | loss: 0.29761 | val_0_auc: 0.96335 |  0:04:44s\n",
            "epoch 86 | loss: 0.29998 | val_0_auc: 0.97103 |  0:04:47s\n",
            "epoch 87 | loss: 0.28819 | val_0_auc: 0.96594 |  0:04:50s\n",
            "epoch 88 | loss: 0.30242 | val_0_auc: 0.97078 |  0:04:54s\n",
            "epoch 89 | loss: 0.30995 | val_0_auc: 0.96699 |  0:04:58s\n",
            "epoch 90 | loss: 0.29944 | val_0_auc: 0.96681 |  0:05:01s\n",
            "epoch 91 | loss: 0.29894 | val_0_auc: 0.97077 |  0:05:05s\n",
            "epoch 92 | loss: 0.29951 | val_0_auc: 0.96802 |  0:05:08s\n",
            "epoch 93 | loss: 0.29737 | val_0_auc: 0.97295 |  0:05:12s\n",
            "epoch 94 | loss: 0.30521 | val_0_auc: 0.96849 |  0:05:15s\n",
            "epoch 95 | loss: 0.29627 | val_0_auc: 0.96928 |  0:05:19s\n",
            "epoch 96 | loss: 0.30148 | val_0_auc: 0.97002 |  0:05:22s\n",
            "epoch 97 | loss: 0.29317 | val_0_auc: 0.97011 |  0:05:26s\n",
            "epoch 98 | loss: 0.29515 | val_0_auc: 0.9719  |  0:05:29s\n",
            "epoch 99 | loss: 0.29137 | val_0_auc: 0.96902 |  0:05:33s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_auc = 0.97295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 06:59:20,769] Trial 31 finished with value: 0.9729454891633594 and parameters: {'n_d': 30, 'n_a': 9, 'n_steps': 6, 'gamma': 0.48259597112357033, 'momentum': 0.049207247489644834, 'lambda_sparse': 0.05134131864389075, 'lr': 0.002069715749404568, 'weight_decay': 0.00022493849699163575}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.76896 | val_0_auc: 0.53534 |  0:00:02s\n",
            "epoch 1  | loss: 1.04145 | val_0_auc: 0.53468 |  0:00:05s\n",
            "epoch 2  | loss: 0.84472 | val_0_auc: 0.70805 |  0:00:09s\n",
            "epoch 3  | loss: 0.75401 | val_0_auc: 0.78795 |  0:00:12s\n",
            "epoch 4  | loss: 0.70574 | val_0_auc: 0.81711 |  0:00:15s\n",
            "epoch 5  | loss: 0.66083 | val_0_auc: 0.84854 |  0:00:18s\n",
            "epoch 6  | loss: 0.63222 | val_0_auc: 0.86314 |  0:00:21s\n",
            "epoch 7  | loss: 0.61111 | val_0_auc: 0.86272 |  0:00:24s\n",
            "epoch 8  | loss: 0.59366 | val_0_auc: 0.87488 |  0:00:26s\n",
            "epoch 9  | loss: 0.57403 | val_0_auc: 0.87483 |  0:00:29s\n",
            "epoch 10 | loss: 0.56645 | val_0_auc: 0.8807  |  0:00:33s\n",
            "epoch 11 | loss: 0.55853 | val_0_auc: 0.88535 |  0:00:35s\n",
            "epoch 12 | loss: 0.54063 | val_0_auc: 0.89305 |  0:00:39s\n",
            "epoch 13 | loss: 0.52618 | val_0_auc: 0.88715 |  0:00:43s\n",
            "epoch 14 | loss: 0.51068 | val_0_auc: 0.9012  |  0:00:47s\n",
            "epoch 15 | loss: 0.50167 | val_0_auc: 0.91324 |  0:00:50s\n",
            "epoch 16 | loss: 0.5052  | val_0_auc: 0.91145 |  0:00:53s\n",
            "epoch 17 | loss: 0.50125 | val_0_auc: 0.91137 |  0:00:56s\n",
            "epoch 18 | loss: 0.49774 | val_0_auc: 0.91801 |  0:00:59s\n",
            "epoch 19 | loss: 0.49293 | val_0_auc: 0.91938 |  0:01:02s\n",
            "epoch 20 | loss: 0.48538 | val_0_auc: 0.91826 |  0:01:05s\n",
            "epoch 21 | loss: 0.47485 | val_0_auc: 0.91755 |  0:01:08s\n",
            "epoch 22 | loss: 0.47259 | val_0_auc: 0.92369 |  0:01:11s\n",
            "epoch 23 | loss: 0.47323 | val_0_auc: 0.92648 |  0:01:14s\n",
            "epoch 24 | loss: 0.46177 | val_0_auc: 0.92475 |  0:01:17s\n",
            "epoch 25 | loss: 0.46769 | val_0_auc: 0.92609 |  0:01:21s\n",
            "epoch 26 | loss: 0.44857 | val_0_auc: 0.92946 |  0:01:24s\n",
            "epoch 27 | loss: 0.44989 | val_0_auc: 0.93388 |  0:01:28s\n",
            "epoch 28 | loss: 0.44615 | val_0_auc: 0.93249 |  0:01:30s\n",
            "epoch 29 | loss: 0.44696 | val_0_auc: 0.93502 |  0:01:34s\n",
            "epoch 30 | loss: 0.43851 | val_0_auc: 0.93881 |  0:01:38s\n",
            "epoch 31 | loss: 0.4384  | val_0_auc: 0.93721 |  0:01:41s\n",
            "epoch 32 | loss: 0.43866 | val_0_auc: 0.93303 |  0:01:44s\n",
            "epoch 33 | loss: 0.43572 | val_0_auc: 0.94155 |  0:01:48s\n",
            "epoch 34 | loss: 0.42861 | val_0_auc: 0.93567 |  0:01:51s\n",
            "epoch 35 | loss: 0.42814 | val_0_auc: 0.94255 |  0:01:54s\n",
            "epoch 36 | loss: 0.41788 | val_0_auc: 0.9397  |  0:01:57s\n",
            "epoch 37 | loss: 0.42287 | val_0_auc: 0.94057 |  0:02:00s\n",
            "epoch 38 | loss: 0.41373 | val_0_auc: 0.94282 |  0:02:04s\n",
            "epoch 39 | loss: 0.41471 | val_0_auc: 0.94612 |  0:02:07s\n",
            "epoch 40 | loss: 0.41182 | val_0_auc: 0.94063 |  0:02:10s\n",
            "epoch 41 | loss: 0.40629 | val_0_auc: 0.94197 |  0:02:13s\n",
            "epoch 42 | loss: 0.41133 | val_0_auc: 0.94576 |  0:02:17s\n",
            "epoch 43 | loss: 0.40455 | val_0_auc: 0.94825 |  0:02:20s\n",
            "epoch 44 | loss: 0.40166 | val_0_auc: 0.94789 |  0:02:24s\n",
            "epoch 45 | loss: 0.40639 | val_0_auc: 0.94562 |  0:02:27s\n",
            "epoch 46 | loss: 0.40991 | val_0_auc: 0.95001 |  0:02:30s\n",
            "epoch 47 | loss: 0.39992 | val_0_auc: 0.94401 |  0:02:33s\n",
            "epoch 48 | loss: 0.39459 | val_0_auc: 0.94784 |  0:02:37s\n",
            "epoch 49 | loss: 0.39955 | val_0_auc: 0.95271 |  0:02:40s\n",
            "epoch 50 | loss: 0.39135 | val_0_auc: 0.94915 |  0:02:43s\n",
            "epoch 51 | loss: 0.39598 | val_0_auc: 0.95239 |  0:02:46s\n",
            "epoch 52 | loss: 0.39715 | val_0_auc: 0.95058 |  0:02:49s\n",
            "epoch 53 | loss: 0.38387 | val_0_auc: 0.95518 |  0:02:53s\n",
            "epoch 54 | loss: 0.38025 | val_0_auc: 0.95209 |  0:02:56s\n",
            "epoch 55 | loss: 0.39805 | val_0_auc: 0.95021 |  0:02:59s\n",
            "epoch 56 | loss: 0.38533 | val_0_auc: 0.9533  |  0:03:03s\n",
            "epoch 57 | loss: 0.38721 | val_0_auc: 0.95432 |  0:03:06s\n",
            "epoch 58 | loss: 0.37781 | val_0_auc: 0.9544  |  0:03:09s\n",
            "epoch 59 | loss: 0.38218 | val_0_auc: 0.95151 |  0:03:12s\n",
            "epoch 60 | loss: 0.37505 | val_0_auc: 0.95388 |  0:03:16s\n",
            "epoch 61 | loss: 0.37339 | val_0_auc: 0.95556 |  0:03:19s\n",
            "epoch 62 | loss: 0.37091 | val_0_auc: 0.95265 |  0:03:22s\n",
            "epoch 63 | loss: 0.3732  | val_0_auc: 0.95547 |  0:03:26s\n",
            "epoch 64 | loss: 0.37701 | val_0_auc: 0.95586 |  0:03:29s\n",
            "epoch 65 | loss: 0.37132 | val_0_auc: 0.95901 |  0:03:32s\n",
            "epoch 66 | loss: 0.36407 | val_0_auc: 0.9576  |  0:03:35s\n",
            "epoch 67 | loss: 0.36436 | val_0_auc: 0.95631 |  0:03:38s\n",
            "epoch 68 | loss: 0.36951 | val_0_auc: 0.95555 |  0:03:42s\n",
            "epoch 69 | loss: 0.36908 | val_0_auc: 0.95763 |  0:03:45s\n",
            "epoch 70 | loss: 0.36319 | val_0_auc: 0.95729 |  0:03:48s\n",
            "epoch 71 | loss: 0.36498 | val_0_auc: 0.95641 |  0:03:52s\n",
            "epoch 72 | loss: 0.36559 | val_0_auc: 0.95741 |  0:03:55s\n",
            "epoch 73 | loss: 0.35065 | val_0_auc: 0.95946 |  0:03:58s\n",
            "epoch 74 | loss: 0.35504 | val_0_auc: 0.95723 |  0:04:03s\n",
            "epoch 75 | loss: 0.36178 | val_0_auc: 0.95622 |  0:04:06s\n",
            "epoch 76 | loss: 0.35898 | val_0_auc: 0.95936 |  0:04:10s\n",
            "epoch 77 | loss: 0.35534 | val_0_auc: 0.95409 |  0:04:13s\n",
            "epoch 78 | loss: 0.35934 | val_0_auc: 0.95826 |  0:04:17s\n",
            "epoch 79 | loss: 0.35509 | val_0_auc: 0.95784 |  0:04:20s\n",
            "epoch 80 | loss: 0.35804 | val_0_auc: 0.9593  |  0:04:23s\n",
            "epoch 81 | loss: 0.35588 | val_0_auc: 0.96142 |  0:04:27s\n",
            "epoch 82 | loss: 0.34981 | val_0_auc: 0.95714 |  0:04:30s\n",
            "epoch 83 | loss: 0.35592 | val_0_auc: 0.95769 |  0:04:33s\n",
            "epoch 84 | loss: 0.35093 | val_0_auc: 0.96035 |  0:04:36s\n",
            "epoch 85 | loss: 0.34801 | val_0_auc: 0.95895 |  0:04:39s\n",
            "epoch 86 | loss: 0.34767 | val_0_auc: 0.95977 |  0:04:43s\n",
            "epoch 87 | loss: 0.35015 | val_0_auc: 0.95823 |  0:04:46s\n",
            "epoch 88 | loss: 0.33919 | val_0_auc: 0.95889 |  0:04:49s\n",
            "epoch 89 | loss: 0.35369 | val_0_auc: 0.96001 |  0:04:53s\n",
            "epoch 90 | loss: 0.34702 | val_0_auc: 0.95715 |  0:04:56s\n",
            "epoch 91 | loss: 0.34061 | val_0_auc: 0.95826 |  0:04:59s\n",
            "\n",
            "Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_auc = 0.96142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:04:21,868] Trial 32 finished with value: 0.9614242176971676 and parameters: {'n_d': 30, 'n_a': 8, 'n_steps': 6, 'gamma': 0.4814199946981987, 'momentum': 0.052211523234807704, 'lambda_sparse': 0.04965510655881058, 'lr': 0.0006788549081587842, 'weight_decay': 0.00021658406006109387}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.96366 | val_0_auc: 0.56962 |  0:00:03s\n",
            "epoch 1  | loss: 0.7437  | val_0_auc: 0.65273 |  0:00:06s\n",
            "epoch 2  | loss: 0.64289 | val_0_auc: 0.79195 |  0:00:10s\n",
            "epoch 3  | loss: 0.58992 | val_0_auc: 0.85495 |  0:00:13s\n",
            "epoch 4  | loss: 0.56317 | val_0_auc: 0.87409 |  0:00:17s\n",
            "epoch 5  | loss: 0.54005 | val_0_auc: 0.87855 |  0:00:21s\n",
            "epoch 6  | loss: 0.51876 | val_0_auc: 0.90891 |  0:00:24s\n",
            "epoch 7  | loss: 0.49462 | val_0_auc: 0.9197  |  0:00:28s\n",
            "epoch 8  | loss: 0.48154 | val_0_auc: 0.92986 |  0:00:31s\n",
            "epoch 9  | loss: 0.47601 | val_0_auc: 0.93305 |  0:00:34s\n",
            "epoch 10 | loss: 0.46172 | val_0_auc: 0.92868 |  0:00:38s\n",
            "epoch 11 | loss: 0.472   | val_0_auc: 0.93412 |  0:00:41s\n",
            "epoch 12 | loss: 0.44194 | val_0_auc: 0.94209 |  0:00:45s\n",
            "epoch 13 | loss: 0.43058 | val_0_auc: 0.93873 |  0:00:48s\n",
            "epoch 14 | loss: 0.43555 | val_0_auc: 0.93218 |  0:00:51s\n",
            "epoch 15 | loss: 0.42064 | val_0_auc: 0.94521 |  0:00:55s\n",
            "epoch 16 | loss: 0.42232 | val_0_auc: 0.94576 |  0:00:59s\n",
            "epoch 17 | loss: 0.41762 | val_0_auc: 0.94212 |  0:01:03s\n",
            "epoch 18 | loss: 0.42262 | val_0_auc: 0.94988 |  0:01:06s\n",
            "epoch 19 | loss: 0.40009 | val_0_auc: 0.94528 |  0:01:10s\n",
            "epoch 20 | loss: 0.40535 | val_0_auc: 0.95274 |  0:01:13s\n",
            "epoch 21 | loss: 0.39866 | val_0_auc: 0.95525 |  0:01:16s\n",
            "epoch 22 | loss: 0.38948 | val_0_auc: 0.9532  |  0:01:21s\n",
            "epoch 23 | loss: 0.38609 | val_0_auc: 0.95536 |  0:01:25s\n",
            "epoch 24 | loss: 0.38342 | val_0_auc: 0.9484  |  0:01:28s\n",
            "epoch 25 | loss: 0.39067 | val_0_auc: 0.9524  |  0:01:32s\n",
            "epoch 26 | loss: 0.37232 | val_0_auc: 0.94962 |  0:01:35s\n",
            "epoch 27 | loss: 0.37351 | val_0_auc: 0.95199 |  0:01:39s\n",
            "epoch 28 | loss: 0.36737 | val_0_auc: 0.95086 |  0:01:42s\n",
            "epoch 29 | loss: 0.36575 | val_0_auc: 0.9559  |  0:01:46s\n",
            "epoch 30 | loss: 0.36239 | val_0_auc: 0.95509 |  0:01:49s\n",
            "epoch 31 | loss: 0.37107 | val_0_auc: 0.95147 |  0:01:53s\n",
            "epoch 32 | loss: 0.3585  | val_0_auc: 0.95287 |  0:01:56s\n",
            "epoch 33 | loss: 0.353   | val_0_auc: 0.9542  |  0:02:00s\n",
            "epoch 34 | loss: 0.35381 | val_0_auc: 0.95818 |  0:02:04s\n",
            "epoch 35 | loss: 0.3548  | val_0_auc: 0.95134 |  0:02:07s\n",
            "epoch 36 | loss: 0.34269 | val_0_auc: 0.96004 |  0:02:11s\n",
            "epoch 37 | loss: 0.34777 | val_0_auc: 0.95563 |  0:02:15s\n",
            "epoch 38 | loss: 0.34708 | val_0_auc: 0.95863 |  0:02:19s\n",
            "epoch 39 | loss: 0.33864 | val_0_auc: 0.96074 |  0:02:23s\n",
            "epoch 40 | loss: 0.34216 | val_0_auc: 0.96193 |  0:02:26s\n",
            "epoch 41 | loss: 0.34642 | val_0_auc: 0.9619  |  0:02:30s\n",
            "epoch 42 | loss: 0.33506 | val_0_auc: 0.95339 |  0:02:33s\n",
            "epoch 43 | loss: 0.32977 | val_0_auc: 0.95952 |  0:02:37s\n",
            "epoch 44 | loss: 0.32288 | val_0_auc: 0.95985 |  0:02:41s\n",
            "epoch 45 | loss: 0.34336 | val_0_auc: 0.95457 |  0:02:44s\n",
            "epoch 46 | loss: 0.33709 | val_0_auc: 0.95847 |  0:02:48s\n",
            "epoch 47 | loss: 0.33423 | val_0_auc: 0.9593  |  0:02:52s\n",
            "epoch 48 | loss: 0.32911 | val_0_auc: 0.95708 |  0:02:56s\n",
            "epoch 49 | loss: 0.32374 | val_0_auc: 0.95662 |  0:02:59s\n",
            "epoch 50 | loss: 0.33863 | val_0_auc: 0.95641 |  0:03:03s\n",
            "\n",
            "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.96193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:07:27,307] Trial 33 finished with value: 0.9619311227328363 and parameters: {'n_d': 22, 'n_a': 15, 'n_steps': 7, 'gamma': 0.6833421991997329, 'momentum': 0.05387878274566923, 'lambda_sparse': 0.06747291849265333, 'lr': 0.005188398709520337, 'weight_decay': 4.0811052149091936e-05}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.87186 | val_0_auc: 0.49647 |  0:00:02s\n",
            "epoch 1  | loss: 0.63591 | val_0_auc: 0.75214 |  0:00:05s\n",
            "epoch 2  | loss: 0.56626 | val_0_auc: 0.84531 |  0:00:08s\n",
            "epoch 3  | loss: 0.53642 | val_0_auc: 0.8923  |  0:00:11s\n",
            "epoch 4  | loss: 0.51269 | val_0_auc: 0.90534 |  0:00:14s\n",
            "epoch 5  | loss: 0.50272 | val_0_auc: 0.90802 |  0:00:17s\n",
            "epoch 6  | loss: 0.491   | val_0_auc: 0.92244 |  0:00:20s\n",
            "epoch 7  | loss: 0.4742  | val_0_auc: 0.9295  |  0:00:23s\n",
            "epoch 8  | loss: 0.46435 | val_0_auc: 0.93117 |  0:00:26s\n",
            "epoch 9  | loss: 0.45548 | val_0_auc: 0.93663 |  0:00:30s\n",
            "epoch 10 | loss: 0.44249 | val_0_auc: 0.94189 |  0:00:33s\n",
            "epoch 11 | loss: 0.43471 | val_0_auc: 0.94276 |  0:00:36s\n",
            "epoch 12 | loss: 0.43211 | val_0_auc: 0.94528 |  0:00:39s\n",
            "epoch 13 | loss: 0.42973 | val_0_auc: 0.9439  |  0:00:42s\n",
            "epoch 14 | loss: 0.42256 | val_0_auc: 0.94373 |  0:00:46s\n",
            "epoch 15 | loss: 0.42531 | val_0_auc: 0.94582 |  0:00:49s\n",
            "epoch 16 | loss: 0.4174  | val_0_auc: 0.94263 |  0:00:51s\n",
            "epoch 17 | loss: 0.41764 | val_0_auc: 0.94905 |  0:00:55s\n",
            "epoch 18 | loss: 0.40775 | val_0_auc: 0.95067 |  0:00:58s\n",
            "epoch 19 | loss: 0.41347 | val_0_auc: 0.95225 |  0:01:01s\n",
            "epoch 20 | loss: 0.39971 | val_0_auc: 0.94872 |  0:01:04s\n",
            "epoch 21 | loss: 0.405   | val_0_auc: 0.94968 |  0:01:07s\n",
            "epoch 22 | loss: 0.39738 | val_0_auc: 0.94957 |  0:01:11s\n",
            "epoch 23 | loss: 0.39455 | val_0_auc: 0.95228 |  0:01:14s\n",
            "epoch 24 | loss: 0.38782 | val_0_auc: 0.953   |  0:01:17s\n",
            "epoch 25 | loss: 0.39173 | val_0_auc: 0.9533  |  0:01:19s\n",
            "epoch 26 | loss: 0.39334 | val_0_auc: 0.95195 |  0:01:23s\n",
            "epoch 27 | loss: 0.38068 | val_0_auc: 0.95401 |  0:01:25s\n",
            "epoch 28 | loss: 0.38508 | val_0_auc: 0.95366 |  0:01:28s\n",
            "epoch 29 | loss: 0.38375 | val_0_auc: 0.95822 |  0:01:31s\n",
            "epoch 30 | loss: 0.38231 | val_0_auc: 0.95624 |  0:01:34s\n",
            "epoch 31 | loss: 0.38022 | val_0_auc: 0.95719 |  0:01:38s\n",
            "epoch 32 | loss: 0.3741  | val_0_auc: 0.9546  |  0:01:41s\n",
            "epoch 33 | loss: 0.37461 | val_0_auc: 0.95615 |  0:01:44s\n",
            "epoch 34 | loss: 0.36519 | val_0_auc: 0.95401 |  0:01:47s\n",
            "epoch 35 | loss: 0.37967 | val_0_auc: 0.9599  |  0:01:50s\n",
            "epoch 36 | loss: 0.36762 | val_0_auc: 0.95649 |  0:01:53s\n",
            "epoch 37 | loss: 0.3801  | val_0_auc: 0.9614  |  0:01:56s\n",
            "epoch 38 | loss: 0.37502 | val_0_auc: 0.95776 |  0:02:00s\n",
            "epoch 39 | loss: 0.36141 | val_0_auc: 0.95993 |  0:02:03s\n",
            "epoch 40 | loss: 0.3652  | val_0_auc: 0.95449 |  0:02:06s\n",
            "epoch 41 | loss: 0.36895 | val_0_auc: 0.95699 |  0:02:09s\n",
            "epoch 42 | loss: 0.36291 | val_0_auc: 0.9585  |  0:02:12s\n",
            "epoch 43 | loss: 0.36627 | val_0_auc: 0.96183 |  0:02:15s\n",
            "epoch 44 | loss: 0.36163 | val_0_auc: 0.95787 |  0:02:19s\n",
            "epoch 45 | loss: 0.35925 | val_0_auc: 0.96351 |  0:02:22s\n",
            "epoch 46 | loss: 0.36683 | val_0_auc: 0.95885 |  0:02:26s\n",
            "epoch 47 | loss: 0.34937 | val_0_auc: 0.96155 |  0:02:30s\n",
            "epoch 48 | loss: 0.35252 | val_0_auc: 0.95953 |  0:02:33s\n",
            "epoch 49 | loss: 0.353   | val_0_auc: 0.95923 |  0:02:37s\n",
            "epoch 50 | loss: 0.34539 | val_0_auc: 0.96303 |  0:02:40s\n",
            "epoch 51 | loss: 0.34904 | val_0_auc: 0.96106 |  0:02:43s\n",
            "epoch 52 | loss: 0.34671 | val_0_auc: 0.96235 |  0:02:46s\n",
            "epoch 53 | loss: 0.35563 | val_0_auc: 0.96543 |  0:02:50s\n",
            "epoch 54 | loss: 0.34206 | val_0_auc: 0.96581 |  0:02:53s\n",
            "epoch 55 | loss: 0.35123 | val_0_auc: 0.96485 |  0:02:56s\n",
            "epoch 56 | loss: 0.34738 | val_0_auc: 0.96374 |  0:03:00s\n",
            "epoch 57 | loss: 0.34798 | val_0_auc: 0.96106 |  0:03:04s\n",
            "epoch 58 | loss: 0.34779 | val_0_auc: 0.96308 |  0:03:07s\n",
            "epoch 59 | loss: 0.35165 | val_0_auc: 0.96318 |  0:03:10s\n",
            "epoch 60 | loss: 0.33822 | val_0_auc: 0.96073 |  0:03:14s\n",
            "epoch 61 | loss: 0.33292 | val_0_auc: 0.96491 |  0:03:17s\n",
            "epoch 62 | loss: 0.33416 | val_0_auc: 0.96352 |  0:03:21s\n",
            "epoch 63 | loss: 0.33339 | val_0_auc: 0.95812 |  0:03:24s\n",
            "epoch 64 | loss: 0.33752 | val_0_auc: 0.96276 |  0:03:28s\n",
            "\n",
            "Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_auc = 0.96581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:10:57,879] Trial 34 finished with value: 0.9658101826094482 and parameters: {'n_d': 16, 'n_a': 13, 'n_steps': 6, 'gamma': 0.28464696892951363, 'momentum': 0.010908244582534601, 'lambda_sparse': 0.051628770730158216, 'lr': 0.0019454892879653602, 'weight_decay': 0.00018862121120426492}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.68224 | val_0_auc: 0.60701 |  0:00:03s\n",
            "epoch 1  | loss: 1.12002 | val_0_auc: 0.64276 |  0:00:07s\n",
            "epoch 2  | loss: 0.91157 | val_0_auc: 0.67696 |  0:00:11s\n",
            "epoch 3  | loss: 0.82184 | val_0_auc: 0.75024 |  0:00:14s\n",
            "epoch 4  | loss: 0.76231 | val_0_auc: 0.80408 |  0:00:18s\n",
            "epoch 5  | loss: 0.71659 | val_0_auc: 0.83605 |  0:00:22s\n",
            "epoch 6  | loss: 0.68057 | val_0_auc: 0.8592  |  0:00:26s\n",
            "epoch 7  | loss: 0.66503 | val_0_auc: 0.86689 |  0:00:29s\n",
            "epoch 8  | loss: 0.64021 | val_0_auc: 0.87784 |  0:00:34s\n",
            "epoch 9  | loss: 0.62243 | val_0_auc: 0.88636 |  0:00:37s\n",
            "epoch 10 | loss: 0.6072  | val_0_auc: 0.89724 |  0:00:41s\n",
            "epoch 11 | loss: 0.59612 | val_0_auc: 0.90137 |  0:00:44s\n",
            "epoch 12 | loss: 0.57708 | val_0_auc: 0.89962 |  0:00:48s\n",
            "epoch 13 | loss: 0.57335 | val_0_auc: 0.90535 |  0:00:52s\n",
            "epoch 14 | loss: 0.56698 | val_0_auc: 0.90928 |  0:00:55s\n",
            "epoch 15 | loss: 0.55487 | val_0_auc: 0.91166 |  0:01:00s\n",
            "epoch 16 | loss: 0.5539  | val_0_auc: 0.91549 |  0:01:04s\n",
            "epoch 17 | loss: 0.54707 | val_0_auc: 0.91501 |  0:01:07s\n",
            "epoch 18 | loss: 0.53575 | val_0_auc: 0.91966 |  0:01:12s\n",
            "epoch 19 | loss: 0.53311 | val_0_auc: 0.92165 |  0:01:15s\n",
            "epoch 20 | loss: 0.52775 | val_0_auc: 0.92204 |  0:01:19s\n",
            "epoch 21 | loss: 0.53233 | val_0_auc: 0.92193 |  0:01:23s\n",
            "epoch 22 | loss: 0.51904 | val_0_auc: 0.92492 |  0:01:26s\n",
            "epoch 23 | loss: 0.5135  | val_0_auc: 0.92707 |  0:01:30s\n",
            "epoch 24 | loss: 0.50853 | val_0_auc: 0.92757 |  0:01:34s\n",
            "epoch 25 | loss: 0.50784 | val_0_auc: 0.92908 |  0:01:38s\n",
            "epoch 26 | loss: 0.49839 | val_0_auc: 0.92643 |  0:01:42s\n",
            "epoch 27 | loss: 0.50587 | val_0_auc: 0.93206 |  0:01:45s\n",
            "epoch 28 | loss: 0.49344 | val_0_auc: 0.93343 |  0:01:50s\n",
            "epoch 29 | loss: 0.49839 | val_0_auc: 0.92857 |  0:01:54s\n",
            "epoch 30 | loss: 0.48411 | val_0_auc: 0.9287  |  0:01:58s\n",
            "epoch 31 | loss: 0.48689 | val_0_auc: 0.9336  |  0:02:02s\n",
            "epoch 32 | loss: 0.48598 | val_0_auc: 0.93209 |  0:02:06s\n",
            "epoch 33 | loss: 0.47725 | val_0_auc: 0.93333 |  0:02:10s\n",
            "epoch 34 | loss: 0.47488 | val_0_auc: 0.93394 |  0:02:14s\n",
            "epoch 35 | loss: 0.4743  | val_0_auc: 0.93734 |  0:02:17s\n",
            "epoch 36 | loss: 0.48109 | val_0_auc: 0.93959 |  0:02:21s\n",
            "epoch 37 | loss: 0.47055 | val_0_auc: 0.9391  |  0:02:25s\n",
            "epoch 38 | loss: 0.46919 | val_0_auc: 0.94085 |  0:02:29s\n",
            "epoch 39 | loss: 0.46498 | val_0_auc: 0.94199 |  0:02:32s\n",
            "epoch 40 | loss: 0.47088 | val_0_auc: 0.94161 |  0:02:36s\n",
            "epoch 41 | loss: 0.46746 | val_0_auc: 0.94012 |  0:02:40s\n",
            "epoch 42 | loss: 0.45838 | val_0_auc: 0.94273 |  0:02:44s\n",
            "epoch 43 | loss: 0.45527 | val_0_auc: 0.94333 |  0:02:48s\n",
            "epoch 44 | loss: 0.46164 | val_0_auc: 0.9411  |  0:02:52s\n",
            "epoch 45 | loss: 0.45793 | val_0_auc: 0.94044 |  0:02:56s\n",
            "epoch 46 | loss: 0.4493  | val_0_auc: 0.94485 |  0:02:59s\n",
            "epoch 47 | loss: 0.45373 | val_0_auc: 0.94368 |  0:03:04s\n",
            "epoch 48 | loss: 0.46149 | val_0_auc: 0.94262 |  0:03:08s\n",
            "epoch 49 | loss: 0.45346 | val_0_auc: 0.94451 |  0:03:12s\n",
            "epoch 50 | loss: 0.46435 | val_0_auc: 0.94182 |  0:03:16s\n",
            "epoch 51 | loss: 0.44178 | val_0_auc: 0.9461  |  0:03:20s\n",
            "epoch 52 | loss: 0.45255 | val_0_auc: 0.94901 |  0:03:24s\n",
            "epoch 53 | loss: 0.44699 | val_0_auc: 0.949   |  0:03:28s\n",
            "epoch 54 | loss: 0.43963 | val_0_auc: 0.94655 |  0:03:31s\n",
            "epoch 55 | loss: 0.4395  | val_0_auc: 0.9505  |  0:03:35s\n",
            "epoch 56 | loss: 0.43851 | val_0_auc: 0.94945 |  0:03:39s\n",
            "epoch 57 | loss: 0.43704 | val_0_auc: 0.94955 |  0:03:43s\n",
            "epoch 58 | loss: 0.44319 | val_0_auc: 0.94716 |  0:03:47s\n",
            "epoch 59 | loss: 0.4442  | val_0_auc: 0.9468  |  0:03:50s\n",
            "epoch 60 | loss: 0.44554 | val_0_auc: 0.94933 |  0:03:55s\n",
            "epoch 61 | loss: 0.43788 | val_0_auc: 0.9475  |  0:03:58s\n",
            "epoch 62 | loss: 0.42843 | val_0_auc: 0.95451 |  0:04:02s\n",
            "epoch 63 | loss: 0.43771 | val_0_auc: 0.95113 |  0:04:06s\n",
            "epoch 64 | loss: 0.44037 | val_0_auc: 0.9533  |  0:04:10s\n",
            "epoch 65 | loss: 0.43149 | val_0_auc: 0.95194 |  0:04:15s\n",
            "epoch 66 | loss: 0.42936 | val_0_auc: 0.9537  |  0:04:19s\n",
            "epoch 67 | loss: 0.42583 | val_0_auc: 0.95181 |  0:04:23s\n",
            "epoch 68 | loss: 0.42843 | val_0_auc: 0.95376 |  0:04:27s\n",
            "epoch 69 | loss: 0.42738 | val_0_auc: 0.95314 |  0:04:31s\n",
            "epoch 70 | loss: 0.42669 | val_0_auc: 0.95084 |  0:04:35s\n",
            "epoch 71 | loss: 0.42586 | val_0_auc: 0.94887 |  0:04:38s\n",
            "epoch 72 | loss: 0.42433 | val_0_auc: 0.94922 |  0:04:43s\n",
            "\n",
            "Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_auc = 0.95451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:15:42,849] Trial 35 finished with value: 0.9545068184909067 and parameters: {'n_d': 31, 'n_a': 12, 'n_steps': 7, 'gamma': 0.27465669978997964, 'momentum': 0.039325286240490476, 'lambda_sparse': 0.061164196240643266, 'lr': 0.0002531070695091778, 'weight_decay': 0.0003166504635620602}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.82126 | val_0_auc: 0.48903 |  0:00:03s\n",
            "epoch 1  | loss: 1.04678 | val_0_auc: 0.52604 |  0:00:06s\n",
            "epoch 2  | loss: 0.86876 | val_0_auc: 0.67696 |  0:00:10s\n",
            "epoch 3  | loss: 0.78545 | val_0_auc: 0.77307 |  0:00:14s\n",
            "epoch 4  | loss: 0.70345 | val_0_auc: 0.83694 |  0:00:17s\n",
            "epoch 5  | loss: 0.64024 | val_0_auc: 0.86924 |  0:00:21s\n",
            "epoch 6  | loss: 0.61652 | val_0_auc: 0.88958 |  0:00:25s\n",
            "epoch 7  | loss: 0.57999 | val_0_auc: 0.8919  |  0:00:29s\n",
            "epoch 8  | loss: 0.56588 | val_0_auc: 0.91266 |  0:00:32s\n",
            "epoch 9  | loss: 0.54316 | val_0_auc: 0.90764 |  0:00:36s\n",
            "epoch 10 | loss: 0.5402  | val_0_auc: 0.91006 |  0:00:40s\n",
            "epoch 11 | loss: 0.52151 | val_0_auc: 0.92113 |  0:00:43s\n",
            "epoch 12 | loss: 0.51744 | val_0_auc: 0.92492 |  0:00:47s\n",
            "epoch 13 | loss: 0.50772 | val_0_auc: 0.927   |  0:00:51s\n",
            "epoch 14 | loss: 0.49869 | val_0_auc: 0.92854 |  0:00:54s\n",
            "epoch 15 | loss: 0.50432 | val_0_auc: 0.93177 |  0:00:57s\n",
            "epoch 16 | loss: 0.48837 | val_0_auc: 0.93201 |  0:01:01s\n",
            "epoch 17 | loss: 0.49597 | val_0_auc: 0.93344 |  0:01:05s\n",
            "epoch 18 | loss: 0.4842  | val_0_auc: 0.93697 |  0:01:08s\n",
            "epoch 19 | loss: 0.46842 | val_0_auc: 0.94022 |  0:01:11s\n",
            "epoch 20 | loss: 0.46925 | val_0_auc: 0.94209 |  0:01:15s\n",
            "epoch 21 | loss: 0.47041 | val_0_auc: 0.9405  |  0:01:19s\n",
            "epoch 22 | loss: 0.46463 | val_0_auc: 0.9396  |  0:01:22s\n",
            "epoch 23 | loss: 0.46803 | val_0_auc: 0.94    |  0:01:26s\n",
            "epoch 24 | loss: 0.45715 | val_0_auc: 0.94635 |  0:01:30s\n",
            "epoch 25 | loss: 0.4546  | val_0_auc: 0.94462 |  0:01:33s\n",
            "epoch 26 | loss: 0.45255 | val_0_auc: 0.94831 |  0:01:36s\n",
            "epoch 27 | loss: 0.45112 | val_0_auc: 0.94591 |  0:01:40s\n",
            "epoch 28 | loss: 0.45301 | val_0_auc: 0.94734 |  0:01:44s\n",
            "epoch 29 | loss: 0.446   | val_0_auc: 0.9476  |  0:01:47s\n",
            "epoch 30 | loss: 0.43823 | val_0_auc: 0.94142 |  0:01:51s\n",
            "epoch 31 | loss: 0.4427  | val_0_auc: 0.94962 |  0:01:55s\n",
            "epoch 32 | loss: 0.42933 | val_0_auc: 0.9476  |  0:01:58s\n",
            "epoch 33 | loss: 0.44238 | val_0_auc: 0.95029 |  0:02:03s\n",
            "epoch 34 | loss: 0.43301 | val_0_auc: 0.95232 |  0:02:07s\n",
            "epoch 35 | loss: 0.43443 | val_0_auc: 0.94809 |  0:02:10s\n",
            "epoch 36 | loss: 0.43224 | val_0_auc: 0.94754 |  0:02:14s\n",
            "epoch 37 | loss: 0.43158 | val_0_auc: 0.94381 |  0:02:18s\n",
            "epoch 38 | loss: 0.42933 | val_0_auc: 0.95198 |  0:02:22s\n",
            "epoch 39 | loss: 0.43157 | val_0_auc: 0.94768 |  0:02:26s\n",
            "epoch 40 | loss: 0.43078 | val_0_auc: 0.9502  |  0:02:30s\n",
            "epoch 41 | loss: 0.42739 | val_0_auc: 0.9551  |  0:02:33s\n",
            "epoch 42 | loss: 0.42772 | val_0_auc: 0.9522  |  0:02:37s\n",
            "epoch 43 | loss: 0.42537 | val_0_auc: 0.95599 |  0:02:41s\n",
            "epoch 44 | loss: 0.42391 | val_0_auc: 0.94643 |  0:02:45s\n",
            "epoch 45 | loss: 0.41017 | val_0_auc: 0.95383 |  0:02:48s\n",
            "epoch 46 | loss: 0.41642 | val_0_auc: 0.94826 |  0:02:52s\n",
            "epoch 47 | loss: 0.426   | val_0_auc: 0.95673 |  0:02:56s\n",
            "epoch 48 | loss: 0.40611 | val_0_auc: 0.95455 |  0:03:00s\n",
            "epoch 49 | loss: 0.41087 | val_0_auc: 0.95455 |  0:03:04s\n",
            "epoch 50 | loss: 0.40573 | val_0_auc: 0.95643 |  0:03:08s\n",
            "epoch 51 | loss: 0.40521 | val_0_auc: 0.95452 |  0:03:11s\n",
            "epoch 52 | loss: 0.4104  | val_0_auc: 0.94354 |  0:03:14s\n",
            "epoch 53 | loss: 0.40958 | val_0_auc: 0.95474 |  0:03:19s\n",
            "epoch 54 | loss: 0.41019 | val_0_auc: 0.95514 |  0:03:23s\n",
            "epoch 55 | loss: 0.41257 | val_0_auc: 0.95297 |  0:03:27s\n",
            "epoch 56 | loss: 0.39998 | val_0_auc: 0.95576 |  0:03:31s\n",
            "epoch 57 | loss: 0.40251 | val_0_auc: 0.95503 |  0:03:34s\n",
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.95673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:19:19,471] Trial 36 finished with value: 0.9567291643485033 and parameters: {'n_d': 22, 'n_a': 16, 'n_steps': 7, 'gamma': 0.46532509281241285, 'momentum': 0.07906502447523737, 'lambda_sparse': 0.0682190192434087, 'lr': 0.0007891036978402233, 'weight_decay': 0.0009563725871590202}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.84848 | val_0_auc: 0.54323 |  0:00:02s\n",
            "epoch 1  | loss: 0.65028 | val_0_auc: 0.68594 |  0:00:06s\n",
            "epoch 2  | loss: 0.60173 | val_0_auc: 0.75727 |  0:00:09s\n",
            "epoch 3  | loss: 0.56524 | val_0_auc: 0.82955 |  0:00:11s\n",
            "epoch 4  | loss: 0.52585 | val_0_auc: 0.90229 |  0:00:14s\n",
            "epoch 5  | loss: 0.50871 | val_0_auc: 0.90914 |  0:00:17s\n",
            "epoch 6  | loss: 0.48138 | val_0_auc: 0.91508 |  0:00:20s\n",
            "epoch 7  | loss: 0.46639 | val_0_auc: 0.91274 |  0:00:23s\n",
            "epoch 8  | loss: 0.45412 | val_0_auc: 0.9274  |  0:00:25s\n",
            "epoch 9  | loss: 0.43993 | val_0_auc: 0.92381 |  0:00:28s\n",
            "epoch 10 | loss: 0.42717 | val_0_auc: 0.91877 |  0:00:31s\n",
            "epoch 11 | loss: 0.41104 | val_0_auc: 0.92972 |  0:00:34s\n",
            "epoch 12 | loss: 0.40931 | val_0_auc: 0.94013 |  0:00:37s\n",
            "epoch 13 | loss: 0.41361 | val_0_auc: 0.93708 |  0:00:40s\n",
            "epoch 14 | loss: 0.39059 | val_0_auc: 0.94222 |  0:00:44s\n",
            "epoch 15 | loss: 0.38621 | val_0_auc: 0.94461 |  0:00:47s\n",
            "epoch 16 | loss: 0.37432 | val_0_auc: 0.94966 |  0:00:50s\n",
            "epoch 17 | loss: 0.38213 | val_0_auc: 0.949   |  0:00:53s\n",
            "epoch 18 | loss: 0.37043 | val_0_auc: 0.94861 |  0:00:56s\n",
            "epoch 19 | loss: 0.37776 | val_0_auc: 0.94928 |  0:00:59s\n",
            "epoch 20 | loss: 0.36049 | val_0_auc: 0.94446 |  0:01:02s\n",
            "epoch 21 | loss: 0.36451 | val_0_auc: 0.94723 |  0:01:04s\n",
            "epoch 22 | loss: 0.35426 | val_0_auc: 0.95132 |  0:01:07s\n",
            "epoch 23 | loss: 0.3506  | val_0_auc: 0.9539  |  0:01:10s\n",
            "epoch 24 | loss: 0.33944 | val_0_auc: 0.9541  |  0:01:14s\n",
            "epoch 25 | loss: 0.34671 | val_0_auc: 0.9571  |  0:01:16s\n",
            "epoch 26 | loss: 0.34306 | val_0_auc: 0.95277 |  0:01:20s\n",
            "epoch 27 | loss: 0.35082 | val_0_auc: 0.94496 |  0:01:22s\n",
            "epoch 28 | loss: 0.33798 | val_0_auc: 0.95337 |  0:01:25s\n",
            "epoch 29 | loss: 0.33854 | val_0_auc: 0.95281 |  0:01:28s\n",
            "epoch 30 | loss: 0.33223 | val_0_auc: 0.95232 |  0:01:32s\n",
            "epoch 31 | loss: 0.33399 | val_0_auc: 0.96117 |  0:01:35s\n",
            "epoch 32 | loss: 0.32726 | val_0_auc: 0.95139 |  0:01:38s\n",
            "epoch 33 | loss: 0.32316 | val_0_auc: 0.95076 |  0:01:40s\n",
            "epoch 34 | loss: 0.32208 | val_0_auc: 0.95435 |  0:01:45s\n",
            "epoch 35 | loss: 0.32606 | val_0_auc: 0.95779 |  0:01:47s\n",
            "epoch 36 | loss: 0.32199 | val_0_auc: 0.96163 |  0:01:51s\n",
            "epoch 37 | loss: 0.31397 | val_0_auc: 0.95645 |  0:01:54s\n",
            "epoch 38 | loss: 0.32689 | val_0_auc: 0.95356 |  0:01:58s\n",
            "epoch 39 | loss: 0.31776 | val_0_auc: 0.96059 |  0:02:01s\n",
            "epoch 40 | loss: 0.31216 | val_0_auc: 0.95914 |  0:02:04s\n",
            "epoch 41 | loss: 0.3024  | val_0_auc: 0.95922 |  0:02:07s\n",
            "epoch 42 | loss: 0.29678 | val_0_auc: 0.96444 |  0:02:10s\n",
            "epoch 43 | loss: 0.3048  | val_0_auc: 0.96416 |  0:02:13s\n",
            "epoch 44 | loss: 0.29647 | val_0_auc: 0.96515 |  0:02:16s\n",
            "epoch 45 | loss: 0.30132 | val_0_auc: 0.96462 |  0:02:19s\n",
            "epoch 46 | loss: 0.30139 | val_0_auc: 0.96082 |  0:02:22s\n",
            "epoch 47 | loss: 0.3045  | val_0_auc: 0.96599 |  0:02:25s\n",
            "epoch 48 | loss: 0.29968 | val_0_auc: 0.96498 |  0:02:29s\n",
            "epoch 49 | loss: 0.29415 | val_0_auc: 0.96041 |  0:02:31s\n",
            "epoch 50 | loss: 0.28877 | val_0_auc: 0.9625  |  0:02:35s\n",
            "epoch 51 | loss: 0.29877 | val_0_auc: 0.96459 |  0:02:38s\n",
            "epoch 52 | loss: 0.29514 | val_0_auc: 0.96279 |  0:02:40s\n",
            "epoch 53 | loss: 0.28528 | val_0_auc: 0.96197 |  0:02:44s\n",
            "epoch 54 | loss: 0.28919 | val_0_auc: 0.96121 |  0:02:48s\n",
            "epoch 55 | loss: 0.28552 | val_0_auc: 0.96241 |  0:02:51s\n",
            "epoch 56 | loss: 0.2821  | val_0_auc: 0.96585 |  0:02:55s\n",
            "epoch 57 | loss: 0.29226 | val_0_auc: 0.96592 |  0:02:58s\n",
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.96599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:22:19,829] Trial 37 finished with value: 0.9659940902290963 and parameters: {'n_d': 37, 'n_a': 10, 'n_steps': 5, 'gamma': 0.5768442581591285, 'momentum': 0.143549573913623, 'lambda_sparse': 0.0421642875801331, 'lr': 0.004783887574142107, 'weight_decay': 0.00010453058289528722}. Best is trial 31 with value: 0.9729454891633594.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.80888 | val_0_auc: 0.57581 |  0:00:03s\n",
            "epoch 1  | loss: 0.60382 | val_0_auc: 0.76593 |  0:00:06s\n",
            "epoch 2  | loss: 0.5615  | val_0_auc: 0.82529 |  0:00:10s\n",
            "epoch 3  | loss: 0.527   | val_0_auc: 0.90119 |  0:00:13s\n",
            "epoch 4  | loss: 0.50666 | val_0_auc: 0.91101 |  0:00:17s\n",
            "epoch 5  | loss: 0.48401 | val_0_auc: 0.9329  |  0:00:20s\n",
            "epoch 6  | loss: 0.46381 | val_0_auc: 0.92863 |  0:00:23s\n",
            "epoch 7  | loss: 0.45331 | val_0_auc: 0.93359 |  0:00:27s\n",
            "epoch 8  | loss: 0.44902 | val_0_auc: 0.93174 |  0:00:30s\n",
            "epoch 9  | loss: 0.44391 | val_0_auc: 0.93702 |  0:00:33s\n",
            "epoch 10 | loss: 0.42748 | val_0_auc: 0.93038 |  0:00:37s\n",
            "epoch 11 | loss: 0.42604 | val_0_auc: 0.9448  |  0:00:40s\n",
            "epoch 12 | loss: 0.41463 | val_0_auc: 0.94742 |  0:00:44s\n",
            "epoch 13 | loss: 0.41087 | val_0_auc: 0.94669 |  0:00:47s\n",
            "epoch 14 | loss: 0.40846 | val_0_auc: 0.94804 |  0:00:50s\n",
            "epoch 15 | loss: 0.40305 | val_0_auc: 0.95151 |  0:00:53s\n",
            "epoch 16 | loss: 0.39872 | val_0_auc: 0.9543  |  0:00:57s\n",
            "epoch 17 | loss: 0.40124 | val_0_auc: 0.95374 |  0:01:01s\n",
            "epoch 18 | loss: 0.39136 | val_0_auc: 0.95188 |  0:01:03s\n",
            "epoch 19 | loss: 0.37874 | val_0_auc: 0.95652 |  0:01:07s\n",
            "epoch 20 | loss: 0.38305 | val_0_auc: 0.95715 |  0:01:10s\n",
            "epoch 21 | loss: 0.37675 | val_0_auc: 0.95179 |  0:01:13s\n",
            "epoch 22 | loss: 0.37803 | val_0_auc: 0.957   |  0:01:16s\n",
            "epoch 23 | loss: 0.37103 | val_0_auc: 0.96086 |  0:01:19s\n",
            "epoch 24 | loss: 0.36735 | val_0_auc: 0.95619 |  0:01:22s\n",
            "epoch 25 | loss: 0.369   | val_0_auc: 0.96045 |  0:01:26s\n",
            "epoch 26 | loss: 0.36338 | val_0_auc: 0.95698 |  0:01:29s\n",
            "epoch 27 | loss: 0.35991 | val_0_auc: 0.96105 |  0:01:32s\n",
            "epoch 28 | loss: 0.36672 | val_0_auc: 0.95862 |  0:01:36s\n",
            "epoch 29 | loss: 0.35198 | val_0_auc: 0.9613  |  0:01:40s\n",
            "epoch 30 | loss: 0.36162 | val_0_auc: 0.96052 |  0:01:43s\n",
            "epoch 31 | loss: 0.35909 | val_0_auc: 0.9641  |  0:01:47s\n",
            "epoch 32 | loss: 0.34848 | val_0_auc: 0.96    |  0:01:51s\n",
            "epoch 33 | loss: 0.34861 | val_0_auc: 0.96356 |  0:01:54s\n",
            "epoch 34 | loss: 0.35237 | val_0_auc: 0.96268 |  0:01:58s\n",
            "epoch 35 | loss: 0.33434 | val_0_auc: 0.9636  |  0:02:01s\n",
            "epoch 36 | loss: 0.34321 | val_0_auc: 0.96539 |  0:02:05s\n",
            "epoch 37 | loss: 0.33906 | val_0_auc: 0.96809 |  0:02:08s\n",
            "epoch 38 | loss: 0.33329 | val_0_auc: 0.96538 |  0:02:11s\n",
            "epoch 39 | loss: 0.32277 | val_0_auc: 0.9646  |  0:02:15s\n",
            "epoch 40 | loss: 0.33812 | val_0_auc: 0.96509 |  0:02:18s\n",
            "epoch 41 | loss: 0.33846 | val_0_auc: 0.96354 |  0:02:22s\n",
            "epoch 42 | loss: 0.33508 | val_0_auc: 0.9688  |  0:02:25s\n",
            "epoch 43 | loss: 0.34124 | val_0_auc: 0.96743 |  0:02:30s\n",
            "epoch 44 | loss: 0.32791 | val_0_auc: 0.96709 |  0:02:34s\n",
            "epoch 45 | loss: 0.32859 | val_0_auc: 0.96659 |  0:02:37s\n",
            "epoch 46 | loss: 0.3309  | val_0_auc: 0.96422 |  0:02:41s\n",
            "epoch 47 | loss: 0.32515 | val_0_auc: 0.96683 |  0:02:45s\n",
            "epoch 48 | loss: 0.32482 | val_0_auc: 0.96896 |  0:02:48s\n",
            "epoch 49 | loss: 0.33292 | val_0_auc: 0.96517 |  0:02:52s\n",
            "epoch 50 | loss: 0.32233 | val_0_auc: 0.96923 |  0:02:56s\n",
            "epoch 51 | loss: 0.31593 | val_0_auc: 0.96583 |  0:02:59s\n",
            "epoch 52 | loss: 0.31184 | val_0_auc: 0.97192 |  0:03:03s\n",
            "epoch 53 | loss: 0.31943 | val_0_auc: 0.97076 |  0:03:07s\n",
            "epoch 54 | loss: 0.31877 | val_0_auc: 0.9667  |  0:03:10s\n",
            "epoch 55 | loss: 0.31004 | val_0_auc: 0.97012 |  0:03:13s\n",
            "epoch 56 | loss: 0.31282 | val_0_auc: 0.9703  |  0:03:17s\n",
            "epoch 57 | loss: 0.30914 | val_0_auc: 0.96852 |  0:03:21s\n",
            "epoch 58 | loss: 0.3098  | val_0_auc: 0.97084 |  0:03:24s\n",
            "epoch 59 | loss: 0.30636 | val_0_auc: 0.97313 |  0:03:28s\n",
            "epoch 60 | loss: 0.30697 | val_0_auc: 0.97041 |  0:03:32s\n",
            "epoch 61 | loss: 0.30785 | val_0_auc: 0.96974 |  0:03:35s\n",
            "epoch 62 | loss: 0.31115 | val_0_auc: 0.97234 |  0:03:38s\n",
            "epoch 63 | loss: 0.30804 | val_0_auc: 0.97339 |  0:03:42s\n",
            "epoch 64 | loss: 0.30059 | val_0_auc: 0.97545 |  0:03:45s\n",
            "epoch 65 | loss: 0.29502 | val_0_auc: 0.97236 |  0:03:49s\n",
            "epoch 66 | loss: 0.30028 | val_0_auc: 0.97039 |  0:03:53s\n",
            "epoch 67 | loss: 0.28396 | val_0_auc: 0.97198 |  0:03:57s\n",
            "epoch 68 | loss: 0.29219 | val_0_auc: 0.97356 |  0:04:00s\n",
            "epoch 69 | loss: 0.30012 | val_0_auc: 0.96985 |  0:04:03s\n",
            "epoch 70 | loss: 0.28845 | val_0_auc: 0.972   |  0:04:07s\n",
            "epoch 71 | loss: 0.29386 | val_0_auc: 0.97181 |  0:04:10s\n",
            "epoch 72 | loss: 0.28044 | val_0_auc: 0.9719  |  0:04:14s\n",
            "epoch 73 | loss: 0.28738 | val_0_auc: 0.97177 |  0:04:18s\n",
            "epoch 74 | loss: 0.28675 | val_0_auc: 0.96903 |  0:04:22s\n",
            "\n",
            "Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_auc = 0.97545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:26:43,944] Trial 38 finished with value: 0.975450650940247 and parameters: {'n_d': 25, 'n_a': 22, 'n_steps': 6, 'gamma': 0.3656150938326871, 'momentum': 0.0816254305857589, 'lambda_sparse': 0.05103010863006034, 'lr': 0.0018506127775402865, 'weight_decay': 5.376118014372652e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.17272 | val_0_auc: 0.40594 |  0:00:03s\n",
            "epoch 1  | loss: 1.06225 | val_0_auc: 0.46212 |  0:00:08s\n",
            "epoch 2  | loss: 0.99708 | val_0_auc: 0.49431 |  0:00:11s\n",
            "epoch 3  | loss: 0.9542  | val_0_auc: 0.52922 |  0:00:15s\n",
            "epoch 4  | loss: 0.92039 | val_0_auc: 0.56912 |  0:00:18s\n",
            "epoch 5  | loss: 0.89514 | val_0_auc: 0.56954 |  0:00:23s\n",
            "epoch 6  | loss: 0.86784 | val_0_auc: 0.58809 |  0:00:27s\n",
            "epoch 7  | loss: 0.82634 | val_0_auc: 0.60417 |  0:00:31s\n",
            "epoch 8  | loss: 0.80952 | val_0_auc: 0.62451 |  0:00:35s\n",
            "epoch 9  | loss: 0.79062 | val_0_auc: 0.60709 |  0:00:39s\n",
            "epoch 10 | loss: 0.77053 | val_0_auc: 0.64706 |  0:00:43s\n",
            "epoch 11 | loss: 0.75657 | val_0_auc: 0.64826 |  0:00:47s\n",
            "epoch 12 | loss: 0.74119 | val_0_auc: 0.65658 |  0:00:51s\n",
            "epoch 13 | loss: 0.74177 | val_0_auc: 0.67004 |  0:00:55s\n",
            "epoch 14 | loss: 0.72356 | val_0_auc: 0.67697 |  0:00:59s\n",
            "epoch 15 | loss: 0.71581 | val_0_auc: 0.67262 |  0:01:03s\n",
            "epoch 16 | loss: 0.71843 | val_0_auc: 0.70319 |  0:01:06s\n",
            "epoch 17 | loss: 0.70037 | val_0_auc: 0.70244 |  0:01:11s\n",
            "epoch 18 | loss: 0.69994 | val_0_auc: 0.70179 |  0:01:15s\n",
            "epoch 19 | loss: 0.69414 | val_0_auc: 0.70227 |  0:01:19s\n",
            "epoch 20 | loss: 0.69214 | val_0_auc: 0.71387 |  0:01:24s\n",
            "epoch 21 | loss: 0.68786 | val_0_auc: 0.72909 |  0:01:27s\n",
            "epoch 22 | loss: 0.68588 | val_0_auc: 0.72178 |  0:01:31s\n",
            "epoch 23 | loss: 0.68244 | val_0_auc: 0.7267  |  0:01:36s\n",
            "epoch 24 | loss: 0.67487 | val_0_auc: 0.74848 |  0:01:39s\n",
            "epoch 25 | loss: 0.67801 | val_0_auc: 0.73621 |  0:01:43s\n",
            "epoch 26 | loss: 0.67012 | val_0_auc: 0.73329 |  0:01:47s\n",
            "epoch 27 | loss: 0.66409 | val_0_auc: 0.75758 |  0:01:51s\n",
            "epoch 28 | loss: 0.6587  | val_0_auc: 0.75572 |  0:01:55s\n",
            "epoch 29 | loss: 0.65711 | val_0_auc: 0.76232 |  0:01:59s\n",
            "epoch 30 | loss: 0.65036 | val_0_auc: 0.77059 |  0:02:03s\n",
            "epoch 31 | loss: 0.64927 | val_0_auc: 0.78839 |  0:02:07s\n",
            "epoch 32 | loss: 0.63893 | val_0_auc: 0.78144 |  0:02:10s\n",
            "epoch 33 | loss: 0.63413 | val_0_auc: 0.8008  |  0:02:15s\n",
            "epoch 34 | loss: 0.63584 | val_0_auc: 0.79804 |  0:02:18s\n",
            "epoch 35 | loss: 0.62971 | val_0_auc: 0.79442 |  0:02:22s\n",
            "epoch 36 | loss: 0.62369 | val_0_auc: 0.78839 |  0:02:27s\n",
            "epoch 37 | loss: 0.623   | val_0_auc: 0.79574 |  0:02:30s\n",
            "epoch 38 | loss: 0.61657 | val_0_auc: 0.79416 |  0:02:34s\n",
            "epoch 39 | loss: 0.61621 | val_0_auc: 0.7961  |  0:02:38s\n",
            "epoch 40 | loss: 0.61623 | val_0_auc: 0.80276 |  0:02:42s\n",
            "epoch 41 | loss: 0.60993 | val_0_auc: 0.79853 |  0:02:45s\n",
            "epoch 42 | loss: 0.61365 | val_0_auc: 0.81349 |  0:02:50s\n",
            "epoch 43 | loss: 0.60414 | val_0_auc: 0.80591 |  0:02:54s\n",
            "epoch 44 | loss: 0.60848 | val_0_auc: 0.81094 |  0:02:58s\n",
            "epoch 45 | loss: 0.60108 | val_0_auc: 0.81399 |  0:03:02s\n",
            "epoch 46 | loss: 0.59377 | val_0_auc: 0.81172 |  0:03:06s\n",
            "epoch 47 | loss: 0.59765 | val_0_auc: 0.81441 |  0:03:10s\n",
            "epoch 48 | loss: 0.59554 | val_0_auc: 0.8134  |  0:03:14s\n",
            "epoch 49 | loss: 0.5933  | val_0_auc: 0.82328 |  0:03:19s\n",
            "epoch 50 | loss: 0.58778 | val_0_auc: 0.82434 |  0:03:23s\n",
            "epoch 51 | loss: 0.58969 | val_0_auc: 0.83265 |  0:03:27s\n",
            "epoch 52 | loss: 0.58997 | val_0_auc: 0.8325  |  0:03:31s\n",
            "epoch 53 | loss: 0.58635 | val_0_auc: 0.8395  |  0:03:35s\n",
            "epoch 54 | loss: 0.59181 | val_0_auc: 0.83734 |  0:03:39s\n",
            "epoch 55 | loss: 0.58129 | val_0_auc: 0.83323 |  0:03:43s\n",
            "epoch 56 | loss: 0.57926 | val_0_auc: 0.83078 |  0:03:47s\n",
            "epoch 57 | loss: 0.57775 | val_0_auc: 0.83545 |  0:03:51s\n",
            "epoch 58 | loss: 0.56903 | val_0_auc: 0.83555 |  0:03:55s\n",
            "epoch 59 | loss: 0.57157 | val_0_auc: 0.84884 |  0:03:59s\n",
            "epoch 60 | loss: 0.57039 | val_0_auc: 0.84615 |  0:04:03s\n",
            "epoch 61 | loss: 0.57265 | val_0_auc: 0.85275 |  0:04:07s\n",
            "epoch 62 | loss: 0.57351 | val_0_auc: 0.85271 |  0:04:10s\n",
            "epoch 63 | loss: 0.56144 | val_0_auc: 0.85172 |  0:04:14s\n",
            "epoch 64 | loss: 0.5641  | val_0_auc: 0.8551  |  0:04:19s\n",
            "epoch 65 | loss: 0.55776 | val_0_auc: 0.85239 |  0:04:22s\n",
            "epoch 66 | loss: 0.55154 | val_0_auc: 0.85144 |  0:04:26s\n",
            "epoch 67 | loss: 0.55264 | val_0_auc: 0.84751 |  0:04:31s\n",
            "epoch 68 | loss: 0.55567 | val_0_auc: 0.85317 |  0:04:34s\n",
            "epoch 69 | loss: 0.54472 | val_0_auc: 0.85777 |  0:04:38s\n",
            "epoch 70 | loss: 0.54495 | val_0_auc: 0.86042 |  0:04:42s\n",
            "epoch 71 | loss: 0.54289 | val_0_auc: 0.85986 |  0:04:47s\n",
            "epoch 72 | loss: 0.54081 | val_0_auc: 0.86407 |  0:04:51s\n",
            "epoch 73 | loss: 0.53902 | val_0_auc: 0.85931 |  0:04:55s\n",
            "epoch 74 | loss: 0.54162 | val_0_auc: 0.85388 |  0:04:59s\n",
            "epoch 75 | loss: 0.53827 | val_0_auc: 0.86079 |  0:05:03s\n",
            "epoch 76 | loss: 0.54148 | val_0_auc: 0.86467 |  0:05:07s\n",
            "epoch 77 | loss: 0.54116 | val_0_auc: 0.86686 |  0:05:11s\n",
            "epoch 78 | loss: 0.53332 | val_0_auc: 0.87375 |  0:05:15s\n",
            "epoch 79 | loss: 0.52889 | val_0_auc: 0.86533 |  0:05:20s\n",
            "epoch 80 | loss: 0.53205 | val_0_auc: 0.86852 |  0:05:24s\n",
            "epoch 81 | loss: 0.52587 | val_0_auc: 0.87033 |  0:05:28s\n",
            "epoch 82 | loss: 0.52691 | val_0_auc: 0.87697 |  0:05:31s\n",
            "epoch 83 | loss: 0.53805 | val_0_auc: 0.87567 |  0:05:36s\n",
            "epoch 84 | loss: 0.53012 | val_0_auc: 0.88267 |  0:05:40s\n",
            "epoch 85 | loss: 0.5264  | val_0_auc: 0.88134 |  0:05:45s\n",
            "epoch 86 | loss: 0.52683 | val_0_auc: 0.87711 |  0:05:49s\n",
            "epoch 87 | loss: 0.52152 | val_0_auc: 0.87774 |  0:05:53s\n",
            "epoch 88 | loss: 0.52435 | val_0_auc: 0.87926 |  0:05:56s\n",
            "epoch 89 | loss: 0.52505 | val_0_auc: 0.88091 |  0:06:00s\n",
            "epoch 90 | loss: 0.51883 | val_0_auc: 0.88366 |  0:06:04s\n",
            "epoch 91 | loss: 0.51338 | val_0_auc: 0.88912 |  0:06:08s\n",
            "epoch 92 | loss: 0.51315 | val_0_auc: 0.88151 |  0:06:12s\n",
            "epoch 93 | loss: 0.51699 | val_0_auc: 0.88222 |  0:06:16s\n",
            "epoch 94 | loss: 0.51483 | val_0_auc: 0.88208 |  0:06:20s\n",
            "epoch 95 | loss: 0.5103  | val_0_auc: 0.87971 |  0:06:24s\n",
            "epoch 96 | loss: 0.51068 | val_0_auc: 0.88355 |  0:06:28s\n",
            "epoch 97 | loss: 0.50694 | val_0_auc: 0.88817 |  0:06:32s\n",
            "epoch 98 | loss: 0.50997 | val_0_auc: 0.88596 |  0:06:36s\n",
            "epoch 99 | loss: 0.50612 | val_0_auc: 0.88691 |  0:06:40s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_0_auc = 0.88912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:33:26,439] Trial 39 finished with value: 0.8891207052161764 and parameters: {'n_d': 11, 'n_a': 22, 'n_steps': 8, 'gamma': 1.0803854948354756, 'momentum': 0.08261739747358057, 'lambda_sparse': 0.05872721710328199, 'lr': 0.000429332228936062, 'weight_decay': 0.0006247213038909439}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.27988 | val_0_auc: 0.53018 |  0:00:02s\n",
            "epoch 1  | loss: 0.77285 | val_0_auc: 0.54307 |  0:00:05s\n",
            "epoch 2  | loss: 0.68191 | val_0_auc: 0.71391 |  0:00:08s\n",
            "epoch 3  | loss: 0.6354  | val_0_auc: 0.80176 |  0:00:10s\n",
            "epoch 4  | loss: 0.61432 | val_0_auc: 0.83407 |  0:00:12s\n",
            "epoch 5  | loss: 0.58786 | val_0_auc: 0.84901 |  0:00:15s\n",
            "epoch 6  | loss: 0.57081 | val_0_auc: 0.8719  |  0:00:18s\n",
            "epoch 7  | loss: 0.5484  | val_0_auc: 0.87709 |  0:00:21s\n",
            "epoch 8  | loss: 0.54722 | val_0_auc: 0.88677 |  0:00:23s\n",
            "epoch 9  | loss: 0.53494 | val_0_auc: 0.88865 |  0:00:26s\n",
            "epoch 10 | loss: 0.52496 | val_0_auc: 0.89903 |  0:00:28s\n",
            "epoch 11 | loss: 0.50135 | val_0_auc: 0.90144 |  0:00:31s\n",
            "epoch 12 | loss: 0.49019 | val_0_auc: 0.90075 |  0:00:34s\n",
            "epoch 13 | loss: 0.48718 | val_0_auc: 0.90788 |  0:00:36s\n",
            "epoch 14 | loss: 0.49221 | val_0_auc: 0.91649 |  0:00:39s\n",
            "epoch 15 | loss: 0.48577 | val_0_auc: 0.91808 |  0:00:41s\n",
            "epoch 16 | loss: 0.47892 | val_0_auc: 0.91875 |  0:00:44s\n",
            "epoch 17 | loss: 0.46347 | val_0_auc: 0.92449 |  0:00:47s\n",
            "epoch 18 | loss: 0.46983 | val_0_auc: 0.92662 |  0:00:49s\n",
            "epoch 19 | loss: 0.45525 | val_0_auc: 0.92616 |  0:00:52s\n",
            "epoch 20 | loss: 0.44534 | val_0_auc: 0.93249 |  0:00:55s\n",
            "epoch 21 | loss: 0.44469 | val_0_auc: 0.93517 |  0:00:58s\n",
            "epoch 22 | loss: 0.44212 | val_0_auc: 0.93571 |  0:01:01s\n",
            "epoch 23 | loss: 0.4324  | val_0_auc: 0.93573 |  0:01:04s\n",
            "epoch 24 | loss: 0.43841 | val_0_auc: 0.93384 |  0:01:06s\n",
            "epoch 25 | loss: 0.43588 | val_0_auc: 0.92959 |  0:01:09s\n",
            "epoch 26 | loss: 0.4265  | val_0_auc: 0.94034 |  0:01:11s\n",
            "epoch 27 | loss: 0.4285  | val_0_auc: 0.94028 |  0:01:14s\n",
            "epoch 28 | loss: 0.42457 | val_0_auc: 0.94151 |  0:01:16s\n",
            "epoch 29 | loss: 0.41557 | val_0_auc: 0.94013 |  0:01:19s\n",
            "epoch 30 | loss: 0.41621 | val_0_auc: 0.93937 |  0:01:21s\n",
            "epoch 31 | loss: 0.42094 | val_0_auc: 0.94052 |  0:01:24s\n",
            "epoch 32 | loss: 0.41546 | val_0_auc: 0.94271 |  0:01:26s\n",
            "epoch 33 | loss: 0.40783 | val_0_auc: 0.94009 |  0:01:29s\n",
            "epoch 34 | loss: 0.40428 | val_0_auc: 0.94367 |  0:01:32s\n",
            "epoch 35 | loss: 0.41482 | val_0_auc: 0.9462  |  0:01:34s\n",
            "epoch 36 | loss: 0.41045 | val_0_auc: 0.94904 |  0:01:37s\n",
            "epoch 37 | loss: 0.40564 | val_0_auc: 0.945   |  0:01:39s\n",
            "epoch 38 | loss: 0.40088 | val_0_auc: 0.94721 |  0:01:42s\n",
            "epoch 39 | loss: 0.40317 | val_0_auc: 0.94734 |  0:01:45s\n",
            "epoch 40 | loss: 0.39392 | val_0_auc: 0.94924 |  0:01:48s\n",
            "epoch 41 | loss: 0.39827 | val_0_auc: 0.94967 |  0:01:50s\n",
            "epoch 42 | loss: 0.39512 | val_0_auc: 0.94983 |  0:01:53s\n",
            "epoch 43 | loss: 0.3924  | val_0_auc: 0.94929 |  0:01:55s\n",
            "epoch 44 | loss: 0.39053 | val_0_auc: 0.95191 |  0:01:58s\n",
            "epoch 45 | loss: 0.39104 | val_0_auc: 0.94876 |  0:02:01s\n",
            "epoch 46 | loss: 0.38681 | val_0_auc: 0.9521  |  0:02:04s\n",
            "epoch 47 | loss: 0.38621 | val_0_auc: 0.95112 |  0:02:06s\n",
            "epoch 48 | loss: 0.38586 | val_0_auc: 0.95486 |  0:02:09s\n",
            "epoch 49 | loss: 0.38392 | val_0_auc: 0.95423 |  0:02:12s\n",
            "epoch 50 | loss: 0.38806 | val_0_auc: 0.95376 |  0:02:14s\n",
            "epoch 51 | loss: 0.3753  | val_0_auc: 0.95653 |  0:02:17s\n",
            "epoch 52 | loss: 0.37723 | val_0_auc: 0.95485 |  0:02:19s\n",
            "epoch 53 | loss: 0.38447 | val_0_auc: 0.95478 |  0:02:22s\n",
            "epoch 54 | loss: 0.37595 | val_0_auc: 0.95496 |  0:02:25s\n",
            "epoch 55 | loss: 0.37606 | val_0_auc: 0.95644 |  0:02:27s\n",
            "epoch 56 | loss: 0.37777 | val_0_auc: 0.95777 |  0:02:30s\n",
            "epoch 57 | loss: 0.36566 | val_0_auc: 0.95404 |  0:02:32s\n",
            "epoch 58 | loss: 0.36961 | val_0_auc: 0.95212 |  0:02:36s\n",
            "epoch 59 | loss: 0.36388 | val_0_auc: 0.95581 |  0:02:38s\n",
            "epoch 60 | loss: 0.36565 | val_0_auc: 0.95407 |  0:02:41s\n",
            "epoch 61 | loss: 0.37274 | val_0_auc: 0.95472 |  0:02:44s\n",
            "epoch 62 | loss: 0.3673  | val_0_auc: 0.95712 |  0:02:47s\n",
            "epoch 63 | loss: 0.36557 | val_0_auc: 0.95391 |  0:02:49s\n",
            "epoch 64 | loss: 0.36469 | val_0_auc: 0.95289 |  0:02:52s\n",
            "epoch 65 | loss: 0.36685 | val_0_auc: 0.95539 |  0:02:55s\n",
            "epoch 66 | loss: 0.36796 | val_0_auc: 0.95637 |  0:02:58s\n",
            "\n",
            "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_auc = 0.95777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:36:26,311] Trial 40 finished with value: 0.9577692469369335 and parameters: {'n_d': 19, 'n_a': 17, 'n_steps': 5, 'gamma': 0.3628771705405605, 'momentum': 0.2109490477339985, 'lambda_sparse': 0.04856549972531173, 'lr': 0.0008491877212273358, 'weight_decay': 5.9746213782517195e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.82506 | val_0_auc: 0.58777 |  0:00:02s\n",
            "epoch 1  | loss: 0.61631 | val_0_auc: 0.74492 |  0:00:05s\n",
            "epoch 2  | loss: 0.56357 | val_0_auc: 0.85551 |  0:00:08s\n",
            "epoch 3  | loss: 0.52672 | val_0_auc: 0.89886 |  0:00:12s\n",
            "epoch 4  | loss: 0.50487 | val_0_auc: 0.92225 |  0:00:15s\n",
            "epoch 5  | loss: 0.49698 | val_0_auc: 0.93287 |  0:00:18s\n",
            "epoch 6  | loss: 0.46656 | val_0_auc: 0.94057 |  0:00:20s\n",
            "epoch 7  | loss: 0.46965 | val_0_auc: 0.94289 |  0:00:24s\n",
            "epoch 8  | loss: 0.46197 | val_0_auc: 0.94469 |  0:00:27s\n",
            "epoch 9  | loss: 0.44692 | val_0_auc: 0.94646 |  0:00:30s\n",
            "epoch 10 | loss: 0.45499 | val_0_auc: 0.94817 |  0:00:33s\n",
            "epoch 11 | loss: 0.43689 | val_0_auc: 0.95065 |  0:00:36s\n",
            "epoch 12 | loss: 0.43521 | val_0_auc: 0.94141 |  0:00:39s\n",
            "epoch 13 | loss: 0.43204 | val_0_auc: 0.94669 |  0:00:41s\n",
            "epoch 14 | loss: 0.42126 | val_0_auc: 0.94907 |  0:00:44s\n",
            "epoch 15 | loss: 0.41748 | val_0_auc: 0.95012 |  0:00:47s\n",
            "epoch 16 | loss: 0.41196 | val_0_auc: 0.95131 |  0:00:51s\n",
            "epoch 17 | loss: 0.40654 | val_0_auc: 0.94992 |  0:00:54s\n",
            "epoch 18 | loss: 0.40925 | val_0_auc: 0.95496 |  0:00:57s\n",
            "epoch 19 | loss: 0.40428 | val_0_auc: 0.95617 |  0:00:59s\n",
            "epoch 20 | loss: 0.40504 | val_0_auc: 0.9554  |  0:01:03s\n",
            "epoch 21 | loss: 0.39318 | val_0_auc: 0.9564  |  0:01:06s\n",
            "epoch 22 | loss: 0.39481 | val_0_auc: 0.95983 |  0:01:08s\n",
            "epoch 23 | loss: 0.39679 | val_0_auc: 0.95623 |  0:01:11s\n",
            "epoch 24 | loss: 0.38284 | val_0_auc: 0.95378 |  0:01:15s\n",
            "epoch 25 | loss: 0.3818  | val_0_auc: 0.95765 |  0:01:18s\n",
            "epoch 26 | loss: 0.38835 | val_0_auc: 0.9603  |  0:01:20s\n",
            "epoch 27 | loss: 0.38119 | val_0_auc: 0.95632 |  0:01:23s\n",
            "epoch 28 | loss: 0.37297 | val_0_auc: 0.95723 |  0:01:27s\n",
            "epoch 29 | loss: 0.37362 | val_0_auc: 0.95752 |  0:01:29s\n",
            "epoch 30 | loss: 0.37233 | val_0_auc: 0.95416 |  0:01:32s\n",
            "epoch 31 | loss: 0.36979 | val_0_auc: 0.95758 |  0:01:35s\n",
            "epoch 32 | loss: 0.36917 | val_0_auc: 0.95771 |  0:01:38s\n",
            "epoch 33 | loss: 0.37269 | val_0_auc: 0.95028 |  0:01:41s\n",
            "epoch 34 | loss: 0.35762 | val_0_auc: 0.95436 |  0:01:44s\n",
            "epoch 35 | loss: 0.36887 | val_0_auc: 0.95345 |  0:01:47s\n",
            "epoch 36 | loss: 0.36496 | val_0_auc: 0.96619 |  0:01:51s\n",
            "epoch 37 | loss: 0.36688 | val_0_auc: 0.95572 |  0:01:54s\n",
            "epoch 38 | loss: 0.36223 | val_0_auc: 0.95879 |  0:01:58s\n",
            "epoch 39 | loss: 0.36223 | val_0_auc: 0.96389 |  0:02:01s\n",
            "epoch 40 | loss: 0.36087 | val_0_auc: 0.9637  |  0:02:05s\n",
            "epoch 41 | loss: 0.35196 | val_0_auc: 0.96203 |  0:02:08s\n",
            "epoch 42 | loss: 0.35761 | val_0_auc: 0.9662  |  0:02:10s\n",
            "epoch 43 | loss: 0.35221 | val_0_auc: 0.96639 |  0:02:13s\n",
            "epoch 44 | loss: 0.3482  | val_0_auc: 0.96607 |  0:02:17s\n",
            "epoch 45 | loss: 0.35642 | val_0_auc: 0.964   |  0:02:20s\n",
            "epoch 46 | loss: 0.34782 | val_0_auc: 0.96165 |  0:02:23s\n",
            "epoch 47 | loss: 0.34636 | val_0_auc: 0.9626  |  0:02:26s\n",
            "epoch 48 | loss: 0.34377 | val_0_auc: 0.96489 |  0:02:30s\n",
            "epoch 49 | loss: 0.34021 | val_0_auc: 0.9664  |  0:02:33s\n",
            "epoch 50 | loss: 0.34097 | val_0_auc: 0.9656  |  0:02:36s\n",
            "epoch 51 | loss: 0.34482 | val_0_auc: 0.9656  |  0:02:39s\n",
            "epoch 52 | loss: 0.33821 | val_0_auc: 0.96585 |  0:02:43s\n",
            "epoch 53 | loss: 0.33756 | val_0_auc: 0.96615 |  0:02:46s\n",
            "epoch 54 | loss: 0.33458 | val_0_auc: 0.96661 |  0:02:49s\n",
            "epoch 55 | loss: 0.3302  | val_0_auc: 0.96907 |  0:02:53s\n",
            "epoch 56 | loss: 0.32245 | val_0_auc: 0.96815 |  0:02:56s\n",
            "epoch 57 | loss: 0.32965 | val_0_auc: 0.96551 |  0:03:00s\n",
            "epoch 58 | loss: 0.33399 | val_0_auc: 0.96998 |  0:03:03s\n",
            "epoch 59 | loss: 0.33324 | val_0_auc: 0.96811 |  0:03:07s\n",
            "epoch 60 | loss: 0.33036 | val_0_auc: 0.97019 |  0:03:09s\n",
            "epoch 61 | loss: 0.32565 | val_0_auc: 0.96876 |  0:03:13s\n",
            "epoch 62 | loss: 0.32555 | val_0_auc: 0.96681 |  0:03:16s\n",
            "epoch 63 | loss: 0.32702 | val_0_auc: 0.96762 |  0:03:20s\n",
            "epoch 64 | loss: 0.32638 | val_0_auc: 0.97047 |  0:03:23s\n",
            "epoch 65 | loss: 0.32155 | val_0_auc: 0.96941 |  0:03:26s\n",
            "epoch 66 | loss: 0.32217 | val_0_auc: 0.97011 |  0:03:29s\n",
            "epoch 67 | loss: 0.31729 | val_0_auc: 0.96767 |  0:03:32s\n",
            "epoch 68 | loss: 0.32761 | val_0_auc: 0.96978 |  0:03:35s\n",
            "epoch 69 | loss: 0.31545 | val_0_auc: 0.97178 |  0:03:38s\n",
            "epoch 70 | loss: 0.3105  | val_0_auc: 0.9688  |  0:03:42s\n",
            "epoch 71 | loss: 0.30629 | val_0_auc: 0.97226 |  0:03:45s\n",
            "epoch 72 | loss: 0.31373 | val_0_auc: 0.97063 |  0:03:48s\n",
            "epoch 73 | loss: 0.32033 | val_0_auc: 0.96814 |  0:03:51s\n",
            "epoch 74 | loss: 0.31329 | val_0_auc: 0.96903 |  0:03:55s\n",
            "epoch 75 | loss: 0.30309 | val_0_auc: 0.97346 |  0:03:58s\n",
            "epoch 76 | loss: 0.31377 | val_0_auc: 0.97371 |  0:04:01s\n",
            "epoch 77 | loss: 0.30244 | val_0_auc: 0.97092 |  0:04:04s\n",
            "epoch 78 | loss: 0.30492 | val_0_auc: 0.97229 |  0:04:08s\n",
            "epoch 79 | loss: 0.30309 | val_0_auc: 0.97052 |  0:04:11s\n",
            "epoch 80 | loss: 0.30803 | val_0_auc: 0.97321 |  0:04:15s\n",
            "epoch 81 | loss: 0.31061 | val_0_auc: 0.97525 |  0:04:18s\n",
            "epoch 82 | loss: 0.30711 | val_0_auc: 0.97108 |  0:04:22s\n",
            "epoch 83 | loss: 0.30364 | val_0_auc: 0.97213 |  0:04:26s\n",
            "epoch 84 | loss: 0.29601 | val_0_auc: 0.97327 |  0:04:29s\n",
            "epoch 85 | loss: 0.29433 | val_0_auc: 0.97279 |  0:04:33s\n",
            "epoch 86 | loss: 0.29964 | val_0_auc: 0.97109 |  0:04:36s\n",
            "epoch 87 | loss: 0.29927 | val_0_auc: 0.97007 |  0:04:39s\n",
            "epoch 88 | loss: 0.2966  | val_0_auc: 0.9738  |  0:04:42s\n",
            "epoch 89 | loss: 0.30097 | val_0_auc: 0.97443 |  0:04:46s\n",
            "epoch 90 | loss: 0.29215 | val_0_auc: 0.97497 |  0:04:49s\n",
            "epoch 91 | loss: 0.29617 | val_0_auc: 0.96999 |  0:04:52s\n",
            "\n",
            "Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_auc = 0.97525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:41:20,585] Trial 41 finished with value: 0.9752481980144159 and parameters: {'n_d': 27, 'n_a': 13, 'n_steps': 6, 'gamma': 0.21996506296899596, 'momentum': 0.028445139927580777, 'lambda_sparse': 0.05460760911854139, 'lr': 0.0015905673700043108, 'weight_decay': 2.7484435001540065e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.95986 | val_0_auc: 0.51259 |  0:00:03s\n",
            "epoch 1  | loss: 0.74408 | val_0_auc: 0.61706 |  0:00:06s\n",
            "epoch 2  | loss: 0.72121 | val_0_auc: 0.72686 |  0:00:09s\n",
            "epoch 3  | loss: 0.65921 | val_0_auc: 0.80808 |  0:00:12s\n",
            "epoch 4  | loss: 0.64835 | val_0_auc: 0.83412 |  0:00:15s\n",
            "epoch 5  | loss: 0.6158  | val_0_auc: 0.8458  |  0:00:18s\n",
            "epoch 6  | loss: 0.58687 | val_0_auc: 0.8879  |  0:00:22s\n",
            "epoch 7  | loss: 0.57668 | val_0_auc: 0.88239 |  0:00:24s\n",
            "epoch 8  | loss: 0.55976 | val_0_auc: 0.87464 |  0:00:28s\n",
            "epoch 9  | loss: 0.55493 | val_0_auc: 0.89502 |  0:00:31s\n",
            "epoch 10 | loss: 0.54082 | val_0_auc: 0.89672 |  0:00:34s\n",
            "epoch 11 | loss: 0.52214 | val_0_auc: 0.91233 |  0:00:37s\n",
            "epoch 12 | loss: 0.51231 | val_0_auc: 0.90936 |  0:00:40s\n",
            "epoch 13 | loss: 0.51346 | val_0_auc: 0.91107 |  0:00:44s\n",
            "epoch 14 | loss: 0.50213 | val_0_auc: 0.91149 |  0:00:47s\n",
            "epoch 15 | loss: 0.48872 | val_0_auc: 0.92232 |  0:00:50s\n",
            "epoch 16 | loss: 0.48341 | val_0_auc: 0.91726 |  0:00:53s\n",
            "epoch 17 | loss: 0.47875 | val_0_auc: 0.92506 |  0:00:56s\n",
            "epoch 18 | loss: 0.47763 | val_0_auc: 0.9288  |  0:00:59s\n",
            "epoch 19 | loss: 0.47738 | val_0_auc: 0.92697 |  0:01:02s\n",
            "epoch 20 | loss: 0.45696 | val_0_auc: 0.92839 |  0:01:05s\n",
            "epoch 21 | loss: 0.45279 | val_0_auc: 0.93523 |  0:01:09s\n",
            "epoch 22 | loss: 0.44297 | val_0_auc: 0.93895 |  0:01:12s\n",
            "epoch 23 | loss: 0.43925 | val_0_auc: 0.93513 |  0:01:15s\n",
            "epoch 24 | loss: 0.44167 | val_0_auc: 0.93449 |  0:01:19s\n",
            "epoch 25 | loss: 0.4348  | val_0_auc: 0.93781 |  0:01:22s\n",
            "epoch 26 | loss: 0.42904 | val_0_auc: 0.94277 |  0:01:25s\n",
            "epoch 27 | loss: 0.41604 | val_0_auc: 0.94446 |  0:01:28s\n",
            "epoch 28 | loss: 0.41613 | val_0_auc: 0.94872 |  0:01:31s\n",
            "epoch 29 | loss: 0.40878 | val_0_auc: 0.94743 |  0:01:34s\n",
            "epoch 30 | loss: 0.4112  | val_0_auc: 0.94374 |  0:01:37s\n",
            "epoch 31 | loss: 0.40373 | val_0_auc: 0.94538 |  0:01:40s\n",
            "epoch 32 | loss: 0.40106 | val_0_auc: 0.94489 |  0:01:44s\n",
            "epoch 33 | loss: 0.40485 | val_0_auc: 0.95004 |  0:01:47s\n",
            "epoch 34 | loss: 0.39607 | val_0_auc: 0.94929 |  0:01:50s\n",
            "epoch 35 | loss: 0.39402 | val_0_auc: 0.95    |  0:01:53s\n",
            "epoch 36 | loss: 0.40011 | val_0_auc: 0.95116 |  0:01:56s\n",
            "epoch 37 | loss: 0.3951  | val_0_auc: 0.95087 |  0:01:59s\n",
            "epoch 38 | loss: 0.38708 | val_0_auc: 0.94777 |  0:02:02s\n",
            "epoch 39 | loss: 0.37878 | val_0_auc: 0.95295 |  0:02:05s\n",
            "epoch 40 | loss: 0.37992 | val_0_auc: 0.94958 |  0:02:08s\n",
            "epoch 41 | loss: 0.37278 | val_0_auc: 0.95343 |  0:02:11s\n",
            "epoch 42 | loss: 0.37755 | val_0_auc: 0.95457 |  0:02:15s\n",
            "epoch 43 | loss: 0.37545 | val_0_auc: 0.95487 |  0:02:18s\n",
            "epoch 44 | loss: 0.37466 | val_0_auc: 0.95372 |  0:02:22s\n",
            "epoch 45 | loss: 0.37787 | val_0_auc: 0.95746 |  0:02:25s\n",
            "epoch 46 | loss: 0.36868 | val_0_auc: 0.95498 |  0:02:27s\n",
            "epoch 47 | loss: 0.37615 | val_0_auc: 0.95619 |  0:02:30s\n",
            "epoch 48 | loss: 0.36673 | val_0_auc: 0.95852 |  0:02:34s\n",
            "epoch 49 | loss: 0.36348 | val_0_auc: 0.95608 |  0:02:37s\n",
            "epoch 50 | loss: 0.36385 | val_0_auc: 0.95488 |  0:02:40s\n",
            "epoch 51 | loss: 0.3616  | val_0_auc: 0.95813 |  0:02:43s\n",
            "epoch 52 | loss: 0.35765 | val_0_auc: 0.95594 |  0:02:47s\n",
            "epoch 53 | loss: 0.36064 | val_0_auc: 0.95761 |  0:02:50s\n",
            "epoch 54 | loss: 0.34929 | val_0_auc: 0.95809 |  0:02:53s\n",
            "epoch 55 | loss: 0.35286 | val_0_auc: 0.95606 |  0:02:56s\n",
            "epoch 56 | loss: 0.34747 | val_0_auc: 0.95609 |  0:03:00s\n",
            "epoch 57 | loss: 0.34847 | val_0_auc: 0.96105 |  0:03:04s\n",
            "epoch 58 | loss: 0.33976 | val_0_auc: 0.96028 |  0:03:07s\n",
            "epoch 59 | loss: 0.35532 | val_0_auc: 0.95887 |  0:03:10s\n",
            "epoch 60 | loss: 0.3372  | val_0_auc: 0.9595  |  0:03:13s\n",
            "epoch 61 | loss: 0.34039 | val_0_auc: 0.96033 |  0:03:17s\n",
            "epoch 62 | loss: 0.33921 | val_0_auc: 0.96174 |  0:03:20s\n",
            "epoch 63 | loss: 0.34004 | val_0_auc: 0.96166 |  0:03:24s\n",
            "epoch 64 | loss: 0.33662 | val_0_auc: 0.96052 |  0:03:27s\n",
            "epoch 65 | loss: 0.33666 | val_0_auc: 0.95628 |  0:03:30s\n",
            "epoch 66 | loss: 0.33174 | val_0_auc: 0.95954 |  0:03:33s\n",
            "epoch 67 | loss: 0.33548 | val_0_auc: 0.9594  |  0:03:37s\n",
            "epoch 68 | loss: 0.3305  | val_0_auc: 0.9611  |  0:03:41s\n",
            "epoch 69 | loss: 0.32906 | val_0_auc: 0.96156 |  0:03:44s\n",
            "epoch 70 | loss: 0.33082 | val_0_auc: 0.9596  |  0:03:48s\n",
            "epoch 71 | loss: 0.32044 | val_0_auc: 0.9625  |  0:03:51s\n",
            "epoch 72 | loss: 0.32033 | val_0_auc: 0.96188 |  0:03:54s\n",
            "epoch 73 | loss: 0.31536 | val_0_auc: 0.96379 |  0:03:57s\n",
            "epoch 74 | loss: 0.32818 | val_0_auc: 0.96351 |  0:04:01s\n",
            "epoch 75 | loss: 0.3214  | val_0_auc: 0.96266 |  0:04:04s\n",
            "epoch 76 | loss: 0.32589 | val_0_auc: 0.96446 |  0:04:07s\n",
            "epoch 77 | loss: 0.33038 | val_0_auc: 0.96497 |  0:04:11s\n",
            "epoch 78 | loss: 0.31699 | val_0_auc: 0.96442 |  0:04:15s\n",
            "epoch 79 | loss: 0.3186  | val_0_auc: 0.9646  |  0:04:18s\n",
            "epoch 80 | loss: 0.31188 | val_0_auc: 0.96793 |  0:04:22s\n",
            "epoch 81 | loss: 0.31077 | val_0_auc: 0.96575 |  0:04:25s\n",
            "epoch 82 | loss: 0.31969 | val_0_auc: 0.96637 |  0:04:28s\n",
            "epoch 83 | loss: 0.31792 | val_0_auc: 0.96671 |  0:04:32s\n",
            "epoch 84 | loss: 0.3181  | val_0_auc: 0.9679  |  0:04:35s\n",
            "epoch 85 | loss: 0.30919 | val_0_auc: 0.96584 |  0:04:38s\n",
            "epoch 86 | loss: 0.3215  | val_0_auc: 0.9662  |  0:04:41s\n",
            "epoch 87 | loss: 0.30596 | val_0_auc: 0.96648 |  0:04:44s\n",
            "epoch 88 | loss: 0.30708 | val_0_auc: 0.9674  |  0:04:48s\n",
            "epoch 89 | loss: 0.30964 | val_0_auc: 0.96453 |  0:04:50s\n",
            "epoch 90 | loss: 0.29762 | val_0_auc: 0.96642 |  0:04:54s\n",
            "\n",
            "Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_auc = 0.96793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:46:16,833] Trial 42 finished with value: 0.9679305292830384 and parameters: {'n_d': 25, 'n_a': 11, 'n_steps': 6, 'gamma': 0.6411756538280047, 'momentum': 0.02857556770623576, 'lambda_sparse': 0.05846921136027806, 'lr': 0.0019579203519245816, 'weight_decay': 1.8932458680178543e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.74316 | val_0_auc: 0.49196 |  0:00:03s\n",
            "epoch 1  | loss: 0.57246 | val_0_auc: 0.67223 |  0:00:06s\n",
            "epoch 2  | loss: 0.52481 | val_0_auc: 0.80814 |  0:00:10s\n",
            "epoch 3  | loss: 0.49737 | val_0_auc: 0.87851 |  0:00:13s\n",
            "epoch 4  | loss: 0.45953 | val_0_auc: 0.91701 |  0:00:16s\n",
            "epoch 5  | loss: 0.43362 | val_0_auc: 0.91467 |  0:00:19s\n",
            "epoch 6  | loss: 0.42161 | val_0_auc: 0.92965 |  0:00:23s\n",
            "epoch 7  | loss: 0.40777 | val_0_auc: 0.92883 |  0:00:26s\n",
            "epoch 8  | loss: 0.41634 | val_0_auc: 0.93767 |  0:00:30s\n",
            "epoch 9  | loss: 0.39541 | val_0_auc: 0.94106 |  0:00:33s\n",
            "epoch 10 | loss: 0.3845  | val_0_auc: 0.94559 |  0:00:36s\n",
            "epoch 11 | loss: 0.38041 | val_0_auc: 0.94963 |  0:00:39s\n",
            "epoch 12 | loss: 0.3724  | val_0_auc: 0.93949 |  0:00:42s\n",
            "epoch 13 | loss: 0.36645 | val_0_auc: 0.94995 |  0:00:45s\n",
            "epoch 14 | loss: 0.35935 | val_0_auc: 0.95065 |  0:00:49s\n",
            "epoch 15 | loss: 0.35656 | val_0_auc: 0.95747 |  0:00:52s\n",
            "epoch 16 | loss: 0.36018 | val_0_auc: 0.95502 |  0:00:55s\n",
            "epoch 17 | loss: 0.34248 | val_0_auc: 0.95684 |  0:00:59s\n",
            "epoch 18 | loss: 0.3369  | val_0_auc: 0.95339 |  0:01:02s\n",
            "epoch 19 | loss: 0.35871 | val_0_auc: 0.95818 |  0:01:05s\n",
            "epoch 20 | loss: 0.35205 | val_0_auc: 0.95823 |  0:01:08s\n",
            "epoch 21 | loss: 0.34324 | val_0_auc: 0.96368 |  0:01:12s\n",
            "epoch 22 | loss: 0.33336 | val_0_auc: 0.95655 |  0:01:14s\n",
            "epoch 23 | loss: 0.33187 | val_0_auc: 0.957   |  0:01:17s\n",
            "epoch 24 | loss: 0.3218  | val_0_auc: 0.94527 |  0:01:20s\n",
            "epoch 25 | loss: 0.33441 | val_0_auc: 0.95873 |  0:01:23s\n",
            "epoch 26 | loss: 0.32099 | val_0_auc: 0.96044 |  0:01:26s\n",
            "epoch 27 | loss: 0.325   | val_0_auc: 0.95943 |  0:01:29s\n",
            "epoch 28 | loss: 0.32594 | val_0_auc: 0.95757 |  0:01:32s\n",
            "epoch 29 | loss: 0.32313 | val_0_auc: 0.95949 |  0:01:36s\n",
            "epoch 30 | loss: 0.31205 | val_0_auc: 0.95826 |  0:01:38s\n",
            "epoch 31 | loss: 0.30798 | val_0_auc: 0.95962 |  0:01:42s\n",
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.96368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:48:00,623] Trial 43 finished with value: 0.9636805632827663 and parameters: {'n_d': 29, 'n_a': 20, 'n_steps': 6, 'gamma': 0.5194585246838738, 'momentum': 0.010380295236262948, 'lambda_sparse': 0.03854887558346275, 'lr': 0.003928166374432784, 'weight_decay': 3.0656338913117106e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.92773 | val_0_auc: 0.4897  |  0:00:03s\n",
            "epoch 1  | loss: 0.63457 | val_0_auc: 0.70003 |  0:00:07s\n",
            "epoch 2  | loss: 0.58168 | val_0_auc: 0.84245 |  0:00:10s\n",
            "epoch 3  | loss: 0.53814 | val_0_auc: 0.89539 |  0:00:14s\n",
            "epoch 4  | loss: 0.50952 | val_0_auc: 0.92413 |  0:00:18s\n",
            "epoch 5  | loss: 0.49969 | val_0_auc: 0.93176 |  0:00:21s\n",
            "epoch 6  | loss: 0.4733  | val_0_auc: 0.93627 |  0:00:25s\n",
            "epoch 7  | loss: 0.46116 | val_0_auc: 0.93848 |  0:00:29s\n",
            "epoch 8  | loss: 0.44543 | val_0_auc: 0.94758 |  0:00:32s\n",
            "epoch 9  | loss: 0.44451 | val_0_auc: 0.94563 |  0:00:35s\n",
            "epoch 10 | loss: 0.43792 | val_0_auc: 0.95054 |  0:00:39s\n",
            "epoch 11 | loss: 0.43492 | val_0_auc: 0.95117 |  0:00:43s\n",
            "epoch 12 | loss: 0.42639 | val_0_auc: 0.95161 |  0:00:46s\n",
            "epoch 13 | loss: 0.42251 | val_0_auc: 0.95197 |  0:00:49s\n",
            "epoch 14 | loss: 0.41621 | val_0_auc: 0.95005 |  0:00:53s\n",
            "epoch 15 | loss: 0.41625 | val_0_auc: 0.95537 |  0:00:57s\n",
            "epoch 16 | loss: 0.40783 | val_0_auc: 0.95755 |  0:01:00s\n",
            "epoch 17 | loss: 0.40325 | val_0_auc: 0.95147 |  0:01:04s\n",
            "epoch 18 | loss: 0.39758 | val_0_auc: 0.95517 |  0:01:08s\n",
            "epoch 19 | loss: 0.39207 | val_0_auc: 0.9568  |  0:01:12s\n",
            "epoch 20 | loss: 0.39488 | val_0_auc: 0.95529 |  0:01:16s\n",
            "epoch 21 | loss: 0.39739 | val_0_auc: 0.95212 |  0:01:19s\n",
            "epoch 22 | loss: 0.39417 | val_0_auc: 0.95493 |  0:01:23s\n",
            "epoch 23 | loss: 0.39273 | val_0_auc: 0.95767 |  0:01:26s\n",
            "epoch 24 | loss: 0.38541 | val_0_auc: 0.9599  |  0:01:30s\n",
            "epoch 25 | loss: 0.37987 | val_0_auc: 0.96306 |  0:01:34s\n",
            "epoch 26 | loss: 0.38704 | val_0_auc: 0.95769 |  0:01:37s\n",
            "epoch 27 | loss: 0.37588 | val_0_auc: 0.96342 |  0:01:40s\n",
            "epoch 28 | loss: 0.3809  | val_0_auc: 0.96324 |  0:01:44s\n",
            "epoch 29 | loss: 0.37445 | val_0_auc: 0.95957 |  0:01:48s\n",
            "epoch 30 | loss: 0.38375 | val_0_auc: 0.95965 |  0:01:52s\n",
            "epoch 31 | loss: 0.37217 | val_0_auc: 0.96336 |  0:01:56s\n",
            "epoch 32 | loss: 0.36521 | val_0_auc: 0.9611  |  0:02:00s\n",
            "epoch 33 | loss: 0.37045 | val_0_auc: 0.96147 |  0:02:03s\n",
            "epoch 34 | loss: 0.36299 | val_0_auc: 0.96199 |  0:02:07s\n",
            "epoch 35 | loss: 0.36173 | val_0_auc: 0.96093 |  0:02:11s\n",
            "epoch 36 | loss: 0.35972 | val_0_auc: 0.96759 |  0:02:15s\n",
            "epoch 37 | loss: 0.3567  | val_0_auc: 0.96417 |  0:02:20s\n",
            "epoch 38 | loss: 0.35734 | val_0_auc: 0.96505 |  0:02:24s\n",
            "epoch 39 | loss: 0.34933 | val_0_auc: 0.95942 |  0:02:28s\n",
            "epoch 40 | loss: 0.35183 | val_0_auc: 0.96594 |  0:02:32s\n",
            "epoch 41 | loss: 0.34938 | val_0_auc: 0.97023 |  0:02:37s\n",
            "epoch 42 | loss: 0.34156 | val_0_auc: 0.97055 |  0:02:40s\n",
            "epoch 43 | loss: 0.34764 | val_0_auc: 0.96524 |  0:02:44s\n",
            "epoch 44 | loss: 0.35965 | val_0_auc: 0.96922 |  0:02:49s\n",
            "epoch 45 | loss: 0.34699 | val_0_auc: 0.96401 |  0:02:52s\n",
            "epoch 46 | loss: 0.34151 | val_0_auc: 0.96377 |  0:02:56s\n",
            "epoch 47 | loss: 0.3434  | val_0_auc: 0.96617 |  0:03:00s\n",
            "epoch 48 | loss: 0.34071 | val_0_auc: 0.96843 |  0:03:04s\n",
            "epoch 49 | loss: 0.34708 | val_0_auc: 0.96744 |  0:03:08s\n",
            "epoch 50 | loss: 0.34165 | val_0_auc: 0.9662  |  0:03:12s\n",
            "epoch 51 | loss: 0.34551 | val_0_auc: 0.96778 |  0:03:16s\n",
            "epoch 52 | loss: 0.34074 | val_0_auc: 0.96684 |  0:03:20s\n",
            "\n",
            "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.97055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:51:23,156] Trial 44 finished with value: 0.9705454174548421 and parameters: {'n_d': 20, 'n_a': 24, 'n_steps': 7, 'gamma': 0.41965453032183275, 'momentum': 0.07508740023944552, 'lambda_sparse': 0.0648184210114426, 'lr': 0.0023635101729664963, 'weight_decay': 0.000168549105956022}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.72893 | val_0_auc: 0.52825 |  0:00:03s\n",
            "epoch 1  | loss: 0.57272 | val_0_auc: 0.69374 |  0:00:07s\n",
            "epoch 2  | loss: 0.53833 | val_0_auc: 0.87057 |  0:00:10s\n",
            "epoch 3  | loss: 0.51959 | val_0_auc: 0.91208 |  0:00:14s\n",
            "epoch 4  | loss: 0.49481 | val_0_auc: 0.93623 |  0:00:18s\n",
            "epoch 5  | loss: 0.48373 | val_0_auc: 0.9377  |  0:00:22s\n",
            "epoch 6  | loss: 0.47701 | val_0_auc: 0.95246 |  0:00:26s\n",
            "epoch 7  | loss: 0.46737 | val_0_auc: 0.94726 |  0:00:30s\n",
            "epoch 8  | loss: 0.47152 | val_0_auc: 0.94813 |  0:00:33s\n",
            "epoch 9  | loss: 0.46032 | val_0_auc: 0.93996 |  0:00:37s\n",
            "epoch 10 | loss: 0.46164 | val_0_auc: 0.94857 |  0:00:41s\n",
            "epoch 11 | loss: 0.44933 | val_0_auc: 0.94839 |  0:00:45s\n",
            "epoch 12 | loss: 0.44899 | val_0_auc: 0.94626 |  0:00:48s\n",
            "epoch 13 | loss: 0.43701 | val_0_auc: 0.95226 |  0:00:53s\n",
            "epoch 14 | loss: 0.4355  | val_0_auc: 0.94682 |  0:00:57s\n",
            "epoch 15 | loss: 0.42871 | val_0_auc: 0.95195 |  0:01:00s\n",
            "epoch 16 | loss: 0.42997 | val_0_auc: 0.95008 |  0:01:04s\n",
            "\n",
            "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.95246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:52:29,673] Trial 45 finished with value: 0.9524591075998665 and parameters: {'n_d': 13, 'n_a': 25, 'n_steps': 7, 'gamma': 0.3868897700582365, 'momentum': 0.1491397603534944, 'lambda_sparse': 0.07899429873904143, 'lr': 0.008011714382221109, 'weight_decay': 0.0002811552226366016}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.15743 | val_0_auc: 0.4964  |  0:00:03s\n",
            "epoch 1  | loss: 0.81774 | val_0_auc: 0.62478 |  0:00:07s\n",
            "epoch 2  | loss: 0.72512 | val_0_auc: 0.73757 |  0:00:11s\n",
            "epoch 3  | loss: 0.66771 | val_0_auc: 0.82003 |  0:00:14s\n",
            "epoch 4  | loss: 0.66188 | val_0_auc: 0.85211 |  0:00:18s\n",
            "epoch 5  | loss: 0.62088 | val_0_auc: 0.86913 |  0:00:22s\n",
            "epoch 6  | loss: 0.58946 | val_0_auc: 0.86928 |  0:00:26s\n",
            "epoch 7  | loss: 0.5664  | val_0_auc: 0.88817 |  0:00:29s\n",
            "epoch 8  | loss: 0.54504 | val_0_auc: 0.89987 |  0:00:34s\n",
            "epoch 9  | loss: 0.54569 | val_0_auc: 0.89338 |  0:00:37s\n",
            "epoch 10 | loss: 0.52395 | val_0_auc: 0.90255 |  0:00:41s\n",
            "epoch 11 | loss: 0.50486 | val_0_auc: 0.90329 |  0:00:45s\n",
            "epoch 12 | loss: 0.51461 | val_0_auc: 0.90942 |  0:00:49s\n",
            "epoch 13 | loss: 0.49288 | val_0_auc: 0.90717 |  0:00:53s\n",
            "epoch 14 | loss: 0.48363 | val_0_auc: 0.91816 |  0:00:56s\n",
            "epoch 15 | loss: 0.47959 | val_0_auc: 0.9155  |  0:01:00s\n",
            "epoch 16 | loss: 0.475   | val_0_auc: 0.92585 |  0:01:04s\n",
            "epoch 17 | loss: 0.46626 | val_0_auc: 0.92751 |  0:01:07s\n",
            "epoch 18 | loss: 0.46176 | val_0_auc: 0.93511 |  0:01:11s\n",
            "epoch 19 | loss: 0.45138 | val_0_auc: 0.94139 |  0:01:14s\n",
            "epoch 20 | loss: 0.44768 | val_0_auc: 0.9402  |  0:01:18s\n",
            "epoch 21 | loss: 0.44016 | val_0_auc: 0.94186 |  0:01:21s\n",
            "epoch 22 | loss: 0.43172 | val_0_auc: 0.94043 |  0:01:25s\n",
            "epoch 23 | loss: 0.43112 | val_0_auc: 0.93956 |  0:01:28s\n",
            "epoch 24 | loss: 0.42661 | val_0_auc: 0.93852 |  0:01:32s\n",
            "epoch 25 | loss: 0.42744 | val_0_auc: 0.94641 |  0:01:37s\n",
            "epoch 26 | loss: 0.42306 | val_0_auc: 0.94904 |  0:01:40s\n",
            "epoch 27 | loss: 0.42283 | val_0_auc: 0.94121 |  0:01:44s\n",
            "epoch 28 | loss: 0.41213 | val_0_auc: 0.94852 |  0:01:48s\n",
            "epoch 29 | loss: 0.41387 | val_0_auc: 0.94534 |  0:01:51s\n",
            "epoch 30 | loss: 0.40632 | val_0_auc: 0.94844 |  0:01:55s\n",
            "epoch 31 | loss: 0.41942 | val_0_auc: 0.94776 |  0:01:58s\n",
            "epoch 32 | loss: 0.4061  | val_0_auc: 0.94992 |  0:02:03s\n",
            "epoch 33 | loss: 0.40277 | val_0_auc: 0.94663 |  0:02:06s\n",
            "epoch 34 | loss: 0.40053 | val_0_auc: 0.9492  |  0:02:10s\n",
            "epoch 35 | loss: 0.39988 | val_0_auc: 0.94272 |  0:02:14s\n",
            "epoch 36 | loss: 0.40474 | val_0_auc: 0.9484  |  0:02:17s\n",
            "epoch 37 | loss: 0.39738 | val_0_auc: 0.95119 |  0:02:21s\n",
            "epoch 38 | loss: 0.38917 | val_0_auc: 0.95196 |  0:02:25s\n",
            "epoch 39 | loss: 0.3969  | val_0_auc: 0.95007 |  0:02:29s\n",
            "epoch 40 | loss: 0.38638 | val_0_auc: 0.95279 |  0:02:32s\n",
            "epoch 41 | loss: 0.38891 | val_0_auc: 0.95362 |  0:02:36s\n",
            "epoch 42 | loss: 0.38607 | val_0_auc: 0.9539  |  0:02:40s\n",
            "epoch 43 | loss: 0.3738  | val_0_auc: 0.94395 |  0:02:44s\n",
            "epoch 44 | loss: 0.3821  | val_0_auc: 0.95245 |  0:02:48s\n",
            "epoch 45 | loss: 0.38031 | val_0_auc: 0.94796 |  0:02:52s\n",
            "epoch 46 | loss: 0.38049 | val_0_auc: 0.95283 |  0:02:56s\n",
            "epoch 47 | loss: 0.37277 | val_0_auc: 0.94616 |  0:02:59s\n",
            "epoch 48 | loss: 0.36665 | val_0_auc: 0.95203 |  0:03:04s\n",
            "epoch 49 | loss: 0.379   | val_0_auc: 0.94934 |  0:03:07s\n",
            "epoch 50 | loss: 0.37031 | val_0_auc: 0.94542 |  0:03:10s\n",
            "epoch 51 | loss: 0.38908 | val_0_auc: 0.95416 |  0:03:15s\n",
            "epoch 52 | loss: 0.36748 | val_0_auc: 0.95524 |  0:03:19s\n",
            "epoch 53 | loss: 0.37198 | val_0_auc: 0.95812 |  0:03:22s\n",
            "epoch 54 | loss: 0.37341 | val_0_auc: 0.95549 |  0:03:26s\n",
            "epoch 55 | loss: 0.36736 | val_0_auc: 0.9498  |  0:03:30s\n",
            "epoch 56 | loss: 0.37227 | val_0_auc: 0.94841 |  0:03:34s\n",
            "epoch 57 | loss: 0.36999 | val_0_auc: 0.95201 |  0:03:38s\n",
            "epoch 58 | loss: 0.36231 | val_0_auc: 0.9512  |  0:03:42s\n",
            "epoch 59 | loss: 0.36951 | val_0_auc: 0.9552  |  0:03:46s\n",
            "epoch 60 | loss: 0.35978 | val_0_auc: 0.95405 |  0:03:49s\n",
            "epoch 61 | loss: 0.35766 | val_0_auc: 0.9573  |  0:03:54s\n",
            "epoch 62 | loss: 0.35562 | val_0_auc: 0.95518 |  0:03:57s\n",
            "epoch 63 | loss: 0.34672 | val_0_auc: 0.95598 |  0:04:01s\n",
            "\n",
            "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.95812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 07:56:33,363] Trial 46 finished with value: 0.9581185168700468 and parameters: {'n_d': 19, 'n_a': 24, 'n_steps': 7, 'gamma': 0.7388070515760465, 'momentum': 0.03213762442753151, 'lambda_sparse': 0.06485001906966435, 'lr': 0.002398062677704912, 'weight_decay': 0.000458844441295308}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.80889 | val_0_auc: 0.62126 |  0:00:04s\n",
            "epoch 1  | loss: 0.56565 | val_0_auc: 0.8061  |  0:00:09s\n",
            "epoch 2  | loss: 0.50996 | val_0_auc: 0.88266 |  0:00:13s\n",
            "epoch 3  | loss: 0.48545 | val_0_auc: 0.91898 |  0:00:17s\n",
            "epoch 4  | loss: 0.47191 | val_0_auc: 0.93713 |  0:00:21s\n",
            "epoch 5  | loss: 0.45571 | val_0_auc: 0.94311 |  0:00:26s\n",
            "epoch 6  | loss: 0.43515 | val_0_auc: 0.94456 |  0:00:30s\n",
            "epoch 7  | loss: 0.43305 | val_0_auc: 0.94139 |  0:00:35s\n",
            "epoch 8  | loss: 0.43579 | val_0_auc: 0.94684 |  0:00:39s\n",
            "epoch 9  | loss: 0.43254 | val_0_auc: 0.9516  |  0:00:44s\n",
            "epoch 10 | loss: 0.42543 | val_0_auc: 0.9546  |  0:00:48s\n",
            "epoch 11 | loss: 0.40845 | val_0_auc: 0.95599 |  0:00:52s\n",
            "epoch 12 | loss: 0.41331 | val_0_auc: 0.94939 |  0:00:56s\n",
            "epoch 13 | loss: 0.40834 | val_0_auc: 0.9506  |  0:01:00s\n",
            "epoch 14 | loss: 0.39675 | val_0_auc: 0.95799 |  0:01:05s\n",
            "epoch 15 | loss: 0.401   | val_0_auc: 0.95299 |  0:01:08s\n",
            "epoch 16 | loss: 0.3928  | val_0_auc: 0.95461 |  0:01:12s\n",
            "epoch 17 | loss: 0.38823 | val_0_auc: 0.95702 |  0:01:17s\n",
            "epoch 18 | loss: 0.38048 | val_0_auc: 0.9466  |  0:01:21s\n",
            "epoch 19 | loss: 0.38005 | val_0_auc: 0.94491 |  0:01:25s\n",
            "epoch 20 | loss: 0.3814  | val_0_auc: 0.95868 |  0:01:30s\n",
            "epoch 21 | loss: 0.36918 | val_0_auc: 0.94058 |  0:01:35s\n",
            "epoch 22 | loss: 0.38064 | val_0_auc: 0.95412 |  0:01:39s\n",
            "epoch 23 | loss: 0.35953 | val_0_auc: 0.95656 |  0:01:44s\n",
            "epoch 24 | loss: 0.35894 | val_0_auc: 0.95997 |  0:01:48s\n",
            "epoch 25 | loss: 0.36237 | val_0_auc: 0.96465 |  0:01:52s\n",
            "epoch 26 | loss: 0.34923 | val_0_auc: 0.96442 |  0:01:56s\n",
            "epoch 27 | loss: 0.3595  | val_0_auc: 0.9629  |  0:02:01s\n",
            "epoch 28 | loss: 0.34765 | val_0_auc: 0.95729 |  0:02:05s\n",
            "epoch 29 | loss: 0.33495 | val_0_auc: 0.96458 |  0:02:09s\n",
            "epoch 30 | loss: 0.33231 | val_0_auc: 0.96168 |  0:02:13s\n",
            "epoch 31 | loss: 0.34792 | val_0_auc: 0.95889 |  0:02:19s\n",
            "epoch 32 | loss: 0.33874 | val_0_auc: 0.95866 |  0:02:23s\n",
            "epoch 33 | loss: 0.34799 | val_0_auc: 0.96355 |  0:02:28s\n",
            "epoch 34 | loss: 0.33625 | val_0_auc: 0.96852 |  0:02:32s\n",
            "epoch 35 | loss: 0.33488 | val_0_auc: 0.96378 |  0:02:38s\n",
            "epoch 36 | loss: 0.33773 | val_0_auc: 0.96324 |  0:02:42s\n",
            "epoch 37 | loss: 0.32428 | val_0_auc: 0.96609 |  0:02:47s\n",
            "epoch 38 | loss: 0.3236  | val_0_auc: 0.96288 |  0:02:51s\n",
            "epoch 39 | loss: 0.32699 | val_0_auc: 0.96348 |  0:02:56s\n",
            "epoch 40 | loss: 0.32578 | val_0_auc: 0.9658  |  0:03:01s\n",
            "epoch 41 | loss: 0.312   | val_0_auc: 0.96898 |  0:03:05s\n",
            "epoch 42 | loss: 0.31821 | val_0_auc: 0.96531 |  0:03:10s\n",
            "epoch 43 | loss: 0.31107 | val_0_auc: 0.96692 |  0:03:15s\n",
            "epoch 44 | loss: 0.30038 | val_0_auc: 0.96636 |  0:03:20s\n",
            "epoch 45 | loss: 0.3081  | val_0_auc: 0.95957 |  0:03:25s\n",
            "epoch 46 | loss: 0.30638 | val_0_auc: 0.96757 |  0:03:31s\n",
            "epoch 47 | loss: 0.31107 | val_0_auc: 0.96896 |  0:03:37s\n",
            "epoch 48 | loss: 0.29998 | val_0_auc: 0.96845 |  0:03:42s\n",
            "epoch 49 | loss: 0.30505 | val_0_auc: 0.96925 |  0:03:47s\n",
            "epoch 50 | loss: 0.29764 | val_0_auc: 0.96414 |  0:03:52s\n",
            "epoch 51 | loss: 0.30275 | val_0_auc: 0.96259 |  0:03:57s\n",
            "epoch 52 | loss: 0.31009 | val_0_auc: 0.9666  |  0:04:01s\n",
            "epoch 53 | loss: 0.28957 | val_0_auc: 0.96628 |  0:04:06s\n",
            "epoch 54 | loss: 0.29265 | val_0_auc: 0.96778 |  0:04:10s\n",
            "epoch 55 | loss: 0.28235 | val_0_auc: 0.96373 |  0:04:15s\n",
            "epoch 56 | loss: 0.28603 | val_0_auc: 0.97101 |  0:04:20s\n",
            "epoch 57 | loss: 0.29416 | val_0_auc: 0.96586 |  0:04:25s\n",
            "epoch 58 | loss: 0.29516 | val_0_auc: 0.9654  |  0:04:30s\n",
            "epoch 59 | loss: 0.28836 | val_0_auc: 0.95814 |  0:04:34s\n",
            "epoch 60 | loss: 0.28539 | val_0_auc: 0.96449 |  0:04:39s\n",
            "epoch 61 | loss: 0.28    | val_0_auc: 0.96709 |  0:04:44s\n",
            "epoch 62 | loss: 0.28313 | val_0_auc: 0.97013 |  0:04:49s\n",
            "epoch 63 | loss: 0.27798 | val_0_auc: 0.96785 |  0:04:54s\n",
            "epoch 64 | loss: 0.26874 | val_0_auc: 0.97065 |  0:04:59s\n",
            "epoch 65 | loss: 0.27943 | val_0_auc: 0.96624 |  0:05:04s\n",
            "epoch 66 | loss: 0.27534 | val_0_auc: 0.96996 |  0:05:09s\n",
            "\n",
            "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_auc = 0.97101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 08:01:46,433] Trial 47 finished with value: 0.9710075046672353 and parameters: {'n_d': 27, 'n_a': 31, 'n_steps': 8, 'gamma': 0.5294336095416285, 'momentum': 0.08993640402278157, 'lambda_sparse': 0.07117058528154478, 'lr': 0.014584593280225057, 'weight_decay': 1.5968511924014647e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.89401 | val_0_auc: 0.54723 |  0:00:04s\n",
            "epoch 1  | loss: 0.56185 | val_0_auc: 0.8314  |  0:00:08s\n",
            "epoch 2  | loss: 0.50774 | val_0_auc: 0.89574 |  0:00:13s\n",
            "epoch 3  | loss: 0.50594 | val_0_auc: 0.93039 |  0:00:18s\n",
            "epoch 4  | loss: 0.48347 | val_0_auc: 0.94313 |  0:00:22s\n",
            "epoch 5  | loss: 0.45051 | val_0_auc: 0.94724 |  0:00:27s\n",
            "epoch 6  | loss: 0.45486 | val_0_auc: 0.94412 |  0:00:32s\n",
            "epoch 7  | loss: 0.44235 | val_0_auc: 0.95357 |  0:00:37s\n",
            "epoch 8  | loss: 0.44581 | val_0_auc: 0.93295 |  0:00:41s\n",
            "epoch 9  | loss: 0.44378 | val_0_auc: 0.95306 |  0:00:45s\n",
            "epoch 10 | loss: 0.43899 | val_0_auc: 0.95158 |  0:00:51s\n",
            "epoch 11 | loss: 0.43465 | val_0_auc: 0.95119 |  0:00:55s\n",
            "epoch 12 | loss: 0.40465 | val_0_auc: 0.94781 |  0:01:00s\n",
            "epoch 13 | loss: 0.41374 | val_0_auc: 0.95054 |  0:01:05s\n",
            "epoch 14 | loss: 0.41614 | val_0_auc: 0.95281 |  0:01:10s\n",
            "epoch 15 | loss: 0.40932 | val_0_auc: 0.94613 |  0:01:15s\n",
            "epoch 16 | loss: 0.40861 | val_0_auc: 0.96147 |  0:01:20s\n",
            "epoch 17 | loss: 0.40438 | val_0_auc: 0.95319 |  0:01:25s\n",
            "epoch 18 | loss: 0.40665 | val_0_auc: 0.95282 |  0:01:29s\n",
            "epoch 19 | loss: 0.4108  | val_0_auc: 0.96097 |  0:01:34s\n",
            "epoch 20 | loss: 0.39679 | val_0_auc: 0.95258 |  0:01:39s\n",
            "epoch 21 | loss: 0.39408 | val_0_auc: 0.95854 |  0:01:43s\n",
            "epoch 22 | loss: 0.37768 | val_0_auc: 0.95065 |  0:01:48s\n",
            "epoch 23 | loss: 0.391   | val_0_auc: 0.95974 |  0:01:53s\n",
            "epoch 24 | loss: 0.37005 | val_0_auc: 0.96225 |  0:01:58s\n",
            "epoch 25 | loss: 0.37869 | val_0_auc: 0.95864 |  0:02:03s\n",
            "epoch 26 | loss: 0.37894 | val_0_auc: 0.95734 |  0:02:08s\n",
            "epoch 27 | loss: 0.36052 | val_0_auc: 0.95634 |  0:02:12s\n",
            "epoch 28 | loss: 0.38454 | val_0_auc: 0.95913 |  0:02:17s\n",
            "epoch 29 | loss: 0.36827 | val_0_auc: 0.96036 |  0:02:22s\n",
            "epoch 30 | loss: 0.37152 | val_0_auc: 0.96556 |  0:02:27s\n",
            "epoch 31 | loss: 0.36376 | val_0_auc: 0.9594  |  0:02:32s\n",
            "epoch 32 | loss: 0.3703  | val_0_auc: 0.95673 |  0:02:37s\n",
            "epoch 33 | loss: 0.36112 | val_0_auc: 0.95903 |  0:02:42s\n",
            "epoch 34 | loss: 0.34891 | val_0_auc: 0.96596 |  0:02:47s\n",
            "epoch 35 | loss: 0.3414  | val_0_auc: 0.96549 |  0:02:52s\n",
            "epoch 36 | loss: 0.34922 | val_0_auc: 0.96088 |  0:02:57s\n",
            "epoch 37 | loss: 0.34543 | val_0_auc: 0.96099 |  0:03:02s\n",
            "epoch 38 | loss: 0.34789 | val_0_auc: 0.9657  |  0:03:07s\n",
            "epoch 39 | loss: 0.33088 | val_0_auc: 0.96181 |  0:03:11s\n",
            "epoch 40 | loss: 0.33465 | val_0_auc: 0.96524 |  0:03:17s\n",
            "epoch 41 | loss: 0.33323 | val_0_auc: 0.96566 |  0:03:22s\n",
            "epoch 42 | loss: 0.33013 | val_0_auc: 0.96295 |  0:03:27s\n",
            "epoch 43 | loss: 0.32607 | val_0_auc: 0.96445 |  0:03:33s\n",
            "epoch 44 | loss: 0.33066 | val_0_auc: 0.96378 |  0:03:37s\n",
            "\n",
            "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.96596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 08:05:27,295] Trial 48 finished with value: 0.9659647268276399 and parameters: {'n_d': 24, 'n_a': 31, 'n_steps': 9, 'gamma': 0.5287662286780003, 'momentum': 0.0956724557639195, 'lambda_sparse': 0.08116785304294535, 'lr': 0.01516353030996161, 'weight_decay': 1.6076026228933898e-05}. Best is trial 38 with value: 0.975450650940247.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.79364 | val_0_auc: 0.64    |  0:00:04s\n",
            "epoch 1  | loss: 0.664   | val_0_auc: 0.52352 |  0:00:08s\n",
            "epoch 2  | loss: 0.65119 | val_0_auc: 0.71959 |  0:00:11s\n",
            "epoch 3  | loss: 0.63873 | val_0_auc: 0.78069 |  0:00:16s\n",
            "epoch 4  | loss: 0.62226 | val_0_auc: 0.80295 |  0:00:19s\n",
            "epoch 5  | loss: 0.61307 | val_0_auc: 0.80288 |  0:00:23s\n",
            "epoch 6  | loss: 0.60311 | val_0_auc: 0.81347 |  0:00:27s\n",
            "epoch 7  | loss: 0.59884 | val_0_auc: 0.8276  |  0:00:30s\n",
            "epoch 8  | loss: 0.57041 | val_0_auc: 0.84863 |  0:00:34s\n",
            "epoch 9  | loss: 0.56163 | val_0_auc: 0.84472 |  0:00:38s\n",
            "epoch 10 | loss: 0.55599 | val_0_auc: 0.85676 |  0:00:43s\n",
            "epoch 11 | loss: 0.54271 | val_0_auc: 0.84091 |  0:00:47s\n",
            "epoch 12 | loss: 0.5415  | val_0_auc: 0.86644 |  0:00:50s\n",
            "epoch 13 | loss: 0.52576 | val_0_auc: 0.86572 |  0:00:55s\n",
            "epoch 14 | loss: 0.53424 | val_0_auc: 0.8713  |  0:00:58s\n",
            "epoch 15 | loss: 0.53325 | val_0_auc: 0.86743 |  0:01:02s\n",
            "epoch 16 | loss: 0.5208  | val_0_auc: 0.86274 |  0:01:06s\n",
            "epoch 17 | loss: 0.52493 | val_0_auc: 0.85311 |  0:01:10s\n",
            "epoch 18 | loss: 0.52237 | val_0_auc: 0.85612 |  0:01:14s\n",
            "epoch 19 | loss: 0.52202 | val_0_auc: 0.84936 |  0:01:19s\n",
            "epoch 20 | loss: 0.52938 | val_0_auc: 0.87625 |  0:01:23s\n",
            "epoch 21 | loss: 0.51314 | val_0_auc: 0.87881 |  0:01:27s\n",
            "epoch 22 | loss: 0.50108 | val_0_auc: 0.87861 |  0:01:31s\n",
            "epoch 23 | loss: 0.49565 | val_0_auc: 0.89036 |  0:01:35s\n",
            "epoch 24 | loss: 0.48474 | val_0_auc: 0.88384 |  0:01:39s\n",
            "epoch 25 | loss: 0.47709 | val_0_auc: 0.89474 |  0:01:43s\n",
            "epoch 26 | loss: 0.46446 | val_0_auc: 0.89607 |  0:01:47s\n",
            "epoch 27 | loss: 0.45909 | val_0_auc: 0.90486 |  0:01:50s\n",
            "epoch 28 | loss: 0.45155 | val_0_auc: 0.90743 |  0:01:55s\n",
            "epoch 29 | loss: 0.45523 | val_0_auc: 0.90657 |  0:01:59s\n",
            "epoch 30 | loss: 0.44712 | val_0_auc: 0.90469 |  0:02:02s\n",
            "epoch 31 | loss: 0.43454 | val_0_auc: 0.90535 |  0:02:07s\n",
            "epoch 32 | loss: 0.44279 | val_0_auc: 0.91108 |  0:02:11s\n",
            "epoch 33 | loss: 0.441   | val_0_auc: 0.89721 |  0:02:15s\n",
            "epoch 34 | loss: 0.4434  | val_0_auc: 0.91318 |  0:02:19s\n",
            "epoch 35 | loss: 0.43222 | val_0_auc: 0.90636 |  0:02:23s\n",
            "epoch 36 | loss: 0.43539 | val_0_auc: 0.91079 |  0:02:27s\n",
            "epoch 37 | loss: 0.43929 | val_0_auc: 0.90585 |  0:02:32s\n",
            "epoch 38 | loss: 0.43224 | val_0_auc: 0.89787 |  0:02:36s\n",
            "epoch 39 | loss: 0.43015 | val_0_auc: 0.91096 |  0:02:40s\n",
            "epoch 40 | loss: 0.42952 | val_0_auc: 0.90918 |  0:02:45s\n",
            "epoch 41 | loss: 0.42559 | val_0_auc: 0.91724 |  0:02:49s\n",
            "epoch 42 | loss: 0.41597 | val_0_auc: 0.92322 |  0:02:52s\n",
            "epoch 43 | loss: 0.40646 | val_0_auc: 0.91704 |  0:02:57s\n",
            "epoch 44 | loss: 0.4087  | val_0_auc: 0.92469 |  0:03:01s\n",
            "epoch 45 | loss: 0.39818 | val_0_auc: 0.92011 |  0:03:05s\n",
            "epoch 46 | loss: 0.40335 | val_0_auc: 0.90472 |  0:03:10s\n",
            "epoch 47 | loss: 0.41284 | val_0_auc: 0.9296  |  0:03:14s\n",
            "epoch 48 | loss: 0.40317 | val_0_auc: 0.92596 |  0:03:18s\n",
            "epoch 49 | loss: 0.39962 | val_0_auc: 0.92657 |  0:03:23s\n",
            "epoch 50 | loss: 0.38553 | val_0_auc: 0.92065 |  0:03:27s\n",
            "epoch 51 | loss: 0.38579 | val_0_auc: 0.93379 |  0:03:31s\n",
            "epoch 52 | loss: 0.38755 | val_0_auc: 0.93038 |  0:03:36s\n",
            "epoch 53 | loss: 0.39975 | val_0_auc: 0.92873 |  0:03:39s\n",
            "epoch 54 | loss: 0.38891 | val_0_auc: 0.92089 |  0:03:44s\n",
            "epoch 55 | loss: 0.38106 | val_0_auc: 0.93078 |  0:03:49s\n",
            "epoch 56 | loss: 0.38038 | val_0_auc: 0.92894 |  0:03:53s\n",
            "epoch 57 | loss: 0.38821 | val_0_auc: 0.92608 |  0:03:57s\n",
            "epoch 58 | loss: 0.38842 | val_0_auc: 0.94202 |  0:04:01s\n",
            "epoch 59 | loss: 0.36639 | val_0_auc: 0.94335 |  0:04:06s\n",
            "epoch 60 | loss: 0.38564 | val_0_auc: 0.93214 |  0:04:09s\n",
            "epoch 61 | loss: 0.37371 | val_0_auc: 0.92755 |  0:04:14s\n",
            "epoch 62 | loss: 0.37286 | val_0_auc: 0.93085 |  0:04:17s\n",
            "epoch 63 | loss: 0.36138 | val_0_auc: 0.94523 |  0:04:21s\n",
            "epoch 64 | loss: 0.36746 | val_0_auc: 0.92092 |  0:04:26s\n",
            "epoch 65 | loss: 0.36172 | val_0_auc: 0.94597 |  0:04:30s\n",
            "epoch 66 | loss: 0.35383 | val_0_auc: 0.94116 |  0:04:34s\n",
            "epoch 67 | loss: 0.35361 | val_0_auc: 0.94102 |  0:04:39s\n",
            "epoch 68 | loss: 0.3576  | val_0_auc: 0.94383 |  0:04:43s\n",
            "epoch 69 | loss: 0.35318 | val_0_auc: 0.94021 |  0:04:47s\n",
            "epoch 70 | loss: 0.34622 | val_0_auc: 0.94102 |  0:04:52s\n",
            "epoch 71 | loss: 0.35493 | val_0_auc: 0.93999 |  0:04:56s\n",
            "epoch 72 | loss: 0.34722 | val_0_auc: 0.945   |  0:05:00s\n",
            "epoch 73 | loss: 0.33928 | val_0_auc: 0.94737 |  0:05:04s\n",
            "epoch 74 | loss: 0.35135 | val_0_auc: 0.94819 |  0:05:08s\n",
            "epoch 75 | loss: 0.34329 | val_0_auc: 0.94284 |  0:05:12s\n",
            "epoch 76 | loss: 0.34843 | val_0_auc: 0.95327 |  0:05:16s\n",
            "epoch 77 | loss: 0.34491 | val_0_auc: 0.94808 |  0:05:20s\n",
            "epoch 78 | loss: 0.33634 | val_0_auc: 0.94591 |  0:05:25s\n",
            "epoch 79 | loss: 0.34359 | val_0_auc: 0.9489  |  0:05:29s\n",
            "epoch 80 | loss: 0.33771 | val_0_auc: 0.95157 |  0:05:33s\n",
            "epoch 81 | loss: 0.33157 | val_0_auc: 0.95545 |  0:05:38s\n",
            "epoch 82 | loss: 0.34973 | val_0_auc: 0.93701 |  0:05:42s\n",
            "epoch 83 | loss: 0.3481  | val_0_auc: 0.94763 |  0:05:46s\n",
            "epoch 84 | loss: 0.34921 | val_0_auc: 0.94848 |  0:05:50s\n",
            "epoch 85 | loss: 0.33452 | val_0_auc: 0.95025 |  0:05:55s\n",
            "epoch 86 | loss: 0.34208 | val_0_auc: 0.95177 |  0:05:59s\n",
            "epoch 87 | loss: 0.34019 | val_0_auc: 0.94828 |  0:06:03s\n",
            "epoch 88 | loss: 0.3355  | val_0_auc: 0.9508  |  0:06:07s\n",
            "epoch 89 | loss: 0.3205  | val_0_auc: 0.95242 |  0:06:11s\n",
            "epoch 90 | loss: 0.32798 | val_0_auc: 0.95249 |  0:06:16s\n",
            "epoch 91 | loss: 0.32634 | val_0_auc: 0.95513 |  0:06:21s\n",
            "\n",
            "Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_auc = 0.95545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2024-05-05 08:11:50,498] Trial 49 finished with value: 0.9554510836640582 and parameters: {'n_d': 20, 'n_a': 19, 'n_steps': 8, 'gamma': 1.0210263884242745, 'momentum': 0.032915316026192826, 'lambda_sparse': 0.07064482653973278, 'lr': 0.010064764315466776, 'weight_decay': 3.294668802349544e-05}. Best is trial 38 with value: 0.975450650940247.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'n_d': 25, 'n_a': 22, 'n_steps': 6, 'gamma': 0.3656150938326871, 'momentum': 0.0816254305857589, 'lambda_sparse': 0.05103010863006034, 'lr': 0.0018506127775402865, 'weight_decay': 5.376118014372652e-05}\n",
            "Best AUC: 0.975450650940247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import optuna.visualization as vis\n",
        "\n",
        "fig = vis.plot_optimization_history(study)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Jt6SiQRiWbsF",
        "outputId": "24965518-5753-4e51-9f26-a51e86a103a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"589bd282-94f4-4282-b74a-f1b7965a58ae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"589bd282-94f4-4282-b74a-f1b7965a58ae\")) {                    Plotly.newPlot(                        \"589bd282-94f4-4282-b74a-f1b7965a58ae\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.920351000828357,0.9555159922356984,0.9486434108527132,0.9627007529394311,0.9502352163000879,0.927436853232447,0.9143685941421559,0.960408862183648,0.9445433527440872,0.9592520987104831,0.9458940692110827,0.8546047995252402,0.9577105201340207,0.9377001347625582,0.9171333902056055,0.949893673577884,0.9404123857918227,0.9661254528145593,0.9658967273716356,0.9607735865385805,0.9547185440698293,0.9636017457314886,0.9515797509983558,0.9510496643299582,0.943448406958199,0.9688608854765526,0.9474286932977263,0.9652229145803196,0.930883189298122,0.9676121681935635,0.9687836133674568,0.9729454891633594,0.9614242176971676,0.9619311227328363,0.9658101826094482,0.9545068184909067,0.9567291643485033,0.9659940902290963,0.975450650940247,0.8891207052161764,0.9577692469369335,0.9752481980144159,0.9679305292830384,0.9636805632827663,0.9705454174548421,0.9524591075998665,0.9581185168700468,0.9710075046672353,0.9659647268276399,0.9554510836640582],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.920351000828357,0.9555159922356984,0.9555159922356984,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9627007529394311,0.9661254528145593,0.9661254528145593,0.9661254528145593,0.9661254528145593,0.9661254528145593,0.9661254528145593,0.9661254528145593,0.9661254528145593,0.9688608854765526,0.9688608854765526,0.9688608854765526,0.9688608854765526,0.9688608854765526,0.9688608854765526,0.9729454891633594,0.9729454891633594,0.9729454891633594,0.9729454891633594,0.9729454891633594,0.9729454891633594,0.9729454891633594,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247,0.975450650940247],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('589bd282-94f4-4282-b74a-f1b7965a58ae');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('balanced_dataset.csv')\n",
        "\n",
        "X = data.drop(columns=['Preterm Pregnancy'])\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "fixed_params = {\n",
        "    \"n_d\": 25,\n",
        "    \"n_a\": 22,\n",
        "    \"n_steps\": 6,\n",
        "    \"gamma\": 0.3656150938326871,\n",
        "    \"momentum\": 0.0816254305857589,\n",
        "    \"lambda_sparse\": 0.05103010863006034,\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.0018506127775402865,\n",
        "        \"weight_decay\": 5.376118014372652e-05\n",
        "    },\n",
        "    \"mask_type\": \"entmax\",\n",
        "}\n",
        "\n",
        "\n",
        "model = TabNetClassifier(**fixed_params)\n",
        "\n",
        "model.fit(X.values, y.values, eval_set=[(X.values, y.values)],\n",
        "          eval_name=['train'], eval_metric=['accuracy'],\n",
        "          max_epochs=200,\n",
        "          batch_size=128, virtual_batch_size=32, num_workers=0, drop_last=False,\n",
        "          patience=-1)\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(feature_importance_df.set_index('Feature'), cmap='coolwarm', annot=True, fmt=\".3f\")\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "\n",
        "y_pred = model.predict(X.values)\n",
        "\n",
        "final_accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Final Accuracy:\", final_accuracy)\n",
        "\n",
        "\n",
        "class_report = classification_report(y, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9YebucnyzGek",
        "outputId": "0b3ec636-c608-4867-a5d8-b801bbdb2c28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.73366 | train_accuracy: 0.55196 |  0:00:05s\n",
            "epoch 1  | loss: 0.55619 | train_accuracy: 0.70674 |  0:00:09s\n",
            "epoch 2  | loss: 0.51972 | train_accuracy: 0.83105 |  0:00:15s\n",
            "epoch 3  | loss: 0.48386 | train_accuracy: 0.85791 |  0:00:20s\n",
            "epoch 4  | loss: 0.47531 | train_accuracy: 0.87805 |  0:00:24s\n",
            "epoch 5  | loss: 0.45185 | train_accuracy: 0.88178 |  0:00:30s\n",
            "epoch 6  | loss: 0.45082 | train_accuracy: 0.8855  |  0:00:34s\n",
            "epoch 7  | loss: 0.44494 | train_accuracy: 0.89781 |  0:00:39s\n",
            "epoch 8  | loss: 0.42636 | train_accuracy: 0.8957  |  0:00:44s\n",
            "epoch 9  | loss: 0.41832 | train_accuracy: 0.89707 |  0:00:48s\n",
            "epoch 10 | loss: 0.40796 | train_accuracy: 0.89433 |  0:00:53s\n",
            "epoch 11 | loss: 0.40967 | train_accuracy: 0.90055 |  0:00:58s\n",
            "epoch 12 | loss: 0.41252 | train_accuracy: 0.90577 |  0:01:03s\n",
            "epoch 13 | loss: 0.39908 | train_accuracy: 0.90651 |  0:01:08s\n",
            "epoch 14 | loss: 0.3921  | train_accuracy: 0.9003  |  0:01:12s\n",
            "epoch 15 | loss: 0.39339 | train_accuracy: 0.9095  |  0:01:17s\n",
            "epoch 16 | loss: 0.39125 | train_accuracy: 0.91037 |  0:01:23s\n",
            "epoch 17 | loss: 0.38157 | train_accuracy: 0.91559 |  0:01:27s\n",
            "epoch 18 | loss: 0.38061 | train_accuracy: 0.91397 |  0:01:31s\n",
            "epoch 19 | loss: 0.37928 | train_accuracy: 0.91857 |  0:01:39s\n",
            "epoch 20 | loss: 0.37251 | train_accuracy: 0.9141  |  0:01:44s\n",
            "epoch 21 | loss: 0.3701  | train_accuracy: 0.91484 |  0:01:49s\n",
            "epoch 22 | loss: 0.35841 | train_accuracy: 0.92466 |  0:01:55s\n",
            "epoch 23 | loss: 0.36256 | train_accuracy: 0.91099 |  0:02:00s\n",
            "epoch 24 | loss: 0.36159 | train_accuracy: 0.9233  |  0:02:05s\n",
            "epoch 25 | loss: 0.35893 | train_accuracy: 0.90925 |  0:02:10s\n",
            "epoch 26 | loss: 0.35681 | train_accuracy: 0.93088 |  0:02:16s\n",
            "epoch 27 | loss: 0.35434 | train_accuracy: 0.92429 |  0:02:21s\n",
            "epoch 28 | loss: 0.35532 | train_accuracy: 0.92429 |  0:02:26s\n",
            "epoch 29 | loss: 0.34834 | train_accuracy: 0.93722 |  0:02:32s\n",
            "epoch 30 | loss: 0.35333 | train_accuracy: 0.92877 |  0:02:37s\n",
            "epoch 31 | loss: 0.34248 | train_accuracy: 0.93001 |  0:02:43s\n",
            "epoch 32 | loss: 0.34197 | train_accuracy: 0.92802 |  0:02:48s\n",
            "epoch 33 | loss: 0.34061 | train_accuracy: 0.93921 |  0:02:54s\n",
            "epoch 34 | loss: 0.3403  | train_accuracy: 0.93536 |  0:02:59s\n",
            "epoch 35 | loss: 0.33223 | train_accuracy: 0.93337 |  0:03:04s\n",
            "epoch 36 | loss: 0.33687 | train_accuracy: 0.93287 |  0:03:10s\n",
            "epoch 37 | loss: 0.33233 | train_accuracy: 0.93809 |  0:03:15s\n",
            "epoch 38 | loss: 0.32896 | train_accuracy: 0.93013 |  0:03:21s\n",
            "epoch 39 | loss: 0.32723 | train_accuracy: 0.94331 |  0:03:27s\n",
            "epoch 40 | loss: 0.31855 | train_accuracy: 0.93063 |  0:03:33s\n",
            "epoch 41 | loss: 0.31066 | train_accuracy: 0.94418 |  0:03:38s\n",
            "epoch 42 | loss: 0.32504 | train_accuracy: 0.93921 |  0:03:44s\n",
            "epoch 43 | loss: 0.31907 | train_accuracy: 0.93212 |  0:03:50s\n",
            "epoch 44 | loss: 0.32315 | train_accuracy: 0.93884 |  0:03:55s\n",
            "epoch 45 | loss: 0.31604 | train_accuracy: 0.93287 |  0:04:01s\n",
            "epoch 46 | loss: 0.31323 | train_accuracy: 0.9504  |  0:04:06s\n",
            "epoch 47 | loss: 0.31881 | train_accuracy: 0.94567 |  0:04:12s\n",
            "epoch 48 | loss: 0.30794 | train_accuracy: 0.94157 |  0:04:18s\n",
            "epoch 49 | loss: 0.31062 | train_accuracy: 0.94766 |  0:04:23s\n",
            "epoch 50 | loss: 0.30987 | train_accuracy: 0.94493 |  0:04:29s\n",
            "epoch 51 | loss: 0.31051 | train_accuracy: 0.9366  |  0:04:34s\n",
            "epoch 52 | loss: 0.30327 | train_accuracy: 0.95065 |  0:04:40s\n",
            "epoch 53 | loss: 0.30735 | train_accuracy: 0.94443 |  0:04:45s\n",
            "epoch 54 | loss: 0.30065 | train_accuracy: 0.94953 |  0:04:51s\n",
            "epoch 55 | loss: 0.3143  | train_accuracy: 0.93946 |  0:04:57s\n",
            "epoch 56 | loss: 0.30854 | train_accuracy: 0.94344 |  0:05:02s\n",
            "epoch 57 | loss: 0.29919 | train_accuracy: 0.94468 |  0:05:09s\n",
            "epoch 58 | loss: 0.29016 | train_accuracy: 0.95326 |  0:05:14s\n",
            "epoch 59 | loss: 0.29187 | train_accuracy: 0.95835 |  0:05:20s\n",
            "epoch 60 | loss: 0.29814 | train_accuracy: 0.95674 |  0:05:25s\n",
            "epoch 61 | loss: 0.30062 | train_accuracy: 0.94281 |  0:05:30s\n",
            "epoch 62 | loss: 0.28793 | train_accuracy: 0.94766 |  0:05:37s\n",
            "epoch 63 | loss: 0.29423 | train_accuracy: 0.95114 |  0:05:47s\n",
            "epoch 64 | loss: 0.28916 | train_accuracy: 0.94841 |  0:05:52s\n",
            "epoch 65 | loss: 0.29572 | train_accuracy: 0.95027 |  0:05:57s\n",
            "epoch 66 | loss: 0.29104 | train_accuracy: 0.955   |  0:06:03s\n",
            "epoch 67 | loss: 0.28353 | train_accuracy: 0.95562 |  0:06:08s\n",
            "epoch 68 | loss: 0.2835  | train_accuracy: 0.95512 |  0:06:15s\n",
            "epoch 69 | loss: 0.28656 | train_accuracy: 0.94692 |  0:06:20s\n",
            "epoch 70 | loss: 0.28647 | train_accuracy: 0.9494  |  0:06:27s\n",
            "epoch 71 | loss: 0.28085 | train_accuracy: 0.95661 |  0:06:33s\n",
            "epoch 72 | loss: 0.27914 | train_accuracy: 0.95562 |  0:06:38s\n",
            "epoch 73 | loss: 0.28161 | train_accuracy: 0.96246 |  0:06:44s\n",
            "epoch 74 | loss: 0.27735 | train_accuracy: 0.95363 |  0:06:49s\n",
            "epoch 75 | loss: 0.27866 | train_accuracy: 0.96072 |  0:06:56s\n",
            "epoch 76 | loss: 0.27752 | train_accuracy: 0.95636 |  0:07:01s\n",
            "epoch 77 | loss: 0.26773 | train_accuracy: 0.95276 |  0:07:07s\n",
            "epoch 78 | loss: 0.28532 | train_accuracy: 0.95599 |  0:07:12s\n",
            "epoch 79 | loss: 0.2671  | train_accuracy: 0.95264 |  0:07:17s\n",
            "epoch 80 | loss: 0.27638 | train_accuracy: 0.95748 |  0:07:24s\n",
            "epoch 81 | loss: 0.27478 | train_accuracy: 0.95264 |  0:07:29s\n",
            "epoch 82 | loss: 0.26861 | train_accuracy: 0.96084 |  0:07:35s\n",
            "epoch 83 | loss: 0.27757 | train_accuracy: 0.95139 |  0:07:40s\n",
            "epoch 84 | loss: 0.27096 | train_accuracy: 0.96681 |  0:07:45s\n",
            "epoch 85 | loss: 0.26824 | train_accuracy: 0.95077 |  0:07:51s\n",
            "epoch 86 | loss: 0.2806  | train_accuracy: 0.95537 |  0:07:56s\n",
            "epoch 87 | loss: 0.26745 | train_accuracy: 0.96967 |  0:08:03s\n",
            "epoch 88 | loss: 0.26475 | train_accuracy: 0.95475 |  0:08:08s\n",
            "epoch 89 | loss: 0.26447 | train_accuracy: 0.9632  |  0:08:13s\n",
            "epoch 90 | loss: 0.26971 | train_accuracy: 0.96432 |  0:08:19s\n",
            "epoch 91 | loss: 0.26511 | train_accuracy: 0.96594 |  0:08:24s\n",
            "epoch 92 | loss: 0.26486 | train_accuracy: 0.96693 |  0:08:31s\n",
            "epoch 93 | loss: 0.26259 | train_accuracy: 0.96718 |  0:08:36s\n",
            "epoch 94 | loss: 0.26364 | train_accuracy: 0.97041 |  0:08:42s\n",
            "epoch 95 | loss: 0.26929 | train_accuracy: 0.95537 |  0:08:47s\n",
            "epoch 96 | loss: 0.2555  | train_accuracy: 0.96208 |  0:08:53s\n",
            "epoch 97 | loss: 0.25819 | train_accuracy: 0.96494 |  0:08:59s\n",
            "epoch 98 | loss: 0.26074 | train_accuracy: 0.96134 |  0:09:04s\n",
            "epoch 99 | loss: 0.25375 | train_accuracy: 0.9637  |  0:09:10s\n",
            "epoch 100| loss: 0.25635 | train_accuracy: 0.95338 |  0:09:15s\n",
            "epoch 101| loss: 0.25954 | train_accuracy: 0.9683  |  0:09:21s\n",
            "epoch 102| loss: 0.25169 | train_accuracy: 0.9632  |  0:09:26s\n",
            "epoch 103| loss: 0.2603  | train_accuracy: 0.96183 |  0:09:32s\n",
            "epoch 104| loss: 0.25065 | train_accuracy: 0.9642  |  0:09:38s\n",
            "epoch 105| loss: 0.25941 | train_accuracy: 0.96905 |  0:09:43s\n",
            "epoch 106| loss: 0.25906 | train_accuracy: 0.97029 |  0:09:49s\n",
            "epoch 107| loss: 0.25872 | train_accuracy: 0.97016 |  0:09:55s\n",
            "epoch 108| loss: 0.25263 | train_accuracy: 0.96159 |  0:10:01s\n",
            "epoch 109| loss: 0.25862 | train_accuracy: 0.96867 |  0:10:06s\n",
            "epoch 110| loss: 0.25418 | train_accuracy: 0.96345 |  0:10:12s\n",
            "epoch 111| loss: 0.25638 | train_accuracy: 0.97054 |  0:10:19s\n",
            "epoch 112| loss: 0.25293 | train_accuracy: 0.96333 |  0:10:24s\n",
            "epoch 113| loss: 0.24916 | train_accuracy: 0.97066 |  0:10:31s\n",
            "epoch 114| loss: 0.24664 | train_accuracy: 0.96109 |  0:10:37s\n",
            "epoch 115| loss: 0.24145 | train_accuracy: 0.96905 |  0:10:43s\n",
            "epoch 116| loss: 0.24401 | train_accuracy: 0.97153 |  0:10:48s\n",
            "epoch 117| loss: 0.24769 | train_accuracy: 0.97414 |  0:10:55s\n",
            "epoch 118| loss: 0.25242 | train_accuracy: 0.9719  |  0:11:01s\n",
            "epoch 119| loss: 0.24454 | train_accuracy: 0.96755 |  0:11:07s\n",
            "epoch 120| loss: 0.24048 | train_accuracy: 0.96159 |  0:11:13s\n",
            "epoch 121| loss: 0.24419 | train_accuracy: 0.96432 |  0:11:19s\n",
            "epoch 122| loss: 0.24218 | train_accuracy: 0.96469 |  0:11:25s\n",
            "epoch 123| loss: 0.24393 | train_accuracy: 0.97277 |  0:11:30s\n",
            "epoch 124| loss: 0.24401 | train_accuracy: 0.96905 |  0:11:37s\n",
            "epoch 125| loss: 0.24145 | train_accuracy: 0.97427 |  0:11:42s\n",
            "epoch 126| loss: 0.23997 | train_accuracy: 0.95848 |  0:11:49s\n",
            "epoch 127| loss: 0.24356 | train_accuracy: 0.96668 |  0:11:54s\n",
            "epoch 128| loss: 0.23936 | train_accuracy: 0.9678  |  0:12:00s\n",
            "epoch 129| loss: 0.24285 | train_accuracy: 0.97215 |  0:12:06s\n",
            "epoch 130| loss: 0.24048 | train_accuracy: 0.96059 |  0:12:11s\n",
            "epoch 131| loss: 0.24012 | train_accuracy: 0.97029 |  0:12:18s\n",
            "epoch 132| loss: 0.23419 | train_accuracy: 0.96668 |  0:12:23s\n",
            "epoch 133| loss: 0.23416 | train_accuracy: 0.96668 |  0:12:29s\n",
            "epoch 134| loss: 0.23113 | train_accuracy: 0.96867 |  0:12:35s\n",
            "epoch 135| loss: 0.23503 | train_accuracy: 0.97302 |  0:12:41s\n",
            "epoch 136| loss: 0.23159 | train_accuracy: 0.97215 |  0:12:48s\n",
            "epoch 137| loss: 0.22802 | train_accuracy: 0.9734  |  0:12:54s\n",
            "epoch 138| loss: 0.2337  | train_accuracy: 0.96793 |  0:13:00s\n",
            "epoch 139| loss: 0.23585 | train_accuracy: 0.97936 |  0:13:05s\n",
            "epoch 140| loss: 0.24059 | train_accuracy: 0.97066 |  0:13:12s\n",
            "epoch 141| loss: 0.23711 | train_accuracy: 0.97364 |  0:13:18s\n",
            "epoch 142| loss: 0.2311  | train_accuracy: 0.97476 |  0:13:24s\n",
            "epoch 143| loss: 0.23324 | train_accuracy: 0.97128 |  0:13:29s\n",
            "epoch 144| loss: 0.237   | train_accuracy: 0.97713 |  0:13:35s\n",
            "epoch 145| loss: 0.22791 | train_accuracy: 0.96507 |  0:13:41s\n",
            "epoch 146| loss: 0.22736 | train_accuracy: 0.97489 |  0:13:46s\n",
            "epoch 147| loss: 0.23208 | train_accuracy: 0.97887 |  0:13:52s\n",
            "epoch 148| loss: 0.22751 | train_accuracy: 0.97203 |  0:13:57s\n",
            "epoch 149| loss: 0.23032 | train_accuracy: 0.97675 |  0:14:04s\n",
            "epoch 150| loss: 0.229   | train_accuracy: 0.9719  |  0:14:10s\n",
            "epoch 151| loss: 0.23407 | train_accuracy: 0.97924 |  0:14:16s\n",
            "epoch 152| loss: 0.22502 | train_accuracy: 0.96929 |  0:14:22s\n",
            "epoch 153| loss: 0.23757 | train_accuracy: 0.98036 |  0:14:27s\n",
            "epoch 154| loss: 0.22573 | train_accuracy: 0.97824 |  0:14:34s\n",
            "epoch 155| loss: 0.22303 | train_accuracy: 0.9719  |  0:14:40s\n",
            "epoch 156| loss: 0.22204 | train_accuracy: 0.98048 |  0:14:46s\n",
            "epoch 157| loss: 0.21148 | train_accuracy: 0.96892 |  0:14:51s\n",
            "epoch 158| loss: 0.22634 | train_accuracy: 0.96581 |  0:14:57s\n",
            "epoch 159| loss: 0.22994 | train_accuracy: 0.9683  |  0:15:03s\n",
            "epoch 160| loss: 0.23563 | train_accuracy: 0.97004 |  0:15:08s\n",
            "epoch 161| loss: 0.22272 | train_accuracy: 0.97501 |  0:15:15s\n",
            "epoch 162| loss: 0.2344  | train_accuracy: 0.97277 |  0:15:20s\n",
            "epoch 163| loss: 0.22117 | train_accuracy: 0.97762 |  0:15:26s\n",
            "epoch 164| loss: 0.22696 | train_accuracy: 0.98284 |  0:15:32s\n",
            "epoch 165| loss: 0.22774 | train_accuracy: 0.97563 |  0:15:40s\n",
            "epoch 166| loss: 0.2274  | train_accuracy: 0.9734  |  0:15:45s\n",
            "epoch 167| loss: 0.22286 | train_accuracy: 0.98421 |  0:15:57s\n",
            "epoch 168| loss: 0.22505 | train_accuracy: 0.97688 |  0:16:02s\n",
            "epoch 169| loss: 0.22082 | train_accuracy: 0.97737 |  0:16:08s\n",
            "epoch 170| loss: 0.22267 | train_accuracy: 0.97999 |  0:16:13s\n",
            "epoch 171| loss: 0.21895 | train_accuracy: 0.97911 |  0:16:19s\n",
            "epoch 172| loss: 0.22079 | train_accuracy: 0.97762 |  0:16:25s\n",
            "epoch 173| loss: 0.2271  | train_accuracy: 0.97563 |  0:16:31s\n",
            "epoch 174| loss: 0.2222  | train_accuracy: 0.97862 |  0:16:37s\n",
            "epoch 175| loss: 0.21382 | train_accuracy: 0.98396 |  0:16:42s\n",
            "epoch 176| loss: 0.21256 | train_accuracy: 0.97675 |  0:16:49s\n",
            "epoch 177| loss: 0.21894 | train_accuracy: 0.97737 |  0:16:54s\n",
            "epoch 178| loss: 0.21431 | train_accuracy: 0.98023 |  0:17:00s\n",
            "epoch 179| loss: 0.2209  | train_accuracy: 0.97128 |  0:17:06s\n",
            "epoch 180| loss: 0.21485 | train_accuracy: 0.97327 |  0:17:11s\n",
            "epoch 181| loss: 0.21526 | train_accuracy: 0.98023 |  0:17:18s\n",
            "epoch 182| loss: 0.21432 | train_accuracy: 0.9811  |  0:17:23s\n",
            "epoch 183| loss: 0.21604 | train_accuracy: 0.97887 |  0:17:29s\n",
            "epoch 184| loss: 0.22189 | train_accuracy: 0.97924 |  0:17:35s\n",
            "epoch 185| loss: 0.21835 | train_accuracy: 0.97974 |  0:17:40s\n",
            "epoch 186| loss: 0.21389 | train_accuracy: 0.97588 |  0:17:47s\n",
            "epoch 187| loss: 0.21445 | train_accuracy: 0.97924 |  0:17:52s\n",
            "epoch 188| loss: 0.20764 | train_accuracy: 0.97414 |  0:17:58s\n",
            "epoch 189| loss: 0.21835 | train_accuracy: 0.97141 |  0:18:03s\n",
            "epoch 190| loss: 0.20708 | train_accuracy: 0.98135 |  0:18:09s\n",
            "epoch 191| loss: 0.2049  | train_accuracy: 0.98222 |  0:18:15s\n",
            "epoch 192| loss: 0.2087  | train_accuracy: 0.9821  |  0:18:21s\n",
            "epoch 193| loss: 0.21388 | train_accuracy: 0.97626 |  0:18:27s\n",
            "epoch 194| loss: 0.20703 | train_accuracy: 0.97588 |  0:18:32s\n",
            "epoch 195| loss: 0.214   | train_accuracy: 0.96818 |  0:18:39s\n",
            "epoch 196| loss: 0.20783 | train_accuracy: 0.98135 |  0:18:44s\n",
            "epoch 197| loss: 0.20579 | train_accuracy: 0.97128 |  0:18:50s\n",
            "epoch 198| loss: 0.20728 | train_accuracy: 0.98061 |  0:18:56s\n",
            "epoch 199| loss: 0.2205  | train_accuracy: 0.97812 |  0:19:02s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 0.9781203381402287\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      3987\n",
            "           1       1.00      0.96      0.98      4057\n",
            "\n",
            "    accuracy                           0.98      8044\n",
            "   macro avg       0.98      0.98      0.98      8044\n",
            "weighted avg       0.98      0.98      0.98      8044\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('balanced_dataset.csv')\n",
        "\n",
        "yes_instances = data[data['Preterm Pregnancy'] == 1]\n",
        "\n",
        "contributing_ranges = {}\n",
        "\n",
        "for feature in data.columns[:-1]:\n",
        "    yes_25th_percentile = yes_instances[feature].quantile(0.25)\n",
        "    yes_75th_percentile = yes_instances[feature].quantile(0.75)\n",
        "\n",
        "    contributing_ranges[feature] = (yes_25th_percentile, yes_75th_percentile)\n",
        "print(\"Most Contributing Ranges of Each Feature Towards Outcome 1:\")\n",
        "for feature, range_values in contributing_ranges.items():\n",
        "    print(f\"{feature}: Range {range_values[0]:.2f} - {range_values[1]:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ7VLDwzD-La",
        "outputId": "1d01e59e-f54d-43e0-83d9-3dd66a8abacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Contributing Ranges of Each Feature Towards Outcome 1:\n",
            "Age: Range 20.00 - 27.00\n",
            "No of Pregnancy: Range 2.00 - 3.00\n",
            "BMI: Range 16.95 - 23.87\n",
            "Systolic Blood Pressure(mmHg): Range 109.00 - 143.00\n",
            "Diastolic Blood Pressure(mmHg): Range 67.00 - 91.00\n",
            "Blood Sugar Fasting(mg/dL): Range 73.48 - 94.79\n",
            "Blood Sugar Post Prandial(mg/dL): Range 132.11 - 174.58\n",
            "Oral Glucose tolerance test(mg/dL): Range 118.38 - 155.68\n",
            "C-Reactive Protein(mg/L): Range 12.98 - 19.11\n",
            "Interleukin 6-IL 6(pg/mL): Range 5.56 - 9.52\n",
            "Birth weight(kg): Range 1.95 - 2.92\n"
          ]
        }
      ]
    }
  ]
}