{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC/lBiZLKrz9+N2fZBDf/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varsha-282/CIP/blob/main/cipalgocomparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIJ-zQkvmPeY",
        "outputId": "27cadc60-bd31-430b-e5bc-3c0b6b7b8f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 4s 5ms/step - loss: 0.6985 - accuracy: 0.5220\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.5723\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.6226\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6164\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.6289\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6541\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6289\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6478\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6415\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6478\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6199 - accuracy: 0.6792\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6792\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.6730\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.6918\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6855\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6792\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.6981\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7107\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7107\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5799 - accuracy: 0.7233\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.7107\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5773 - accuracy: 0.7233\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7296\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7170\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7170\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7107\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7170\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7107\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7170\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7233\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7170\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7170\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7170\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7233\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7044\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.6855\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7044\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7358\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7799\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7736\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7296\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7862\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7547\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7233\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7736\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7862\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7233\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7547\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7547\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4936 - accuracy: 0.7547\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7358\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7673\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7799\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7610\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7925\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7610\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7925\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7736\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7736\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7673\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7862\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7987\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7925\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7736\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7987\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7925\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7925\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7925\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7925\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7925\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.8113\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7925\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7862\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8239\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8113\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7799\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.8176\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.8113\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8176\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7925\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8365\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8176\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.8113\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8239\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8302\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8239\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8176\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8050\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8113\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8239\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8302\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8239\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7987\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8428\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8239\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8176\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8239\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8176\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8176\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8113\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8302\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8428\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8428\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8428\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8365\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8491\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8428\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8239\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8553\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8491\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8302\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8428\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8302\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8428\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8239\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8553\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8616\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8365\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8365\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8428\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8553\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8491\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8679\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8679\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8491\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8616\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8616\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8679\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8616\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8553\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3472 - accuracy: 0.8679\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8742\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8742\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8805\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8805\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8868\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8679\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8428\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8931\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8742\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8805\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8868\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8868\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8868\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8931\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.8868\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8868\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8868\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8868\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.8931\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8868\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8931\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8805\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8931\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8868\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3125 - accuracy: 0.8931\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.9057\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8868\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3084 - accuracy: 0.8742\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8805\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.9057\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3082 - accuracy: 0.8742\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8868\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.8868\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3028 - accuracy: 0.8994\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8994\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.9057\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8994\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.8868\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8994\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.8994\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.8931\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8868\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.8931\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3067 - accuracy: 0.8994\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.9057\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2937 - accuracy: 0.8868\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2873 - accuracy: 0.8994\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2920 - accuracy: 0.8742\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8931\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8805\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8868\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8994\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2775 - accuracy: 0.8931\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2791 - accuracy: 0.8994\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2736 - accuracy: 0.9057\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.9057\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2721 - accuracy: 0.9057\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2719 - accuracy: 0.8994\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.9057\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2706 - accuracy: 0.9057\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.9057\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2704 - accuracy: 0.8931\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2669 - accuracy: 0.9057\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.9057\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2643 - accuracy: 0.8868\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2675 - accuracy: 0.8931\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.9057\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2561 - accuracy: 0.9057\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2710 - accuracy: 0.9057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Accuracy: 0.825\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.67      0.74        15\n",
            "           1       0.82      0.92      0.87        25\n",
            "\n",
            "    accuracy                           0.82        40\n",
            "   macro avg       0.83      0.79      0.80        40\n",
            "weighted avg       0.83      0.82      0.82        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"preprocessed_data.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Convert dataframe to numpy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Reshape X for LSTM input: [samples, timesteps, features]\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"balanced_dataset.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Convert dataframe to numpy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Reshape X for LSTM input: [samples, timesteps, features]\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIliaW-Pm9fE",
        "outputId": "439abf88-67d2-4c27-aa39-5a7162c13d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "202/202 [==============================] - 4s 3ms/step - loss: 0.6568 - accuracy: 0.6264\n",
            "Epoch 2/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.6261 - accuracy: 0.6625\n",
            "Epoch 3/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.6014 - accuracy: 0.6985\n",
            "Epoch 4/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.5822 - accuracy: 0.7193\n",
            "Epoch 5/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.5611 - accuracy: 0.7333\n",
            "Epoch 6/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.5429 - accuracy: 0.7504\n",
            "Epoch 7/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.5378 - accuracy: 0.7487\n",
            "Epoch 8/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.7587\n",
            "Epoch 9/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.5196 - accuracy: 0.7557\n",
            "Epoch 10/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.5018 - accuracy: 0.7719\n",
            "Epoch 11/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.7705\n",
            "Epoch 12/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4856 - accuracy: 0.7829\n",
            "Epoch 13/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7719\n",
            "Epoch 14/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.7740\n",
            "Epoch 15/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7706\n",
            "Epoch 16/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4634 - accuracy: 0.7877\n",
            "Epoch 17/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4573 - accuracy: 0.7910\n",
            "Epoch 18/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.7852\n",
            "Epoch 19/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.7944\n",
            "Epoch 20/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4542 - accuracy: 0.7944\n",
            "Epoch 21/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.7995\n",
            "Epoch 22/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4428 - accuracy: 0.7988\n",
            "Epoch 23/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4415 - accuracy: 0.7989\n",
            "Epoch 24/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4332 - accuracy: 0.8050\n",
            "Epoch 25/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4393 - accuracy: 0.7998\n",
            "Epoch 26/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.8050\n",
            "Epoch 27/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4366 - accuracy: 0.8039\n",
            "Epoch 28/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8031\n",
            "Epoch 29/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4307 - accuracy: 0.8006\n",
            "Epoch 30/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8131\n",
            "Epoch 31/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8208\n",
            "Epoch 32/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8151\n",
            "Epoch 33/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4117 - accuracy: 0.8157\n",
            "Epoch 34/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4128 - accuracy: 0.8148\n",
            "Epoch 35/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8166\n",
            "Epoch 36/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4099 - accuracy: 0.8160\n",
            "Epoch 37/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.8236\n",
            "Epoch 38/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8230\n",
            "Epoch 39/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8264\n",
            "Epoch 40/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.8211\n",
            "Epoch 41/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3921 - accuracy: 0.8284\n",
            "Epoch 42/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3944 - accuracy: 0.8196\n",
            "Epoch 43/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3923 - accuracy: 0.8277\n",
            "Epoch 44/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3942 - accuracy: 0.8253\n",
            "Epoch 45/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3900 - accuracy: 0.8235\n",
            "Epoch 46/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3837 - accuracy: 0.8311\n",
            "Epoch 47/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8348\n",
            "Epoch 48/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8303\n",
            "Epoch 49/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3694 - accuracy: 0.8413\n",
            "Epoch 50/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8379\n",
            "Epoch 51/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3801 - accuracy: 0.8331\n",
            "Epoch 52/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8351\n",
            "Epoch 53/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8390\n",
            "Epoch 54/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8291\n",
            "Epoch 55/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8345\n",
            "Epoch 56/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.8418\n",
            "Epoch 57/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8396\n",
            "Epoch 58/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8390\n",
            "Epoch 59/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4114 - accuracy: 0.8168\n",
            "Epoch 60/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8230\n",
            "Epoch 61/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8213\n",
            "Epoch 62/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3924 - accuracy: 0.8266\n",
            "Epoch 63/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3856 - accuracy: 0.8274\n",
            "Epoch 64/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3882 - accuracy: 0.8252\n",
            "Epoch 65/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8319\n",
            "Epoch 66/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3838 - accuracy: 0.8339\n",
            "Epoch 67/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3811 - accuracy: 0.8322\n",
            "Epoch 68/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8329\n",
            "Epoch 69/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3839 - accuracy: 0.8275\n",
            "Epoch 70/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8389\n",
            "Epoch 71/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8284\n",
            "Epoch 72/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.8336\n",
            "Epoch 73/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8367\n",
            "Epoch 74/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.3730 - accuracy: 0.8362\n",
            "Epoch 75/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.3712 - accuracy: 0.8359\n",
            "Epoch 76/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3695 - accuracy: 0.8387\n",
            "Epoch 77/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.3664 - accuracy: 0.8404\n",
            "Epoch 78/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.3711 - accuracy: 0.8393\n",
            "Epoch 79/200\n",
            "202/202 [==============================] - 1s 7ms/step - loss: 0.3664 - accuracy: 0.8378\n",
            "Epoch 80/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3686 - accuracy: 0.8342\n",
            "Epoch 81/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.3713 - accuracy: 0.8409\n",
            "Epoch 82/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3659 - accuracy: 0.8420\n",
            "Epoch 83/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8448\n",
            "Epoch 84/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8407\n",
            "Epoch 85/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3681 - accuracy: 0.8402\n",
            "Epoch 86/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3576 - accuracy: 0.8499\n",
            "Epoch 87/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8387\n",
            "Epoch 88/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3652 - accuracy: 0.8373\n",
            "Epoch 89/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3645 - accuracy: 0.8410\n",
            "Epoch 90/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8390\n",
            "Epoch 91/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3590 - accuracy: 0.8423\n",
            "Epoch 92/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3643 - accuracy: 0.8415\n",
            "Epoch 93/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3591 - accuracy: 0.8440\n",
            "Epoch 94/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8476\n",
            "Epoch 95/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3638 - accuracy: 0.8378\n",
            "Epoch 96/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3627 - accuracy: 0.8415\n",
            "Epoch 97/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8395\n",
            "Epoch 98/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8426\n",
            "Epoch 99/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8471\n",
            "Epoch 100/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3583 - accuracy: 0.8474\n",
            "Epoch 101/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3569 - accuracy: 0.8430\n",
            "Epoch 102/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3579 - accuracy: 0.8404\n",
            "Epoch 103/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3530 - accuracy: 0.8488\n",
            "Epoch 104/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.8427\n",
            "Epoch 105/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3478 - accuracy: 0.8469\n",
            "Epoch 106/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3523 - accuracy: 0.8446\n",
            "Epoch 107/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3538 - accuracy: 0.8437\n",
            "Epoch 108/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3501 - accuracy: 0.8502\n",
            "Epoch 109/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3516 - accuracy: 0.8452\n",
            "Epoch 110/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3587 - accuracy: 0.8435\n",
            "Epoch 111/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3535 - accuracy: 0.8477\n",
            "Epoch 112/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.8483\n",
            "Epoch 113/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3558 - accuracy: 0.8466\n",
            "Epoch 114/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8452\n",
            "Epoch 115/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3506 - accuracy: 0.8455\n",
            "Epoch 116/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3543 - accuracy: 0.8471\n",
            "Epoch 117/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8479\n",
            "Epoch 118/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8429\n",
            "Epoch 119/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8483\n",
            "Epoch 120/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8465\n",
            "Epoch 121/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8491\n",
            "Epoch 122/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8476\n",
            "Epoch 123/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8434\n",
            "Epoch 124/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8530\n",
            "Epoch 125/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3449 - accuracy: 0.8476\n",
            "Epoch 126/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3424 - accuracy: 0.8533\n",
            "Epoch 127/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8415\n",
            "Epoch 128/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8519\n",
            "Epoch 129/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8485\n",
            "Epoch 130/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8524\n",
            "Epoch 131/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8508\n",
            "Epoch 132/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.8449\n",
            "Epoch 133/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8516\n",
            "Epoch 134/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.8444\n",
            "Epoch 135/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8480\n",
            "Epoch 136/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8525\n",
            "Epoch 137/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8488\n",
            "Epoch 138/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8535\n",
            "Epoch 139/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8545\n",
            "Epoch 140/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8553\n",
            "Epoch 141/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3489 - accuracy: 0.8440\n",
            "Epoch 142/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.8488\n",
            "Epoch 143/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8522\n",
            "Epoch 144/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3477 - accuracy: 0.8474\n",
            "Epoch 145/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3408 - accuracy: 0.8521\n",
            "Epoch 146/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8503\n",
            "Epoch 147/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8525\n",
            "Epoch 148/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3548 - accuracy: 0.8424\n",
            "Epoch 149/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8471\n",
            "Epoch 150/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8531\n",
            "Epoch 151/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8542\n",
            "Epoch 152/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3448 - accuracy: 0.8507\n",
            "Epoch 153/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8531\n",
            "Epoch 154/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8471\n",
            "Epoch 155/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8476\n",
            "Epoch 156/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.8476\n",
            "Epoch 157/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8510\n",
            "Epoch 158/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8491\n",
            "Epoch 159/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8465\n",
            "Epoch 160/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8572\n",
            "Epoch 161/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8502\n",
            "Epoch 162/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3390 - accuracy: 0.8542\n",
            "Epoch 163/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8525\n",
            "Epoch 164/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8517\n",
            "Epoch 165/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8513\n",
            "Epoch 166/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8542\n",
            "Epoch 167/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8488\n",
            "Epoch 168/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8550\n",
            "Epoch 169/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8530\n",
            "Epoch 170/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8477\n",
            "Epoch 171/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8517\n",
            "Epoch 172/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8527\n",
            "Epoch 173/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.8584\n",
            "Epoch 174/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8516\n",
            "Epoch 175/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8514\n",
            "Epoch 176/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8482\n",
            "Epoch 177/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8561\n",
            "Epoch 178/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8491\n",
            "Epoch 179/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3347 - accuracy: 0.8517\n",
            "Epoch 180/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3404 - accuracy: 0.8510\n",
            "Epoch 181/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8494\n",
            "Epoch 182/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8570\n",
            "Epoch 183/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8552\n",
            "Epoch 184/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8508\n",
            "Epoch 185/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8558\n",
            "Epoch 186/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8538\n",
            "Epoch 187/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8541\n",
            "Epoch 188/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8472\n",
            "Epoch 189/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8555\n",
            "Epoch 190/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8572\n",
            "Epoch 191/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8497\n",
            "Epoch 192/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8566\n",
            "Epoch 193/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8566\n",
            "Epoch 194/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8581\n",
            "Epoch 195/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8533\n",
            "Epoch 196/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.8586\n",
            "Epoch 197/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.8561\n",
            "Epoch 198/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8517\n",
            "Epoch 199/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8567\n",
            "Epoch 200/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8533\n",
            "51/51 [==============================] - 1s 2ms/step\n",
            "Accuracy: 0.8427594779366065\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       817\n",
            "           1       0.88      0.79      0.83       792\n",
            "\n",
            "    accuracy                           0.84      1609\n",
            "   macro avg       0.85      0.84      0.84      1609\n",
            "weighted avg       0.85      0.84      0.84      1609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"synthetic_data_rounded.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Convert dataframe to numpy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Reshape X for LSTM input: [samples, timesteps, features]\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ8RQ472n7DJ",
        "outputId": "f64cb7ba-228c-4e09-a3be-8a2e0c01a3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 3s 3ms/step - loss: 0.4949 - accuracy: 0.7837\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8123\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8123\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8127\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8138\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8188\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8232\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8230\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8292\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8328\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8320\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8353\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8370\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8375\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8395\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8422\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8418\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8455\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3546 - accuracy: 0.8460\n",
            "Epoch 20/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3519 - accuracy: 0.8453\n",
            "Epoch 21/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3521 - accuracy: 0.8460\n",
            "Epoch 22/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8520\n",
            "Epoch 23/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8500\n",
            "Epoch 24/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8493\n",
            "Epoch 25/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8510\n",
            "Epoch 26/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8555\n",
            "Epoch 27/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8525\n",
            "Epoch 28/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8545\n",
            "Epoch 29/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8537\n",
            "Epoch 30/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8608\n",
            "Epoch 31/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8575\n",
            "Epoch 32/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8618\n",
            "Epoch 33/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8655\n",
            "Epoch 34/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8593\n",
            "Epoch 35/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8570\n",
            "Epoch 36/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8583\n",
            "Epoch 37/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8650\n",
            "Epoch 38/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8665\n",
            "Epoch 39/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8627\n",
            "Epoch 40/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8683\n",
            "Epoch 41/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8637\n",
            "Epoch 42/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8673\n",
            "Epoch 43/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8655\n",
            "Epoch 44/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8652\n",
            "Epoch 45/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8670\n",
            "Epoch 46/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8727\n",
            "Epoch 47/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8700\n",
            "Epoch 48/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3060 - accuracy: 0.8758\n",
            "Epoch 49/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8712\n",
            "Epoch 50/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.8720\n",
            "Epoch 51/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3081 - accuracy: 0.8745\n",
            "Epoch 52/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3153 - accuracy: 0.8695\n",
            "Epoch 53/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8767\n",
            "Epoch 54/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8692\n",
            "Epoch 55/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.8748\n",
            "Epoch 56/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8715\n",
            "Epoch 57/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8712\n",
            "Epoch 58/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8750\n",
            "Epoch 59/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8733\n",
            "Epoch 60/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8755\n",
            "Epoch 61/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8695\n",
            "Epoch 62/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8725\n",
            "Epoch 63/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8737\n",
            "Epoch 64/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8758\n",
            "Epoch 65/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8740\n",
            "Epoch 66/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8783\n",
            "Epoch 67/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8677\n",
            "Epoch 68/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8708\n",
            "Epoch 69/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8742\n",
            "Epoch 70/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8760\n",
            "Epoch 71/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8745\n",
            "Epoch 72/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8805\n",
            "Epoch 73/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8705\n",
            "Epoch 74/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8792\n",
            "Epoch 75/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.8840\n",
            "Epoch 76/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8808\n",
            "Epoch 77/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8745\n",
            "Epoch 78/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8715\n",
            "Epoch 79/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2946 - accuracy: 0.8788\n",
            "Epoch 80/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3026 - accuracy: 0.8712\n",
            "Epoch 81/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2938 - accuracy: 0.8777\n",
            "Epoch 82/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2991 - accuracy: 0.8735\n",
            "Epoch 83/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2889 - accuracy: 0.8802\n",
            "Epoch 84/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8810\n",
            "Epoch 85/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.8790\n",
            "Epoch 86/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.8792\n",
            "Epoch 87/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8785\n",
            "Epoch 88/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8788\n",
            "Epoch 89/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8773\n",
            "Epoch 90/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8745\n",
            "Epoch 91/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8635\n",
            "Epoch 92/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8767\n",
            "Epoch 93/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2926 - accuracy: 0.8763\n",
            "Epoch 94/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8792\n",
            "Epoch 95/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8808\n",
            "Epoch 96/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8800\n",
            "Epoch 97/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8848\n",
            "Epoch 98/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8805\n",
            "Epoch 99/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8777\n",
            "Epoch 100/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8873\n",
            "Epoch 101/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8655\n",
            "Epoch 102/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8767\n",
            "Epoch 103/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8725\n",
            "Epoch 104/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8802\n",
            "Epoch 105/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8792\n",
            "Epoch 106/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8775\n",
            "Epoch 107/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.8777\n",
            "Epoch 108/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8808\n",
            "Epoch 109/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8805\n",
            "Epoch 110/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.8823\n",
            "Epoch 111/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.8830\n",
            "Epoch 112/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2848 - accuracy: 0.8758\n",
            "Epoch 113/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2860 - accuracy: 0.8758\n",
            "Epoch 114/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2778 - accuracy: 0.8823\n",
            "Epoch 115/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.8820\n",
            "Epoch 116/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8758\n",
            "Epoch 117/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8783\n",
            "Epoch 118/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.8792\n",
            "Epoch 119/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8783\n",
            "Epoch 120/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8808\n",
            "Epoch 121/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8792\n",
            "Epoch 122/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8802\n",
            "Epoch 123/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8785\n",
            "Epoch 124/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8798\n",
            "Epoch 125/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8748\n",
            "Epoch 126/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8792\n",
            "Epoch 127/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.8832\n",
            "Epoch 128/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8780\n",
            "Epoch 129/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8780\n",
            "Epoch 130/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8755\n",
            "Epoch 131/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8795\n",
            "Epoch 132/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8805\n",
            "Epoch 133/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8802\n",
            "Epoch 134/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8808\n",
            "Epoch 135/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8823\n",
            "Epoch 136/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8730\n",
            "Epoch 137/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8775\n",
            "Epoch 138/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8765\n",
            "Epoch 139/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8825\n",
            "Epoch 140/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2761 - accuracy: 0.8777\n",
            "Epoch 141/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.8817\n",
            "Epoch 142/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8815\n",
            "Epoch 143/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2787 - accuracy: 0.8808\n",
            "Epoch 144/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2752 - accuracy: 0.8835\n",
            "Epoch 145/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8780\n",
            "Epoch 146/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8763\n",
            "Epoch 147/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8792\n",
            "Epoch 148/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8783\n",
            "Epoch 149/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8700\n",
            "Epoch 150/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8852\n",
            "Epoch 151/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8838\n",
            "Epoch 152/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8817\n",
            "Epoch 153/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8798\n",
            "Epoch 154/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8810\n",
            "Epoch 155/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8802\n",
            "Epoch 156/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.8878\n",
            "Epoch 157/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8838\n",
            "Epoch 158/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8780\n",
            "Epoch 159/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8838\n",
            "Epoch 160/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8813\n",
            "Epoch 161/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8795\n",
            "Epoch 162/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8835\n",
            "Epoch 163/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8783\n",
            "Epoch 164/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8802\n",
            "Epoch 165/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8832\n",
            "Epoch 166/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8815\n",
            "Epoch 167/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8788\n",
            "Epoch 168/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8840\n",
            "Epoch 169/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8815\n",
            "Epoch 170/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2788 - accuracy: 0.8800\n",
            "Epoch 171/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2750 - accuracy: 0.8815\n",
            "Epoch 172/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2763 - accuracy: 0.8808\n",
            "Epoch 173/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2733 - accuracy: 0.8802\n",
            "Epoch 174/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2733 - accuracy: 0.8848\n",
            "Epoch 175/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8838\n",
            "Epoch 176/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8810\n",
            "Epoch 177/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8830\n",
            "Epoch 178/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8820\n",
            "Epoch 179/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8792\n",
            "Epoch 180/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8842\n",
            "Epoch 181/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8825\n",
            "Epoch 182/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8820\n",
            "Epoch 183/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2730 - accuracy: 0.8790\n",
            "Epoch 184/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2733 - accuracy: 0.8840\n",
            "Epoch 185/200\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2666 - accuracy: 0.8815\n",
            "Epoch 186/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2753 - accuracy: 0.8795\n",
            "Epoch 187/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2724 - accuracy: 0.8825\n",
            "Epoch 188/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8860\n",
            "Epoch 189/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8830\n",
            "Epoch 190/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8805\n",
            "Epoch 191/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8840\n",
            "Epoch 192/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8855\n",
            "Epoch 193/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8827\n",
            "Epoch 194/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2722 - accuracy: 0.8790\n",
            "Epoch 195/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2719 - accuracy: 0.8838\n",
            "Epoch 196/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2685 - accuracy: 0.8840\n",
            "Epoch 197/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2721 - accuracy: 0.8780\n",
            "Epoch 198/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2748 - accuracy: 0.8835\n",
            "Epoch 199/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8845\n",
            "Epoch 200/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8798\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.884\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.53      0.64       192\n",
            "           1       0.90      0.97      0.93       808\n",
            "\n",
            "    accuracy                           0.88      1000\n",
            "   macro avg       0.85      0.75      0.78      1000\n",
            "weighted avg       0.88      0.88      0.87      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"preprocessed_data.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the XGBoost model\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1c4ZdkBotTS",
        "outputId": "8f3f1f49-1c03-443b-c6b5-70353ae4710a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.975\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        15\n",
            "           1       1.00      0.96      0.98        25\n",
            "\n",
            "    accuracy                           0.97        40\n",
            "   macro avg       0.97      0.98      0.97        40\n",
            "weighted avg       0.98      0.97      0.98        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"synthetic_data_rounded.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the XGBoost model\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I24s5-Wno8ET",
        "outputId": "e85a324d-1f49-497a-95f0-3ca868dab73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.48      0.57       192\n",
            "           1       0.88      0.95      0.92       808\n",
            "\n",
            "    accuracy                           0.86      1000\n",
            "   macro avg       0.79      0.71      0.74      1000\n",
            "weighted avg       0.85      0.86      0.85      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"balanced_dataset.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the XGBoost model\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77Lf7OggpCag",
        "outputId": "2e433814-df74-4a07-a883-3c6fb1ef9753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.925419515226849\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93       817\n",
            "           1       0.92      0.93      0.93       792\n",
            "\n",
            "    accuracy                           0.93      1609\n",
            "   macro avg       0.93      0.93      0.93      1609\n",
            "weighted avg       0.93      0.93      0.93      1609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"preprocessed_data.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1mSFpCHpeOf",
        "outputId": "b0058ff9-bb34-4030-9db6-e225d1b4d0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 5s 9ms/step - loss: 2.8285 - accuracy: 0.6226\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4629 - accuracy: 0.6038\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2811 - accuracy: 0.7170\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1523 - accuracy: 0.6038\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.9596 - accuracy: 0.7421\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7904 - accuracy: 0.7484\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8334 - accuracy: 0.6918\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7303 - accuracy: 0.7610\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.6918\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.7610\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6699 - accuracy: 0.6855\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7113 - accuracy: 0.6855\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.7170\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6539 - accuracy: 0.7170\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.7421\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6336 - accuracy: 0.7044\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6200 - accuracy: 0.7421\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6003 - accuracy: 0.7610\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5707 - accuracy: 0.7484\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5782 - accuracy: 0.7925\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5865 - accuracy: 0.7296\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5592 - accuracy: 0.7547\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5594 - accuracy: 0.7673\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5418 - accuracy: 0.7484\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5416 - accuracy: 0.7421\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5358 - accuracy: 0.7799\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5377 - accuracy: 0.7610\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7296\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7862\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7484\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7736\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7673\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7799\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7610\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7296\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6981\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.8113\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7421\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7799\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7987\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7862\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7987\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7862\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8113\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8176\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7610\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7925\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7799\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7673\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7799\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8050\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8113\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7673\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7862\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8113\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7673\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8113\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8365\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8365\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8239\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7925\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7799\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8050\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7170\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.6541\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7170\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7358\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7421\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7673\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8176\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.7987\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8428\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8365\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7925\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7925\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7987\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7799\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8113\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8113\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8491\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8239\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8239\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7296\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7547\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8742\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8113\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7925\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8616\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7987\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8365\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8302\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8616\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8113\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8365\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8365\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.7987\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.7925\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8491\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8365\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7233\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7736\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8239\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8302\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8239\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.7987\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.7925\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8365\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8176\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8491\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8553\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8553\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8239\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8553\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7925\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8428\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8428\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8176\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8553\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8302\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8365\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8365\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8239\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8679\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8428\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8616\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8742\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8616\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8742\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8239\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8428\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8365\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8616\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8679\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8805\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8491\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8616\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8679\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.7925\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8302\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8491\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8868\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8679\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8616\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8742\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8679\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.8553\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8616\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8553\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8113\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8365\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8239\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8616\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8679\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8239\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8428\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8176\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.7925\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8050\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.7987\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.8742\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8805\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8679\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8742\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8679\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8616\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8616\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8679\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8365\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8868\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.8742\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8868\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8931\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8679\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8679\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8616\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8805\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8553\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8742\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.7987\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.7799\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.7925\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7421\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.7862\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8679\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8742\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8679\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8553\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8491\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8050\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8365\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8868\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8742\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8805\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8365\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8742\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8553\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8616\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8553\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8176\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8302\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Accuracy: 0.725\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.73      0.67        15\n",
            "           1       0.82      0.72      0.77        25\n",
            "\n",
            "    accuracy                           0.73        40\n",
            "   macro avg       0.71      0.73      0.72        40\n",
            "weighted avg       0.74      0.72      0.73        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"synthetic_data_rounded.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxsBDy82ptrF",
        "outputId": "a1e15944-29d7-4863-f05f-cc0522da9f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.7993\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8040\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8155\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8127\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8148\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8180\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8250\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8267\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8280\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8250\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8350\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8322\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8435\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8328\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8438\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8445\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8487\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8482\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8490\n",
            "Epoch 20/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8450\n",
            "Epoch 21/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8460\n",
            "Epoch 22/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8418\n",
            "Epoch 23/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8565\n",
            "Epoch 24/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8533\n",
            "Epoch 25/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8583\n",
            "Epoch 26/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8568\n",
            "Epoch 27/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8558\n",
            "Epoch 28/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8643\n",
            "Epoch 29/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8665\n",
            "Epoch 30/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8495\n",
            "Epoch 31/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8610\n",
            "Epoch 32/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8597\n",
            "Epoch 33/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8540\n",
            "Epoch 34/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8610\n",
            "Epoch 35/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8685\n",
            "Epoch 36/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8670\n",
            "Epoch 37/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8670\n",
            "Epoch 38/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8705\n",
            "Epoch 39/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8692\n",
            "Epoch 40/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8650\n",
            "Epoch 41/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8625\n",
            "Epoch 42/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8652\n",
            "Epoch 43/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8733\n",
            "Epoch 44/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8698\n",
            "Epoch 45/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8735\n",
            "Epoch 46/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8698\n",
            "Epoch 47/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8735\n",
            "Epoch 48/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8695\n",
            "Epoch 49/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8740\n",
            "Epoch 50/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8710\n",
            "Epoch 51/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8658\n",
            "Epoch 52/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8750\n",
            "Epoch 53/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8775\n",
            "Epoch 54/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8725\n",
            "Epoch 55/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8702\n",
            "Epoch 56/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8827\n",
            "Epoch 57/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8710\n",
            "Epoch 58/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8835\n",
            "Epoch 59/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8798\n",
            "Epoch 60/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8733\n",
            "Epoch 61/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8735\n",
            "Epoch 62/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8760\n",
            "Epoch 63/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8775\n",
            "Epoch 64/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8863\n",
            "Epoch 65/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.8780\n",
            "Epoch 66/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8737\n",
            "Epoch 67/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8795\n",
            "Epoch 68/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8765\n",
            "Epoch 69/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8775\n",
            "Epoch 70/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8863\n",
            "Epoch 71/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8832\n",
            "Epoch 72/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.8845\n",
            "Epoch 73/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8800\n",
            "Epoch 74/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8815\n",
            "Epoch 75/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8760\n",
            "Epoch 76/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8870\n",
            "Epoch 77/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8825\n",
            "Epoch 78/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.8848\n",
            "Epoch 79/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8770\n",
            "Epoch 80/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8815\n",
            "Epoch 81/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8810\n",
            "Epoch 82/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8763\n",
            "Epoch 83/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8805\n",
            "Epoch 84/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8850\n",
            "Epoch 85/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8867\n",
            "Epoch 86/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8790\n",
            "Epoch 87/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.8888\n",
            "Epoch 88/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8850\n",
            "Epoch 89/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8823\n",
            "Epoch 90/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8800\n",
            "Epoch 91/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8907\n",
            "Epoch 92/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8910\n",
            "Epoch 93/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8888\n",
            "Epoch 94/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8848\n",
            "Epoch 95/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8860\n",
            "Epoch 96/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8863\n",
            "Epoch 97/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8945\n",
            "Epoch 98/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8740\n",
            "Epoch 99/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8890\n",
            "Epoch 100/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8860\n",
            "Epoch 101/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8845\n",
            "Epoch 102/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.8865\n",
            "Epoch 103/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8777\n",
            "Epoch 104/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8798\n",
            "Epoch 105/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8875\n",
            "Epoch 106/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.8910\n",
            "Epoch 107/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8823\n",
            "Epoch 108/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8830\n",
            "Epoch 109/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8870\n",
            "Epoch 110/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8913\n",
            "Epoch 111/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8928\n",
            "Epoch 112/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8882\n",
            "Epoch 113/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8815\n",
            "Epoch 114/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8917\n",
            "Epoch 115/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8867\n",
            "Epoch 116/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8892\n",
            "Epoch 117/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8957\n",
            "Epoch 118/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8913\n",
            "Epoch 119/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.8910\n",
            "Epoch 120/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8852\n",
            "Epoch 121/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8880\n",
            "Epoch 122/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.8920\n",
            "Epoch 123/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.8888\n",
            "Epoch 124/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.8920\n",
            "Epoch 125/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.8945\n",
            "Epoch 126/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8840\n",
            "Epoch 127/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8947\n",
            "Epoch 128/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8885\n",
            "Epoch 129/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8892\n",
            "Epoch 130/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8947\n",
            "Epoch 131/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8903\n",
            "Epoch 132/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8875\n",
            "Epoch 133/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8935\n",
            "Epoch 134/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8960\n",
            "Epoch 135/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8953\n",
            "Epoch 136/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8870\n",
            "Epoch 137/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8960\n",
            "Epoch 138/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8915\n",
            "Epoch 139/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8965\n",
            "Epoch 140/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8915\n",
            "Epoch 141/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8932\n",
            "Epoch 142/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.8898\n",
            "Epoch 143/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.8950\n",
            "Epoch 144/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8957\n",
            "Epoch 145/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8960\n",
            "Epoch 146/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8930\n",
            "Epoch 147/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8925\n",
            "Epoch 148/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.8935\n",
            "Epoch 149/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8935\n",
            "Epoch 150/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8972\n",
            "Epoch 151/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.8972\n",
            "Epoch 152/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.8928\n",
            "Epoch 153/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8972\n",
            "Epoch 154/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8907\n",
            "Epoch 155/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8955\n",
            "Epoch 156/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8928\n",
            "Epoch 157/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8975\n",
            "Epoch 158/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8990\n",
            "Epoch 159/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8972\n",
            "Epoch 160/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8965\n",
            "Epoch 161/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8932\n",
            "Epoch 162/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9022\n",
            "Epoch 163/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9000\n",
            "Epoch 164/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8900\n",
            "Epoch 165/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.8997\n",
            "Epoch 166/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.8988\n",
            "Epoch 167/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.8898\n",
            "Epoch 168/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.8982\n",
            "Epoch 169/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8935\n",
            "Epoch 170/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.8935\n",
            "Epoch 171/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.8935\n",
            "Epoch 172/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2428 - accuracy: 0.8925\n",
            "Epoch 173/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9003\n",
            "Epoch 174/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.8980\n",
            "Epoch 175/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.8978\n",
            "Epoch 176/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9022\n",
            "Epoch 177/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.8995\n",
            "Epoch 178/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8915\n",
            "Epoch 179/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8945\n",
            "Epoch 180/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.8995\n",
            "Epoch 181/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.8990\n",
            "Epoch 182/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.8930\n",
            "Epoch 183/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9020\n",
            "Epoch 184/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.8997\n",
            "Epoch 185/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.8992\n",
            "Epoch 186/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.8967\n",
            "Epoch 187/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8965\n",
            "Epoch 188/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8982\n",
            "Epoch 189/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.8985\n",
            "Epoch 190/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8947\n",
            "Epoch 191/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9003\n",
            "Epoch 192/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9010\n",
            "Epoch 193/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9003\n",
            "Epoch 194/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.8978\n",
            "Epoch 195/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8910\n",
            "Epoch 196/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.8997\n",
            "Epoch 197/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9005\n",
            "Epoch 198/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.8980\n",
            "Epoch 199/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9045\n",
            "Epoch 200/200\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9010\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.881\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.71      0.70       192\n",
            "           1       0.93      0.92      0.93       808\n",
            "\n",
            "    accuracy                           0.88      1000\n",
            "   macro avg       0.81      0.82      0.81      1000\n",
            "weighted avg       0.88      0.88      0.88      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"balanced_dataset.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKKFSSnUqPhm",
        "outputId": "9704cc79-3ef0-4765-92fa-16bb7499c1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "202/202 [==============================] - 2s 4ms/step - loss: 2.1317 - accuracy: 0.6005\n",
            "Epoch 2/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7396 - accuracy: 0.6308\n",
            "Epoch 3/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.6347\n",
            "Epoch 4/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6743\n",
            "Epoch 5/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6993\n",
            "Epoch 6/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6824\n",
            "Epoch 7/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7046\n",
            "Epoch 8/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6909\n",
            "Epoch 9/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7245\n",
            "Epoch 10/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7153\n",
            "Epoch 11/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7248\n",
            "Epoch 12/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7509\n",
            "Epoch 13/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7534\n",
            "Epoch 14/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7611\n",
            "Epoch 15/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7577\n",
            "Epoch 16/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.7779\n",
            "Epoch 17/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4725 - accuracy: 0.7723\n",
            "Epoch 18/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4709 - accuracy: 0.7719\n",
            "Epoch 19/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4690 - accuracy: 0.7779\n",
            "Epoch 20/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.7790\n",
            "Epoch 21/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7695\n",
            "Epoch 22/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7806\n",
            "Epoch 23/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7947\n",
            "Epoch 24/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7862\n",
            "Epoch 25/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7838\n",
            "Epoch 26/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8099\n",
            "Epoch 27/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7955\n",
            "Epoch 28/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7776\n",
            "Epoch 29/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8042\n",
            "Epoch 30/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8026\n",
            "Epoch 31/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8026\n",
            "Epoch 32/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8123\n",
            "Epoch 33/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8149\n",
            "Epoch 34/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8123\n",
            "Epoch 35/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8067\n",
            "Epoch 36/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7963\n",
            "Epoch 37/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8141\n",
            "Epoch 38/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8075\n",
            "Epoch 39/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8186\n",
            "Epoch 40/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8084\n",
            "Epoch 41/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8168\n",
            "Epoch 42/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8162\n",
            "Epoch 43/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3852 - accuracy: 0.8275\n",
            "Epoch 44/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4064 - accuracy: 0.8190\n",
            "Epoch 45/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8244\n",
            "Epoch 46/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4007 - accuracy: 0.8196\n",
            "Epoch 47/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8401\n",
            "Epoch 48/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8339\n",
            "Epoch 49/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8210\n",
            "Epoch 50/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8334\n",
            "Epoch 51/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8308\n",
            "Epoch 52/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8323\n",
            "Epoch 53/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8266\n",
            "Epoch 54/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8289\n",
            "Epoch 55/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8202\n",
            "Epoch 56/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8294\n",
            "Epoch 57/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8389\n",
            "Epoch 58/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8458\n",
            "Epoch 59/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8361\n",
            "Epoch 60/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8444\n",
            "Epoch 61/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8426\n",
            "Epoch 62/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8472\n",
            "Epoch 63/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8510\n",
            "Epoch 64/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8331\n",
            "Epoch 65/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8368\n",
            "Epoch 66/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8347\n",
            "Epoch 67/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8308\n",
            "Epoch 68/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8482\n",
            "Epoch 69/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8329\n",
            "Epoch 70/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3554 - accuracy: 0.8463\n",
            "Epoch 71/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8499\n",
            "Epoch 72/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8412\n",
            "Epoch 73/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8446\n",
            "Epoch 74/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8404\n",
            "Epoch 75/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8496\n",
            "Epoch 76/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8524\n",
            "Epoch 77/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8514\n",
            "Epoch 78/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8513\n",
            "Epoch 79/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8539\n",
            "Epoch 80/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8528\n",
            "Epoch 81/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8490\n",
            "Epoch 82/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8550\n",
            "Epoch 83/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8580\n",
            "Epoch 84/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8485\n",
            "Epoch 85/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8463\n",
            "Epoch 86/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8466\n",
            "Epoch 87/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8457\n",
            "Epoch 88/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8539\n",
            "Epoch 89/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8606\n",
            "Epoch 90/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8458\n",
            "Epoch 91/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8594\n",
            "Epoch 92/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8458\n",
            "Epoch 93/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8545\n",
            "Epoch 94/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8510\n",
            "Epoch 95/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8559\n",
            "Epoch 96/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8598\n",
            "Epoch 97/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8572\n",
            "Epoch 98/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8561\n",
            "Epoch 99/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8569\n",
            "Epoch 100/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8586\n",
            "Epoch 101/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8550\n",
            "Epoch 102/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8511\n",
            "Epoch 103/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8612\n",
            "Epoch 104/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8609\n",
            "Epoch 105/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8625\n",
            "Epoch 106/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8555\n",
            "Epoch 107/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8618\n",
            "Epoch 108/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8653\n",
            "Epoch 109/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8628\n",
            "Epoch 110/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8670\n",
            "Epoch 111/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8654\n",
            "Epoch 112/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8553\n",
            "Epoch 113/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8688\n",
            "Epoch 114/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8659\n",
            "Epoch 115/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8693\n",
            "Epoch 116/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8684\n",
            "Epoch 117/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8710\n",
            "Epoch 118/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8618\n",
            "Epoch 119/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8577\n",
            "Epoch 120/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8704\n",
            "Epoch 121/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8684\n",
            "Epoch 122/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8701\n",
            "Epoch 123/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8688\n",
            "Epoch 124/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8605\n",
            "Epoch 125/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8603\n",
            "Epoch 126/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.8651\n",
            "Epoch 127/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.8701\n",
            "Epoch 128/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3053 - accuracy: 0.8678\n",
            "Epoch 129/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.8701\n",
            "Epoch 130/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8690\n",
            "Epoch 131/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8716\n",
            "Epoch 132/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8614\n",
            "Epoch 133/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8656\n",
            "Epoch 134/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8667\n",
            "Epoch 135/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8713\n",
            "Epoch 136/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8626\n",
            "Epoch 137/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8664\n",
            "Epoch 138/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8639\n",
            "Epoch 139/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8730\n",
            "Epoch 140/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8698\n",
            "Epoch 141/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
            "Epoch 142/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8707\n",
            "Epoch 143/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8737\n",
            "Epoch 144/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8740\n",
            "Epoch 145/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8761\n",
            "Epoch 146/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8723\n",
            "Epoch 147/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8690\n",
            "Epoch 148/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8690\n",
            "Epoch 149/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8810\n",
            "Epoch 150/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8639\n",
            "Epoch 151/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8713\n",
            "Epoch 152/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.2956 - accuracy: 0.8772\n",
            "Epoch 153/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.8668\n",
            "Epoch 154/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3110 - accuracy: 0.8640\n",
            "Epoch 155/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.2914 - accuracy: 0.8788\n",
            "Epoch 156/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8754\n",
            "Epoch 157/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8761\n",
            "Epoch 158/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8721\n",
            "Epoch 159/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8771\n",
            "Epoch 160/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8741\n",
            "Epoch 161/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8803\n",
            "Epoch 162/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8783\n",
            "Epoch 163/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8766\n",
            "Epoch 164/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8747\n",
            "Epoch 165/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8830\n",
            "Epoch 166/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8775\n",
            "Epoch 167/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.8794\n",
            "Epoch 168/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8789\n",
            "Epoch 169/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8772\n",
            "Epoch 170/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8752\n",
            "Epoch 171/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8782\n",
            "Epoch 172/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8800\n",
            "Epoch 173/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8687\n",
            "Epoch 174/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8765\n",
            "Epoch 175/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8695\n",
            "Epoch 176/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8709\n",
            "Epoch 177/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8791\n",
            "Epoch 178/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.8783\n",
            "Epoch 179/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8853\n",
            "Epoch 180/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.8805\n",
            "Epoch 181/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.2828 - accuracy: 0.8775\n",
            "Epoch 182/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8848\n",
            "Epoch 183/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.8794\n",
            "Epoch 184/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8733\n",
            "Epoch 185/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8796\n",
            "Epoch 186/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8850\n",
            "Epoch 187/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8850\n",
            "Epoch 188/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8830\n",
            "Epoch 189/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8831\n",
            "Epoch 190/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8803\n",
            "Epoch 191/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8738\n",
            "Epoch 192/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8816\n",
            "Epoch 193/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8805\n",
            "Epoch 194/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8760\n",
            "Epoch 195/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8839\n",
            "Epoch 196/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8830\n",
            "Epoch 197/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8816\n",
            "Epoch 198/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8911\n",
            "Epoch 199/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8866\n",
            "Epoch 200/200\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8811\n",
            "51/51 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.8290863890615289\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81       817\n",
            "           1       0.76      0.94      0.84       792\n",
            "\n",
            "    accuracy                           0.83      1609\n",
            "   macro avg       0.85      0.83      0.83      1609\n",
            "weighted avg       0.85      0.83      0.83      1609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"preprocessed_data.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for GRU input: [samples, timesteps, features]\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential()\n",
        "model.add(GRU(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpEaOhB5q1mQ",
        "outputId": "8f6a94ff-ecb5-400c-9098-208ab1da8df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 4s 8ms/step - loss: 0.7628 - accuracy: 0.4654\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6655 - accuracy: 0.6164\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6734 - accuracy: 0.6164\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6686 - accuracy: 0.6164\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6592 - accuracy: 0.6164\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6605 - accuracy: 0.6164\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.6164\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6511 - accuracy: 0.6164\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.6164\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6445 - accuracy: 0.6164\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6402 - accuracy: 0.6164\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.6289\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.6415\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6290 - accuracy: 0.6415\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6260 - accuracy: 0.6478\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.6855\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.7547\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.6478\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6053 - accuracy: 0.7358\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6004 - accuracy: 0.7296\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5937 - accuracy: 0.7233\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5859 - accuracy: 0.7421\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.7547\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5677 - accuracy: 0.7170\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5597 - accuracy: 0.6918\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5585 - accuracy: 0.7107\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5384 - accuracy: 0.7547\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5258 - accuracy: 0.7358\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5093 - accuracy: 0.7484\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.7610\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.7736\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.7610\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.7862\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8239\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3789 - accuracy: 0.7799\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3663 - accuracy: 0.8113\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3599 - accuracy: 0.8491\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3650 - accuracy: 0.8176\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3669 - accuracy: 0.8176\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8302\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3273 - accuracy: 0.8553\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2987 - accuracy: 0.8491\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2873 - accuracy: 0.8742\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8679\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2851 - accuracy: 0.8805\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2810 - accuracy: 0.8679\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2807 - accuracy: 0.8868\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2761 - accuracy: 0.8742\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2852 - accuracy: 0.8805\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2994 - accuracy: 0.8491\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3610 - accuracy: 0.8239\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.7736\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3389 - accuracy: 0.8302\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8176\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2702 - accuracy: 0.8742\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2640 - accuracy: 0.8805\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2784 - accuracy: 0.8994\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2773 - accuracy: 0.8742\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2723 - accuracy: 0.8491\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2534 - accuracy: 0.8805\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2591 - accuracy: 0.8868\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2605 - accuracy: 0.8868\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2479 - accuracy: 0.8931\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2485 - accuracy: 0.8805\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2555 - accuracy: 0.8931\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2417 - accuracy: 0.8931\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2436 - accuracy: 0.8931\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2452 - accuracy: 0.8931\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2643 - accuracy: 0.8553\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2558 - accuracy: 0.8616\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2436 - accuracy: 0.9057\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2783 - accuracy: 0.8616\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2893 - accuracy: 0.8616\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2714 - accuracy: 0.8742\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2963 - accuracy: 0.8616\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2724 - accuracy: 0.8805\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2526 - accuracy: 0.8931\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2424 - accuracy: 0.8994\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.8868\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2316 - accuracy: 0.9119\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2415 - accuracy: 0.9119\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2301 - accuracy: 0.8931\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2413 - accuracy: 0.8994\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2257 - accuracy: 0.8994\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2411 - accuracy: 0.8868\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2481 - accuracy: 0.8868\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2395 - accuracy: 0.8931\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2409 - accuracy: 0.9057\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2248 - accuracy: 0.8931\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2274 - accuracy: 0.8931\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2280 - accuracy: 0.8994\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2303 - accuracy: 0.8931\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2289 - accuracy: 0.8931\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2201 - accuracy: 0.8931\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2254 - accuracy: 0.8931\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2305 - accuracy: 0.9057\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2181 - accuracy: 0.8931\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2175 - accuracy: 0.8931\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2141 - accuracy: 0.8931\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2177 - accuracy: 0.8931\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2291 - accuracy: 0.8931\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2152 - accuracy: 0.8994\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9057\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2341 - accuracy: 0.8868\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2581 - accuracy: 0.8491\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2238 - accuracy: 0.8805\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2181 - accuracy: 0.8994\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2168 - accuracy: 0.8994\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2109 - accuracy: 0.8931\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2033 - accuracy: 0.8931\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2132 - accuracy: 0.9245\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2103 - accuracy: 0.8931\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2061 - accuracy: 0.9182\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2029 - accuracy: 0.8931\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2134 - accuracy: 0.9119\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2361 - accuracy: 0.8994\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2413 - accuracy: 0.8365\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2628 - accuracy: 0.8742\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2762 - accuracy: 0.8491\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2639 - accuracy: 0.8742\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2665 - accuracy: 0.8491\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2408 - accuracy: 0.9119\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2078 - accuracy: 0.9057\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2299 - accuracy: 0.8994\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2051 - accuracy: 0.8931\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2163 - accuracy: 0.9245\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2003 - accuracy: 0.8994\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2150 - accuracy: 0.9119\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2225 - accuracy: 0.8931\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2025 - accuracy: 0.9245\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2479 - accuracy: 0.8931\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2257 - accuracy: 0.8868\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2072 - accuracy: 0.8994\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1924 - accuracy: 0.9119\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2019 - accuracy: 0.9308\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1968 - accuracy: 0.8994\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1960 - accuracy: 0.9182\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1933 - accuracy: 0.8931\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2053 - accuracy: 0.8931\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9182\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2043 - accuracy: 0.8931\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2011 - accuracy: 0.9057\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1829 - accuracy: 0.9245\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1899 - accuracy: 0.9057\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1856 - accuracy: 0.9182\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1829 - accuracy: 0.9182\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2126 - accuracy: 0.9057\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2073 - accuracy: 0.9182\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2175 - accuracy: 0.8931\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1873 - accuracy: 0.9371\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2177 - accuracy: 0.9245\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1897 - accuracy: 0.9119\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1847 - accuracy: 0.9119\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1823 - accuracy: 0.9245\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1861 - accuracy: 0.9057\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1762 - accuracy: 0.9371\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1784 - accuracy: 0.9434\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1849 - accuracy: 0.9182\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1676 - accuracy: 0.9245\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1798 - accuracy: 0.9371\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1737 - accuracy: 0.9308\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.8805\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2425 - accuracy: 0.8868\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2567 - accuracy: 0.8428\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2268 - accuracy: 0.8931\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2124 - accuracy: 0.9245\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1940 - accuracy: 0.9182\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1920 - accuracy: 0.9245\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1622 - accuracy: 0.9371\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1805 - accuracy: 0.9245\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9434\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1636 - accuracy: 0.9434\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1675 - accuracy: 0.9434\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1647 - accuracy: 0.9371\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1800 - accuracy: 0.9245\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1709 - accuracy: 0.9245\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1811 - accuracy: 0.9182\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1622 - accuracy: 0.9434\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1602 - accuracy: 0.9497\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1493 - accuracy: 0.9497\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1557 - accuracy: 0.9497\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1504 - accuracy: 0.9560\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1519 - accuracy: 0.9497\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1524 - accuracy: 0.9497\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1498 - accuracy: 0.9560\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1610 - accuracy: 0.9434\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1685 - accuracy: 0.9560\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1759 - accuracy: 0.9434\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1717 - accuracy: 0.9245\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1564 - accuracy: 0.9497\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1622 - accuracy: 0.9434\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1601 - accuracy: 0.9497\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.9623\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1438 - accuracy: 0.9560\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1508 - accuracy: 0.9434\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1407 - accuracy: 0.9497\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1453 - accuracy: 0.9497\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1709 - accuracy: 0.9308\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1659 - accuracy: 0.9182\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1671 - accuracy: 0.9245\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "Accuracy: 0.775\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.77        15\n",
            "           1       1.00      0.64      0.78        25\n",
            "\n",
            "    accuracy                           0.78        40\n",
            "   macro avg       0.81      0.82      0.77        40\n",
            "weighted avg       0.86      0.78      0.78        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"synthetic_data_rounded.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for GRU input: [samples, timesteps, features]\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential()\n",
        "model.add(GRU(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u1TfeyurGg9",
        "outputId": "3882a7ec-7e24-4047-e168-99fdde775da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 3s 6ms/step - loss: 0.4853 - accuracy: 0.8067\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4611 - accuracy: 0.8123\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.8230\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4159 - accuracy: 0.8267\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3959 - accuracy: 0.8315\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3863 - accuracy: 0.8363\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3745 - accuracy: 0.8440\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3684 - accuracy: 0.8410\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3647 - accuracy: 0.8393\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3674 - accuracy: 0.8407\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3610 - accuracy: 0.8455\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3545 - accuracy: 0.8480\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3594 - accuracy: 0.8428\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3533 - accuracy: 0.8470\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3566 - accuracy: 0.8435\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3499 - accuracy: 0.8485\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3472 - accuracy: 0.8478\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3429 - accuracy: 0.8478\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3447 - accuracy: 0.8468\n",
            "Epoch 20/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3406 - accuracy: 0.8505\n",
            "Epoch 21/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3429 - accuracy: 0.8495\n",
            "Epoch 22/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3418 - accuracy: 0.8493\n",
            "Epoch 23/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3440 - accuracy: 0.8493\n",
            "Epoch 24/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3377 - accuracy: 0.8495\n",
            "Epoch 25/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3375 - accuracy: 0.8518\n",
            "Epoch 26/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3348 - accuracy: 0.8525\n",
            "Epoch 27/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3360 - accuracy: 0.8535\n",
            "Epoch 28/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3309 - accuracy: 0.8533\n",
            "Epoch 29/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3343 - accuracy: 0.8537\n",
            "Epoch 30/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3323 - accuracy: 0.8530\n",
            "Epoch 31/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3299 - accuracy: 0.8545\n",
            "Epoch 32/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3322 - accuracy: 0.8558\n",
            "Epoch 33/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3288 - accuracy: 0.8503\n",
            "Epoch 34/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3232 - accuracy: 0.8577\n",
            "Epoch 35/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3356 - accuracy: 0.8493\n",
            "Epoch 36/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3230 - accuracy: 0.8583\n",
            "Epoch 37/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3264 - accuracy: 0.8572\n",
            "Epoch 38/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3263 - accuracy: 0.8553\n",
            "Epoch 39/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3209 - accuracy: 0.8580\n",
            "Epoch 40/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3230 - accuracy: 0.8570\n",
            "Epoch 41/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3219 - accuracy: 0.8580\n",
            "Epoch 42/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3248 - accuracy: 0.8558\n",
            "Epoch 43/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3150 - accuracy: 0.8570\n",
            "Epoch 44/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3171 - accuracy: 0.8577\n",
            "Epoch 45/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3154 - accuracy: 0.8612\n",
            "Epoch 46/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3165 - accuracy: 0.8533\n",
            "Epoch 47/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3132 - accuracy: 0.8590\n",
            "Epoch 48/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3174 - accuracy: 0.8565\n",
            "Epoch 49/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3110 - accuracy: 0.8610\n",
            "Epoch 50/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3183 - accuracy: 0.8590\n",
            "Epoch 51/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3141 - accuracy: 0.8585\n",
            "Epoch 52/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3147 - accuracy: 0.8558\n",
            "Epoch 53/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3094 - accuracy: 0.8597\n",
            "Epoch 54/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3098 - accuracy: 0.8600\n",
            "Epoch 55/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3120 - accuracy: 0.8568\n",
            "Epoch 56/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3135 - accuracy: 0.8593\n",
            "Epoch 57/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3100 - accuracy: 0.8650\n",
            "Epoch 58/200\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3107 - accuracy: 0.8608\n",
            "Epoch 59/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3066 - accuracy: 0.8637\n",
            "Epoch 60/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3111 - accuracy: 0.8600\n",
            "Epoch 61/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3020 - accuracy: 0.8635\n",
            "Epoch 62/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3032 - accuracy: 0.8643\n",
            "Epoch 63/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3082 - accuracy: 0.8650\n",
            "Epoch 64/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3053 - accuracy: 0.8637\n",
            "Epoch 65/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3027 - accuracy: 0.8645\n",
            "Epoch 66/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3035 - accuracy: 0.8602\n",
            "Epoch 67/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3060 - accuracy: 0.8650\n",
            "Epoch 68/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3040 - accuracy: 0.8635\n",
            "Epoch 69/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3000 - accuracy: 0.8662\n",
            "Epoch 70/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2971 - accuracy: 0.8668\n",
            "Epoch 71/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2962 - accuracy: 0.8643\n",
            "Epoch 72/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3071 - accuracy: 0.8593\n",
            "Epoch 73/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3002 - accuracy: 0.8655\n",
            "Epoch 74/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2984 - accuracy: 0.8670\n",
            "Epoch 75/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2963 - accuracy: 0.8643\n",
            "Epoch 76/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2947 - accuracy: 0.8637\n",
            "Epoch 77/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2989 - accuracy: 0.8648\n",
            "Epoch 78/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2957 - accuracy: 0.8630\n",
            "Epoch 79/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2946 - accuracy: 0.8630\n",
            "Epoch 80/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3005 - accuracy: 0.8702\n",
            "Epoch 81/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2945 - accuracy: 0.8720\n",
            "Epoch 82/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2917 - accuracy: 0.8675\n",
            "Epoch 83/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2897 - accuracy: 0.8698\n",
            "Epoch 84/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2891 - accuracy: 0.8702\n",
            "Epoch 85/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2927 - accuracy: 0.8723\n",
            "Epoch 86/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2918 - accuracy: 0.8702\n",
            "Epoch 87/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2894 - accuracy: 0.8687\n",
            "Epoch 88/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2856 - accuracy: 0.8715\n",
            "Epoch 89/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2879 - accuracy: 0.8708\n",
            "Epoch 90/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2868 - accuracy: 0.8720\n",
            "Epoch 91/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2869 - accuracy: 0.8698\n",
            "Epoch 92/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2868 - accuracy: 0.8723\n",
            "Epoch 93/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2887 - accuracy: 0.8733\n",
            "Epoch 94/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.8737\n",
            "Epoch 95/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2849 - accuracy: 0.8725\n",
            "Epoch 96/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2816 - accuracy: 0.8760\n",
            "Epoch 97/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2810 - accuracy: 0.8727\n",
            "Epoch 98/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2817 - accuracy: 0.8705\n",
            "Epoch 99/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2824 - accuracy: 0.8730\n",
            "Epoch 100/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2831 - accuracy: 0.8750\n",
            "Epoch 101/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2767 - accuracy: 0.8790\n",
            "Epoch 102/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2820 - accuracy: 0.8712\n",
            "Epoch 103/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2809 - accuracy: 0.8755\n",
            "Epoch 104/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2778 - accuracy: 0.8742\n",
            "Epoch 105/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2768 - accuracy: 0.8715\n",
            "Epoch 106/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2821 - accuracy: 0.8740\n",
            "Epoch 107/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2766 - accuracy: 0.8752\n",
            "Epoch 108/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2757 - accuracy: 0.8780\n",
            "Epoch 109/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2734 - accuracy: 0.8763\n",
            "Epoch 110/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2769 - accuracy: 0.8748\n",
            "Epoch 111/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2736 - accuracy: 0.8788\n",
            "Epoch 112/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2706 - accuracy: 0.8775\n",
            "Epoch 113/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2723 - accuracy: 0.8777\n",
            "Epoch 114/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2695 - accuracy: 0.8805\n",
            "Epoch 115/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2721 - accuracy: 0.8795\n",
            "Epoch 116/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2662 - accuracy: 0.8842\n",
            "Epoch 117/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2686 - accuracy: 0.8792\n",
            "Epoch 118/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2635 - accuracy: 0.8835\n",
            "Epoch 119/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2700 - accuracy: 0.8788\n",
            "Epoch 120/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2688 - accuracy: 0.8800\n",
            "Epoch 121/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2641 - accuracy: 0.8840\n",
            "Epoch 122/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2628 - accuracy: 0.8845\n",
            "Epoch 123/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2616 - accuracy: 0.8777\n",
            "Epoch 124/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2686 - accuracy: 0.8783\n",
            "Epoch 125/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2620 - accuracy: 0.8867\n",
            "Epoch 126/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2572 - accuracy: 0.8825\n",
            "Epoch 127/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2552 - accuracy: 0.8875\n",
            "Epoch 128/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2623 - accuracy: 0.8830\n",
            "Epoch 129/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2569 - accuracy: 0.8875\n",
            "Epoch 130/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2582 - accuracy: 0.8857\n",
            "Epoch 131/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2593 - accuracy: 0.8863\n",
            "Epoch 132/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2609 - accuracy: 0.8790\n",
            "Epoch 133/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2622 - accuracy: 0.8808\n",
            "Epoch 134/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2549 - accuracy: 0.8857\n",
            "Epoch 135/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2605 - accuracy: 0.8830\n",
            "Epoch 136/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2523 - accuracy: 0.8855\n",
            "Epoch 137/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2523 - accuracy: 0.8875\n",
            "Epoch 138/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2512 - accuracy: 0.8900\n",
            "Epoch 139/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2549 - accuracy: 0.8867\n",
            "Epoch 140/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2492 - accuracy: 0.8910\n",
            "Epoch 141/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2485 - accuracy: 0.8913\n",
            "Epoch 142/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2494 - accuracy: 0.8890\n",
            "Epoch 143/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2489 - accuracy: 0.8890\n",
            "Epoch 144/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2489 - accuracy: 0.8845\n",
            "Epoch 145/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2473 - accuracy: 0.8903\n",
            "Epoch 146/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2465 - accuracy: 0.8895\n",
            "Epoch 147/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2454 - accuracy: 0.8932\n",
            "Epoch 148/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2464 - accuracy: 0.8865\n",
            "Epoch 149/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2485 - accuracy: 0.8888\n",
            "Epoch 150/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2439 - accuracy: 0.8923\n",
            "Epoch 151/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2422 - accuracy: 0.8925\n",
            "Epoch 152/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2403 - accuracy: 0.8900\n",
            "Epoch 153/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2408 - accuracy: 0.8938\n",
            "Epoch 154/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2475 - accuracy: 0.8928\n",
            "Epoch 155/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2366 - accuracy: 0.8957\n",
            "Epoch 156/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2310 - accuracy: 0.8963\n",
            "Epoch 157/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2379 - accuracy: 0.8955\n",
            "Epoch 158/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2350 - accuracy: 0.8917\n",
            "Epoch 159/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.8935\n",
            "Epoch 160/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2368 - accuracy: 0.8928\n",
            "Epoch 161/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2329 - accuracy: 0.8980\n",
            "Epoch 162/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2320 - accuracy: 0.8995\n",
            "Epoch 163/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2284 - accuracy: 0.8980\n",
            "Epoch 164/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2342 - accuracy: 0.8967\n",
            "Epoch 165/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2305 - accuracy: 0.8940\n",
            "Epoch 166/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2302 - accuracy: 0.8992\n",
            "Epoch 167/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2312 - accuracy: 0.8950\n",
            "Epoch 168/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2340 - accuracy: 0.8963\n",
            "Epoch 169/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2243 - accuracy: 0.8985\n",
            "Epoch 170/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2252 - accuracy: 0.9007\n",
            "Epoch 171/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2264 - accuracy: 0.8980\n",
            "Epoch 172/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2265 - accuracy: 0.9010\n",
            "Epoch 173/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2182 - accuracy: 0.9018\n",
            "Epoch 174/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9047\n",
            "Epoch 175/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2198 - accuracy: 0.9013\n",
            "Epoch 176/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2227 - accuracy: 0.9028\n",
            "Epoch 177/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2175 - accuracy: 0.9018\n",
            "Epoch 178/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2130 - accuracy: 0.9057\n",
            "Epoch 179/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2142 - accuracy: 0.9032\n",
            "Epoch 180/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2124 - accuracy: 0.9022\n",
            "Epoch 181/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2203 - accuracy: 0.9028\n",
            "Epoch 182/200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2168 - accuracy: 0.9028\n",
            "Epoch 183/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2206 - accuracy: 0.9030\n",
            "Epoch 184/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2074 - accuracy: 0.9095\n",
            "Epoch 185/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2094 - accuracy: 0.9062\n",
            "Epoch 186/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2070 - accuracy: 0.9075\n",
            "Epoch 187/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9060\n",
            "Epoch 188/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2046 - accuracy: 0.9078\n",
            "Epoch 189/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.9087\n",
            "Epoch 190/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2052 - accuracy: 0.9093\n",
            "Epoch 191/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2100 - accuracy: 0.9053\n",
            "Epoch 192/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2033 - accuracy: 0.9135\n",
            "Epoch 193/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2080 - accuracy: 0.9065\n",
            "Epoch 194/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2050 - accuracy: 0.9055\n",
            "Epoch 195/200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1999 - accuracy: 0.9130\n",
            "Epoch 196/200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2016 - accuracy: 0.9090\n",
            "Epoch 197/200\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1918 - accuracy: 0.9162\n",
            "Epoch 198/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2022 - accuracy: 0.9107\n",
            "Epoch 199/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2002 - accuracy: 0.9125\n",
            "Epoch 200/200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1926 - accuracy: 0.9137\n",
            "32/32 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.847\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.51      0.56       192\n",
            "           1       0.89      0.93      0.91       808\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.76      0.72      0.73      1000\n",
            "weighted avg       0.84      0.85      0.84      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the resampled dataset from the CSV file\n",
        "resampled_df = pd.read_csv(\"balanced_dataset.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = resampled_df.drop('Preterm Pregnancy', axis=1)\n",
        "y = resampled_df['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for GRU input: [samples, timesteps, features]\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential()\n",
        "model.add(GRU(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf896Bu1sEQe",
        "outputId": "dbae4a26-cbf2-4086-9290-0fa64bb6f3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "202/202 [==============================] - 5s 8ms/step - loss: 0.6840 - accuracy: 0.5554\n",
            "Epoch 2/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.6477 - accuracy: 0.6205\n",
            "Epoch 3/200\n",
            "202/202 [==============================] - 1s 7ms/step - loss: 0.6054 - accuracy: 0.6760\n",
            "Epoch 4/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.5627 - accuracy: 0.7094\n",
            "Epoch 5/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.5304 - accuracy: 0.7324\n",
            "Epoch 6/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.5147 - accuracy: 0.7470\n",
            "Epoch 7/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.5029 - accuracy: 0.7571\n",
            "Epoch 8/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.5013 - accuracy: 0.7504\n",
            "Epoch 9/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4936 - accuracy: 0.7622\n",
            "Epoch 10/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4850 - accuracy: 0.7661\n",
            "Epoch 11/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4797 - accuracy: 0.7731\n",
            "Epoch 12/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4767 - accuracy: 0.7744\n",
            "Epoch 13/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.4633 - accuracy: 0.7823\n",
            "Epoch 14/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.4625 - accuracy: 0.7809\n",
            "Epoch 15/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4631 - accuracy: 0.7852\n",
            "Epoch 16/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4559 - accuracy: 0.7866\n",
            "Epoch 17/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4515 - accuracy: 0.7880\n",
            "Epoch 18/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4438 - accuracy: 0.7960\n",
            "Epoch 19/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4415 - accuracy: 0.7932\n",
            "Epoch 20/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4420 - accuracy: 0.7941\n",
            "Epoch 21/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.4406 - accuracy: 0.7925\n",
            "Epoch 22/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.4394 - accuracy: 0.7927\n",
            "Epoch 23/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.4423 - accuracy: 0.7893\n",
            "Epoch 24/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4286 - accuracy: 0.8002\n",
            "Epoch 25/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4297 - accuracy: 0.8023\n",
            "Epoch 26/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4288 - accuracy: 0.8023\n",
            "Epoch 27/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4249 - accuracy: 0.8068\n",
            "Epoch 28/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.4196 - accuracy: 0.8051\n",
            "Epoch 29/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.4200 - accuracy: 0.8071\n",
            "Epoch 30/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4163 - accuracy: 0.8107\n",
            "Epoch 31/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4166 - accuracy: 0.8048\n",
            "Epoch 32/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4097 - accuracy: 0.8157\n",
            "Epoch 33/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4145 - accuracy: 0.8118\n",
            "Epoch 34/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.4109 - accuracy: 0.8106\n",
            "Epoch 35/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.4140 - accuracy: 0.8109\n",
            "Epoch 36/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.4079 - accuracy: 0.8121\n",
            "Epoch 37/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3983 - accuracy: 0.8154\n",
            "Epoch 38/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3995 - accuracy: 0.8166\n",
            "Epoch 39/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3960 - accuracy: 0.8210\n",
            "Epoch 40/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3979 - accuracy: 0.8193\n",
            "Epoch 41/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3966 - accuracy: 0.8182\n",
            "Epoch 42/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3900 - accuracy: 0.8266\n",
            "Epoch 43/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.3963 - accuracy: 0.8216\n",
            "Epoch 44/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.3862 - accuracy: 0.8281\n",
            "Epoch 45/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3929 - accuracy: 0.8253\n",
            "Epoch 46/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3805 - accuracy: 0.8303\n",
            "Epoch 47/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3794 - accuracy: 0.8342\n",
            "Epoch 48/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3742 - accuracy: 0.8361\n",
            "Epoch 49/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3770 - accuracy: 0.8339\n",
            "Epoch 50/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3714 - accuracy: 0.8373\n",
            "Epoch 51/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.3645 - accuracy: 0.8384\n",
            "Epoch 52/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.3701 - accuracy: 0.8389\n",
            "Epoch 53/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3502 - accuracy: 0.8482\n",
            "Epoch 54/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3454 - accuracy: 0.8516\n",
            "Epoch 55/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3409 - accuracy: 0.8553\n",
            "Epoch 56/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3416 - accuracy: 0.8517\n",
            "Epoch 57/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3464 - accuracy: 0.8480\n",
            "Epoch 58/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.3288 - accuracy: 0.8597\n",
            "Epoch 59/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.3268 - accuracy: 0.8625\n",
            "Epoch 60/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3302 - accuracy: 0.8597\n",
            "Epoch 61/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3170 - accuracy: 0.8654\n",
            "Epoch 62/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3141 - accuracy: 0.8664\n",
            "Epoch 63/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3127 - accuracy: 0.8687\n",
            "Epoch 64/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3090 - accuracy: 0.8721\n",
            "Epoch 65/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3082 - accuracy: 0.8723\n",
            "Epoch 66/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.3068 - accuracy: 0.8699\n",
            "Epoch 67/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.3013 - accuracy: 0.8730\n",
            "Epoch 68/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3027 - accuracy: 0.8744\n",
            "Epoch 69/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3000 - accuracy: 0.8738\n",
            "Epoch 70/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2959 - accuracy: 0.8730\n",
            "Epoch 71/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.3057 - accuracy: 0.8729\n",
            "Epoch 72/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2990 - accuracy: 0.8766\n",
            "Epoch 73/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.2839 - accuracy: 0.8828\n",
            "Epoch 74/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2792 - accuracy: 0.8844\n",
            "Epoch 75/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2909 - accuracy: 0.8766\n",
            "Epoch 76/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2764 - accuracy: 0.8858\n",
            "Epoch 77/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2780 - accuracy: 0.8824\n",
            "Epoch 78/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2743 - accuracy: 0.8866\n",
            "Epoch 79/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2729 - accuracy: 0.8845\n",
            "Epoch 80/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2752 - accuracy: 0.8856\n",
            "Epoch 81/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2673 - accuracy: 0.8898\n",
            "Epoch 82/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.2744 - accuracy: 0.8876\n",
            "Epoch 83/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2675 - accuracy: 0.8895\n",
            "Epoch 84/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2678 - accuracy: 0.8886\n",
            "Epoch 85/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2728 - accuracy: 0.8929\n",
            "Epoch 86/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2591 - accuracy: 0.8953\n",
            "Epoch 87/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2634 - accuracy: 0.8918\n",
            "Epoch 88/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2587 - accuracy: 0.8931\n",
            "Epoch 89/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.2542 - accuracy: 0.8953\n",
            "Epoch 90/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2544 - accuracy: 0.8922\n",
            "Epoch 91/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2544 - accuracy: 0.8976\n",
            "Epoch 92/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2539 - accuracy: 0.8953\n",
            "Epoch 93/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2599 - accuracy: 0.8960\n",
            "Epoch 94/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2638 - accuracy: 0.8922\n",
            "Epoch 95/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2456 - accuracy: 0.9029\n",
            "Epoch 96/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.2543 - accuracy: 0.8963\n",
            "Epoch 97/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2403 - accuracy: 0.9047\n",
            "Epoch 98/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2481 - accuracy: 0.8974\n",
            "Epoch 99/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2449 - accuracy: 0.8984\n",
            "Epoch 100/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2311 - accuracy: 0.9074\n",
            "Epoch 101/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2458 - accuracy: 0.8990\n",
            "Epoch 102/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2443 - accuracy: 0.8999\n",
            "Epoch 103/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2377 - accuracy: 0.9061\n",
            "Epoch 104/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2320 - accuracy: 0.9075\n",
            "Epoch 105/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.2322 - accuracy: 0.9027\n",
            "Epoch 106/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2335 - accuracy: 0.9069\n",
            "Epoch 107/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2362 - accuracy: 0.9044\n",
            "Epoch 108/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2246 - accuracy: 0.9077\n",
            "Epoch 109/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2303 - accuracy: 0.9085\n",
            "Epoch 110/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2341 - accuracy: 0.9043\n",
            "Epoch 111/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.2164 - accuracy: 0.9110\n",
            "Epoch 112/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2223 - accuracy: 0.9103\n",
            "Epoch 113/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2196 - accuracy: 0.9125\n",
            "Epoch 114/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2265 - accuracy: 0.9027\n",
            "Epoch 115/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2209 - accuracy: 0.9153\n",
            "Epoch 116/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2096 - accuracy: 0.9153\n",
            "Epoch 117/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2087 - accuracy: 0.9192\n",
            "Epoch 118/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2249 - accuracy: 0.9097\n",
            "Epoch 119/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2067 - accuracy: 0.9170\n",
            "Epoch 120/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.2250 - accuracy: 0.9097\n",
            "Epoch 121/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2068 - accuracy: 0.9152\n",
            "Epoch 122/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.2010 - accuracy: 0.9225\n",
            "Epoch 123/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.2206 - accuracy: 0.9108\n",
            "Epoch 124/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2115 - accuracy: 0.9131\n",
            "Epoch 125/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2005 - accuracy: 0.9201\n",
            "Epoch 126/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.1938 - accuracy: 0.9215\n",
            "Epoch 127/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.1975 - accuracy: 0.9223\n",
            "Epoch 128/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1995 - accuracy: 0.9201\n",
            "Epoch 129/200\n",
            "202/202 [==============================] - 2s 7ms/step - loss: 0.1987 - accuracy: 0.9183\n",
            "Epoch 130/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1887 - accuracy: 0.9245\n",
            "Epoch 131/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1945 - accuracy: 0.9217\n",
            "Epoch 132/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1917 - accuracy: 0.9245\n",
            "Epoch 133/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1883 - accuracy: 0.9257\n",
            "Epoch 134/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.1958 - accuracy: 0.9235\n",
            "Epoch 135/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.2283 - accuracy: 0.9099\n",
            "Epoch 136/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1889 - accuracy: 0.9259\n",
            "Epoch 137/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1875 - accuracy: 0.9240\n",
            "Epoch 138/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1794 - accuracy: 0.9296\n",
            "Epoch 139/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1918 - accuracy: 0.9232\n",
            "Epoch 140/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1842 - accuracy: 0.9263\n",
            "Epoch 141/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1846 - accuracy: 0.9287\n",
            "Epoch 142/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1789 - accuracy: 0.9288\n",
            "Epoch 143/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1851 - accuracy: 0.9273\n",
            "Epoch 144/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1769 - accuracy: 0.9296\n",
            "Epoch 145/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1709 - accuracy: 0.9344\n",
            "Epoch 146/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1726 - accuracy: 0.9319\n",
            "Epoch 147/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1797 - accuracy: 0.9259\n",
            "Epoch 148/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1762 - accuracy: 0.9293\n",
            "Epoch 149/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.1733 - accuracy: 0.9304\n",
            "Epoch 150/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1925 - accuracy: 0.9239\n",
            "Epoch 151/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1883 - accuracy: 0.9248\n",
            "Epoch 152/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1631 - accuracy: 0.9371\n",
            "Epoch 153/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1616 - accuracy: 0.9397\n",
            "Epoch 154/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1708 - accuracy: 0.9312\n",
            "Epoch 155/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1683 - accuracy: 0.9344\n",
            "Epoch 156/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1602 - accuracy: 0.9357\n",
            "Epoch 157/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1614 - accuracy: 0.9357\n",
            "Epoch 158/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1518 - accuracy: 0.9413\n",
            "Epoch 159/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1594 - accuracy: 0.9386\n",
            "Epoch 160/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1650 - accuracy: 0.9329\n",
            "Epoch 161/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1549 - accuracy: 0.9363\n",
            "Epoch 162/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1708 - accuracy: 0.9355\n",
            "Epoch 163/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1499 - accuracy: 0.9450\n",
            "Epoch 164/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.1467 - accuracy: 0.9447\n",
            "Epoch 165/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.1528 - accuracy: 0.9408\n",
            "Epoch 166/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1572 - accuracy: 0.9391\n",
            "Epoch 167/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1472 - accuracy: 0.9414\n",
            "Epoch 168/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1531 - accuracy: 0.9433\n",
            "Epoch 169/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1540 - accuracy: 0.9414\n",
            "Epoch 170/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1477 - accuracy: 0.9414\n",
            "Epoch 171/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1810 - accuracy: 0.9319\n",
            "Epoch 172/200\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.1391 - accuracy: 0.9448\n",
            "Epoch 173/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1322 - accuracy: 0.9504\n",
            "Epoch 174/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1435 - accuracy: 0.9450\n",
            "Epoch 175/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1419 - accuracy: 0.9447\n",
            "Epoch 176/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1373 - accuracy: 0.9473\n",
            "Epoch 177/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1404 - accuracy: 0.9447\n",
            "Epoch 178/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1297 - accuracy: 0.9498\n",
            "Epoch 179/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.1412 - accuracy: 0.9459\n",
            "Epoch 180/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1322 - accuracy: 0.9475\n",
            "Epoch 181/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1262 - accuracy: 0.9512\n",
            "Epoch 182/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1557 - accuracy: 0.9402\n",
            "Epoch 183/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1401 - accuracy: 0.9472\n",
            "Epoch 184/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1215 - accuracy: 0.9549\n",
            "Epoch 185/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1395 - accuracy: 0.9461\n",
            "Epoch 186/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1281 - accuracy: 0.9517\n",
            "Epoch 187/200\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.1287 - accuracy: 0.9520\n",
            "Epoch 188/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1229 - accuracy: 0.9545\n",
            "Epoch 189/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1200 - accuracy: 0.9538\n",
            "Epoch 190/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1143 - accuracy: 0.9568\n",
            "Epoch 191/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1394 - accuracy: 0.9487\n",
            "Epoch 192/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1298 - accuracy: 0.9515\n",
            "Epoch 193/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1282 - accuracy: 0.9497\n",
            "Epoch 194/200\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.1246 - accuracy: 0.9521\n",
            "Epoch 195/200\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.1279 - accuracy: 0.9481\n",
            "Epoch 196/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1187 - accuracy: 0.9552\n",
            "Epoch 197/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1218 - accuracy: 0.9551\n",
            "Epoch 198/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1052 - accuracy: 0.9599\n",
            "Epoch 199/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1029 - accuracy: 0.9621\n",
            "Epoch 200/200\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.1346 - accuracy: 0.9473\n",
            "51/51 [==============================] - 1s 5ms/step\n",
            "Accuracy: 0.9036668738346799\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.91       817\n",
            "           1       0.92      0.89      0.90       792\n",
            "\n",
            "    accuracy                           0.90      1609\n",
            "   macro avg       0.90      0.90      0.90      1609\n",
            "weighted avg       0.90      0.90      0.90      1609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the numerical dataset from the CSV file\n",
        "data = pd.read_csv(\"preprocessed_data.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Preterm Pregnancy', axis=1)\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for LSTM input: [samples, timesteps, features]\n",
        "X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LExQ7OrEtuz_",
        "outputId": "3a693ba2-96a3-4cf9-ee99-33251b5bf2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 3s 5ms/step - loss: 0.7853 - accuracy: 0.3836\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.6101\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.6981\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6604\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.6730\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6730\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.7233\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.7421\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.7358\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5856 - accuracy: 0.7358\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5827 - accuracy: 0.7484\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.7296\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7673\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7673\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7736\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5603 - accuracy: 0.7610\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7610\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7547\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7673\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7799\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5441 - accuracy: 0.7610\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7484\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7799\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7987\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7862\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7547\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7862\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7862\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.8113\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7862\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7736\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5103 - accuracy: 0.7862\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.8113\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7987\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.8050\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7987\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7987\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7987\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7925\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7925\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.8050\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.8050\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.8050\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7925\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7987\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.8239\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.8113\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7987\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.8050\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7925\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7987\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.8050\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.8176\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8113\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8113\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.8239\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.8176\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8176\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8176\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.8302\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8113\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8176\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8239\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8428\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8113\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8176\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8365\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8302\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8302\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8553\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8428\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8491\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8553\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8553\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8302\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8428\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8679\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8553\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8491\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8616\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8428\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8679\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8679\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8742\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8616\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8553\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8679\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8616\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.8679\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3561 - accuracy: 0.8742\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8742\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8994\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8868\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8931\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3449 - accuracy: 0.8931\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8679\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8805\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.9057\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8868\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8994\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8868\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.9057\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8805\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3224 - accuracy: 0.9057\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3255 - accuracy: 0.8994\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3183 - accuracy: 0.8994\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8994\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.8931\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8931\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8742\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3163 - accuracy: 0.8931\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3219 - accuracy: 0.8868\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8994\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8931\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.9057\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3001 - accuracy: 0.9057\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3005 - accuracy: 0.9057\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.8994\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.8994\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3000 - accuracy: 0.8994\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8994\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2895 - accuracy: 0.9057\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2920 - accuracy: 0.8994\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2857 - accuracy: 0.9057\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.8931\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2994 - accuracy: 0.8805\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2981 - accuracy: 0.8994\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.9119\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8868\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.8931\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2732 - accuracy: 0.8931\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8994\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2829 - accuracy: 0.9057\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9057\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9119\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2661 - accuracy: 0.9119\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2709 - accuracy: 0.9057\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.9057\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2607 - accuracy: 0.9057\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2639 - accuracy: 0.9119\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2623 - accuracy: 0.8994\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9057\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9182\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.9119\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9182\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 0.8994\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9182\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2516 - accuracy: 0.9245\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.8994\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2529 - accuracy: 0.9119\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2514 - accuracy: 0.9182\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2470 - accuracy: 0.9245\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.9245\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.8994\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2479 - accuracy: 0.9182\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2442 - accuracy: 0.9119\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2431 - accuracy: 0.9245\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2442 - accuracy: 0.9119\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2433 - accuracy: 0.9308\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2424 - accuracy: 0.9182\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.9245\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2354 - accuracy: 0.9057\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9182\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9308\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2354 - accuracy: 0.9057\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9245\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9182\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2292 - accuracy: 0.9119\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2272 - accuracy: 0.9182\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9245\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9182\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2246 - accuracy: 0.9119\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9371\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9245\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2291 - accuracy: 0.9434\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9057\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9308\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.9245\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2214 - accuracy: 0.9308\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2177 - accuracy: 0.9182\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9245\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9182\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2183 - accuracy: 0.9371\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2090 - accuracy: 0.9497\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9119\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2379 - accuracy: 0.9560\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2205 - accuracy: 0.9057\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2265 - accuracy: 0.9308\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9245\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9371\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2106 - accuracy: 0.9245\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2048 - accuracy: 0.9245\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2066 - accuracy: 0.9497\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2082 - accuracy: 0.9182\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2055 - accuracy: 0.9371\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2100 - accuracy: 0.9245\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2011 - accuracy: 0.9434\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9371\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2048 - accuracy: 0.9497\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1939 - accuracy: 0.9371\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Accuracy: 0.825\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.53      0.70        15\n",
            "           1       0.78      1.00      0.88        25\n",
            "\n",
            "    accuracy                           0.82        40\n",
            "   macro avg       0.89      0.77      0.79        40\n",
            "weighted avg       0.86      0.82      0.81        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the numerical dataset from the CSV file\n",
        "data = pd.read_csv(\"synthetic_data_rounded.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Preterm Pregnancy', axis=1)\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for LSTM input: [samples, timesteps, features]\n",
        "X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHOHKqMruatu",
        "outputId": "c5a68212-4899-4a02-870f-cc56163a2050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "125/125 [==============================] - 5s 8ms/step - loss: 0.4673 - accuracy: 0.8083\n",
            "Epoch 2/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4372 - accuracy: 0.8123\n",
            "Epoch 3/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8127\n",
            "Epoch 4/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8112\n",
            "Epoch 5/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8112\n",
            "Epoch 6/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8158\n",
            "Epoch 7/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8213\n",
            "Epoch 8/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8217\n",
            "Epoch 9/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8220\n",
            "Epoch 10/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8235\n",
            "Epoch 11/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8257\n",
            "Epoch 12/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8267\n",
            "Epoch 13/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8315\n",
            "Epoch 14/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8282\n",
            "Epoch 15/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8340\n",
            "Epoch 16/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8335\n",
            "Epoch 17/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8315\n",
            "Epoch 18/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8320\n",
            "Epoch 19/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8298\n",
            "Epoch 20/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8365\n",
            "Epoch 21/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8325\n",
            "Epoch 22/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8345\n",
            "Epoch 23/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8335\n",
            "Epoch 24/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8375\n",
            "Epoch 25/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8372\n",
            "Epoch 26/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3624 - accuracy: 0.8415\n",
            "Epoch 27/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.8438\n",
            "Epoch 28/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3582 - accuracy: 0.8447\n",
            "Epoch 29/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3560 - accuracy: 0.8422\n",
            "Epoch 30/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3557 - accuracy: 0.8413\n",
            "Epoch 31/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8422\n",
            "Epoch 32/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8447\n",
            "Epoch 33/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8482\n",
            "Epoch 34/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8475\n",
            "Epoch 35/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8497\n",
            "Epoch 36/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8453\n",
            "Epoch 37/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8500\n",
            "Epoch 38/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8503\n",
            "Epoch 39/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8503\n",
            "Epoch 40/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8525\n",
            "Epoch 41/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8493\n",
            "Epoch 42/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8558\n",
            "Epoch 43/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8583\n",
            "Epoch 44/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8583\n",
            "Epoch 45/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8503\n",
            "Epoch 46/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8528\n",
            "Epoch 47/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8537\n",
            "Epoch 48/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8585\n",
            "Epoch 49/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8575\n",
            "Epoch 50/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8620\n",
            "Epoch 51/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8635\n",
            "Epoch 52/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8652\n",
            "Epoch 53/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8643\n",
            "Epoch 54/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.8585\n",
            "Epoch 55/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.8630\n",
            "Epoch 56/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.8677\n",
            "Epoch 57/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3207 - accuracy: 0.8612\n",
            "Epoch 58/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3123 - accuracy: 0.8648\n",
            "Epoch 59/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8630\n",
            "Epoch 60/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8620\n",
            "Epoch 61/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8665\n",
            "Epoch 62/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8675\n",
            "Epoch 63/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.8690\n",
            "Epoch 64/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8710\n",
            "Epoch 65/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8680\n",
            "Epoch 66/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8675\n",
            "Epoch 67/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8637\n",
            "Epoch 68/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8652\n",
            "Epoch 69/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8687\n",
            "Epoch 70/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.8695\n",
            "Epoch 71/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8645\n",
            "Epoch 72/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8670\n",
            "Epoch 73/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8685\n",
            "Epoch 74/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8737\n",
            "Epoch 75/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8760\n",
            "Epoch 76/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8680\n",
            "Epoch 77/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8677\n",
            "Epoch 78/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8662\n",
            "Epoch 79/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8742\n",
            "Epoch 80/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8692\n",
            "Epoch 81/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8785\n",
            "Epoch 82/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8725\n",
            "Epoch 83/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3010 - accuracy: 0.8730\n",
            "Epoch 84/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.8723\n",
            "Epoch 85/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2945 - accuracy: 0.8730\n",
            "Epoch 86/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2987 - accuracy: 0.8705\n",
            "Epoch 87/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2977 - accuracy: 0.8687\n",
            "Epoch 88/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8765\n",
            "Epoch 89/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8788\n",
            "Epoch 90/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8695\n",
            "Epoch 91/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8745\n",
            "Epoch 92/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8767\n",
            "Epoch 93/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8780\n",
            "Epoch 94/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8750\n",
            "Epoch 95/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8712\n",
            "Epoch 96/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.8750\n",
            "Epoch 97/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8788\n",
            "Epoch 98/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.8742\n",
            "Epoch 99/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8777\n",
            "Epoch 100/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8730\n",
            "Epoch 101/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8785\n",
            "Epoch 102/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8780\n",
            "Epoch 103/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8725\n",
            "Epoch 104/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8750\n",
            "Epoch 105/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8777\n",
            "Epoch 106/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8708\n",
            "Epoch 107/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8752\n",
            "Epoch 108/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2875 - accuracy: 0.8790\n",
            "Epoch 109/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2895 - accuracy: 0.8773\n",
            "Epoch 110/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8785\n",
            "Epoch 111/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8763\n",
            "Epoch 112/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2899 - accuracy: 0.8758\n",
            "Epoch 113/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2898 - accuracy: 0.8752\n",
            "Epoch 114/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2882 - accuracy: 0.8740\n",
            "Epoch 115/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2880 - accuracy: 0.8770\n",
            "Epoch 116/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2868 - accuracy: 0.8785\n",
            "Epoch 117/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8790\n",
            "Epoch 118/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8813\n",
            "Epoch 119/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8798\n",
            "Epoch 120/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8750\n",
            "Epoch 121/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8820\n",
            "Epoch 122/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8825\n",
            "Epoch 123/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8760\n",
            "Epoch 124/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8765\n",
            "Epoch 125/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8845\n",
            "Epoch 126/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8783\n",
            "Epoch 127/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8760\n",
            "Epoch 128/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8730\n",
            "Epoch 129/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8848\n",
            "Epoch 130/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8717\n",
            "Epoch 131/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8783\n",
            "Epoch 132/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8805\n",
            "Epoch 133/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8813\n",
            "Epoch 134/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.8792\n",
            "Epoch 135/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8825\n",
            "Epoch 136/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8777\n",
            "Epoch 137/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.8817\n",
            "Epoch 138/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8798\n",
            "Epoch 139/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.8820\n",
            "Epoch 140/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.8842\n",
            "Epoch 141/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2828 - accuracy: 0.8765\n",
            "Epoch 142/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2837 - accuracy: 0.8748\n",
            "Epoch 143/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2821 - accuracy: 0.8792\n",
            "Epoch 144/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2807 - accuracy: 0.8798\n",
            "Epoch 145/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8792\n",
            "Epoch 146/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8820\n",
            "Epoch 147/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8750\n",
            "Epoch 148/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8780\n",
            "Epoch 149/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8805\n",
            "Epoch 150/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 0.8827\n",
            "Epoch 151/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8783\n",
            "Epoch 152/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.8798\n",
            "Epoch 153/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8817\n",
            "Epoch 154/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8863\n",
            "Epoch 155/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8755\n",
            "Epoch 156/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8775\n",
            "Epoch 157/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8845\n",
            "Epoch 158/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8825\n",
            "Epoch 159/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8840\n",
            "Epoch 160/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8792\n",
            "Epoch 161/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8848\n",
            "Epoch 162/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8788\n",
            "Epoch 163/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8800\n",
            "Epoch 164/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8840\n",
            "Epoch 165/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8792\n",
            "Epoch 166/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8825\n",
            "Epoch 167/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8820\n",
            "Epoch 168/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8842\n",
            "Epoch 169/200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2780 - accuracy: 0.8802\n",
            "Epoch 170/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2744 - accuracy: 0.8805\n",
            "Epoch 171/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2745 - accuracy: 0.8808\n",
            "Epoch 172/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2731 - accuracy: 0.8875\n",
            "Epoch 173/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.8842\n",
            "Epoch 174/200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8842\n",
            "Epoch 175/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8845\n",
            "Epoch 176/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8790\n",
            "Epoch 177/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8838\n",
            "Epoch 178/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8867\n",
            "Epoch 179/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8813\n",
            "Epoch 180/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8860\n",
            "Epoch 181/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8882\n",
            "Epoch 182/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8867\n",
            "Epoch 183/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.8880\n",
            "Epoch 184/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8852\n",
            "Epoch 185/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8838\n",
            "Epoch 186/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8813\n",
            "Epoch 187/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8840\n",
            "Epoch 188/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8835\n",
            "Epoch 189/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8855\n",
            "Epoch 190/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8848\n",
            "Epoch 191/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8840\n",
            "Epoch 192/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8827\n",
            "Epoch 193/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8838\n",
            "Epoch 194/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8850\n",
            "Epoch 195/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8850\n",
            "Epoch 196/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.8860\n",
            "Epoch 197/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8860\n",
            "Epoch 198/200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8810\n",
            "Epoch 199/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2698 - accuracy: 0.8817\n",
            "Epoch 200/200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2682 - accuracy: 0.8892\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.884\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.50      0.62       192\n",
            "           1       0.89      0.98      0.93       808\n",
            "\n",
            "    accuracy                           0.88      1000\n",
            "   macro avg       0.86      0.74      0.78      1000\n",
            "weighted avg       0.88      0.88      0.87      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the numerical dataset from the CSV file\n",
        "data = pd.read_csv(\"balanced_dataset.csv\")\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Preterm Pregnancy', axis=1)\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape X for LSTM input: [samples, timesteps, features]\n",
        "X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with 100 epochs\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtltlB6VvJfY",
        "outputId": "062712b8-b996-48a9-c7f4-4cb027a90695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "202/202 [==============================] - 4s 3ms/step - loss: 0.6500 - accuracy: 0.6291\n",
            "Epoch 2/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.6168 - accuracy: 0.6911\n",
            "Epoch 3/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.5919 - accuracy: 0.7187\n",
            "Epoch 4/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.5665 - accuracy: 0.7386\n",
            "Epoch 5/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.5510 - accuracy: 0.7497\n",
            "Epoch 6/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.5414 - accuracy: 0.7514\n",
            "Epoch 7/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.5239 - accuracy: 0.7681\n",
            "Epoch 8/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.5217 - accuracy: 0.7551\n",
            "Epoch 9/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.7761\n",
            "Epoch 10/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4945 - accuracy: 0.7719\n",
            "Epoch 11/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4817 - accuracy: 0.7789\n",
            "Epoch 12/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4737 - accuracy: 0.7846\n",
            "Epoch 13/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4706 - accuracy: 0.7845\n",
            "Epoch 14/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4573 - accuracy: 0.7911\n",
            "Epoch 15/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4488 - accuracy: 0.7970\n",
            "Epoch 16/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4362 - accuracy: 0.8075\n",
            "Epoch 17/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4356 - accuracy: 0.8036\n",
            "Epoch 18/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4312 - accuracy: 0.8042\n",
            "Epoch 19/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.8030\n",
            "Epoch 20/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4165 - accuracy: 0.8129\n",
            "Epoch 21/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4136 - accuracy: 0.8149\n",
            "Epoch 22/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4046 - accuracy: 0.8222\n",
            "Epoch 23/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8145\n",
            "Epoch 24/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.4049 - accuracy: 0.8186\n",
            "Epoch 25/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3980 - accuracy: 0.8190\n",
            "Epoch 26/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8253\n",
            "Epoch 27/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8241\n",
            "Epoch 28/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3917 - accuracy: 0.8261\n",
            "Epoch 29/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3818 - accuracy: 0.8362\n",
            "Epoch 30/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3973 - accuracy: 0.8239\n",
            "Epoch 31/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3886 - accuracy: 0.8287\n",
            "Epoch 32/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3895 - accuracy: 0.8270\n",
            "Epoch 33/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8395\n",
            "Epoch 34/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3787 - accuracy: 0.8354\n",
            "Epoch 35/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3934 - accuracy: 0.8199\n",
            "Epoch 36/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.8351\n",
            "Epoch 37/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.8356\n",
            "Epoch 38/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3866 - accuracy: 0.8289\n",
            "Epoch 39/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8370\n",
            "Epoch 40/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3728 - accuracy: 0.8412\n",
            "Epoch 41/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8390\n",
            "Epoch 42/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8269\n",
            "Epoch 43/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8340\n",
            "Epoch 44/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8371\n",
            "Epoch 45/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3725 - accuracy: 0.8357\n",
            "Epoch 46/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3701 - accuracy: 0.8378\n",
            "Epoch 47/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8373\n",
            "Epoch 48/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8351\n",
            "Epoch 49/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8402\n",
            "Epoch 50/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3746 - accuracy: 0.8333\n",
            "Epoch 51/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3723 - accuracy: 0.8378\n",
            "Epoch 52/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3739 - accuracy: 0.8347\n",
            "Epoch 53/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8407\n",
            "Epoch 54/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3641 - accuracy: 0.8398\n",
            "Epoch 55/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3645 - accuracy: 0.8406\n",
            "Epoch 56/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3655 - accuracy: 0.8370\n",
            "Epoch 57/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3617 - accuracy: 0.8427\n",
            "Epoch 58/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8381\n",
            "Epoch 59/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8367\n",
            "Epoch 60/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.8441\n",
            "Epoch 61/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3505 - accuracy: 0.8476\n",
            "Epoch 62/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8497\n",
            "Epoch 63/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3545 - accuracy: 0.8424\n",
            "Epoch 64/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8385\n",
            "Epoch 65/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8462\n",
            "Epoch 66/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3548 - accuracy: 0.8443\n",
            "Epoch 67/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3536 - accuracy: 0.8451\n",
            "Epoch 68/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3625 - accuracy: 0.8407\n",
            "Epoch 69/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8410\n",
            "Epoch 70/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3646 - accuracy: 0.8406\n",
            "Epoch 71/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8448\n",
            "Epoch 72/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3614 - accuracy: 0.8416\n",
            "Epoch 73/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3581 - accuracy: 0.8444\n",
            "Epoch 74/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8446\n",
            "Epoch 75/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3546 - accuracy: 0.8466\n",
            "Epoch 76/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3572 - accuracy: 0.8406\n",
            "Epoch 77/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8375\n",
            "Epoch 78/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3528 - accuracy: 0.8471\n",
            "Epoch 79/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8466\n",
            "Epoch 80/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8471\n",
            "Epoch 81/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8449\n",
            "Epoch 82/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3438 - accuracy: 0.8474\n",
            "Epoch 83/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3432 - accuracy: 0.8510\n",
            "Epoch 84/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8468\n",
            "Epoch 85/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8497\n",
            "Epoch 86/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8449\n",
            "Epoch 87/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3433 - accuracy: 0.8476\n",
            "Epoch 88/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3509 - accuracy: 0.8465\n",
            "Epoch 89/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3449 - accuracy: 0.8503\n",
            "Epoch 90/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8502\n",
            "Epoch 91/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.8496\n",
            "Epoch 92/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3484 - accuracy: 0.8488\n",
            "Epoch 93/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8496\n",
            "Epoch 94/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3408 - accuracy: 0.8493\n",
            "Epoch 95/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3623 - accuracy: 0.8379\n",
            "Epoch 96/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8389\n",
            "Epoch 97/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3452 - accuracy: 0.8524\n",
            "Epoch 98/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8510\n",
            "Epoch 99/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8466\n",
            "Epoch 100/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3495 - accuracy: 0.8497\n",
            "Epoch 101/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3413 - accuracy: 0.8539\n",
            "Epoch 102/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.8387\n",
            "Epoch 103/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8567\n",
            "Epoch 104/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8516\n",
            "Epoch 105/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3410 - accuracy: 0.8496\n",
            "Epoch 106/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8525\n",
            "Epoch 107/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.8462\n",
            "Epoch 108/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8482\n",
            "Epoch 109/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3420 - accuracy: 0.8490\n",
            "Epoch 110/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8521\n",
            "Epoch 111/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8483\n",
            "Epoch 112/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8510\n",
            "Epoch 113/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8469\n",
            "Epoch 114/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8555\n",
            "Epoch 115/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8542\n",
            "Epoch 116/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3424 - accuracy: 0.8474\n",
            "Epoch 117/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8538\n",
            "Epoch 118/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8567\n",
            "Epoch 119/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8472\n",
            "Epoch 120/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8587\n",
            "Epoch 121/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8567\n",
            "Epoch 122/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8544\n",
            "Epoch 123/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8561\n",
            "Epoch 124/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8556\n",
            "Epoch 125/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8535\n",
            "Epoch 126/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8547\n",
            "Epoch 127/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8594\n",
            "Epoch 128/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3284 - accuracy: 0.8566\n",
            "Epoch 129/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.8567\n",
            "Epoch 130/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3276 - accuracy: 0.8541\n",
            "Epoch 131/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8521\n",
            "Epoch 132/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.3308 - accuracy: 0.8566\n",
            "Epoch 133/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8530\n",
            "Epoch 134/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8508\n",
            "Epoch 135/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8589\n",
            "Epoch 136/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3255 - accuracy: 0.8552\n",
            "Epoch 137/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.8584\n",
            "Epoch 138/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8547\n",
            "Epoch 139/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3425 - accuracy: 0.8476\n",
            "Epoch 140/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8639\n",
            "Epoch 141/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8592\n",
            "Epoch 142/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3290 - accuracy: 0.8561\n",
            "Epoch 143/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8584\n",
            "Epoch 144/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3265 - accuracy: 0.8570\n",
            "Epoch 145/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8458\n",
            "Epoch 146/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3398 - accuracy: 0.8449\n",
            "Epoch 147/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8502\n",
            "Epoch 148/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3388 - accuracy: 0.8472\n",
            "Epoch 149/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8510\n",
            "Epoch 150/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8525\n",
            "Epoch 151/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8524\n",
            "Epoch 152/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.3273 - accuracy: 0.8573\n",
            "Epoch 153/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.8511\n",
            "Epoch 154/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3346 - accuracy: 0.8527\n",
            "Epoch 155/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3401 - accuracy: 0.8513\n",
            "Epoch 156/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3277 - accuracy: 0.8552\n",
            "Epoch 157/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8519\n",
            "Epoch 158/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8530\n",
            "Epoch 159/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8566\n",
            "Epoch 160/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3258 - accuracy: 0.8536\n",
            "Epoch 161/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8597\n",
            "Epoch 162/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3281 - accuracy: 0.8536\n",
            "Epoch 163/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.8577\n",
            "Epoch 164/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.8510\n",
            "Epoch 165/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3236 - accuracy: 0.8595\n",
            "Epoch 166/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8530\n",
            "Epoch 167/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.8587\n",
            "Epoch 168/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3224 - accuracy: 0.8589\n",
            "Epoch 169/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8500\n",
            "Epoch 170/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.8531\n",
            "Epoch 171/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8612\n",
            "Epoch 172/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8598\n",
            "Epoch 173/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8564\n",
            "Epoch 174/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8539\n",
            "Epoch 175/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.8572\n",
            "Epoch 176/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3176 - accuracy: 0.8583\n",
            "Epoch 177/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3358 - accuracy: 0.8522\n",
            "Epoch 178/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.8598\n",
            "Epoch 179/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8598\n",
            "Epoch 180/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3232 - accuracy: 0.8566\n",
            "Epoch 181/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3173 - accuracy: 0.8608\n",
            "Epoch 182/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.8611\n",
            "Epoch 183/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3213 - accuracy: 0.8583\n",
            "Epoch 184/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8541\n",
            "Epoch 185/200\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.3192 - accuracy: 0.8594\n",
            "Epoch 186/200\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.3167 - accuracy: 0.8639\n",
            "Epoch 187/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.8549\n",
            "Epoch 188/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8591\n",
            "Epoch 189/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3192 - accuracy: 0.8634\n",
            "Epoch 190/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.8587\n",
            "Epoch 191/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.8617\n",
            "Epoch 192/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8594\n",
            "Epoch 193/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3194 - accuracy: 0.8583\n",
            "Epoch 194/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3174 - accuracy: 0.8595\n",
            "Epoch 195/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.8595\n",
            "Epoch 196/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3265 - accuracy: 0.8524\n",
            "Epoch 197/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3169 - accuracy: 0.8612\n",
            "Epoch 198/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3233 - accuracy: 0.8586\n",
            "Epoch 199/200\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3191 - accuracy: 0.8595\n",
            "Epoch 200/200\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8587\n",
            "51/51 [==============================] - 1s 2ms/step\n",
            "Accuracy: 0.8719701678060907\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88       817\n",
            "           1       0.92      0.82      0.86       792\n",
            "\n",
            "    accuracy                           0.87      1609\n",
            "   macro avg       0.88      0.87      0.87      1609\n",
            "weighted avg       0.88      0.87      0.87      1609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zRvjoqiwrYc",
        "outputId": "7cadc091-d4a7-40db-bb06-78403d8cc92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m717.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your CSV file\n",
        "data = pd.read_csv('preprocessed_data.csv')\n",
        "\n",
        "# Split into features and target\n",
        "X = data.drop(columns=['Preterm Pregnancy'])\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define fixed hyperparameters for TabNet\n",
        "fixed_params = {\n",
        "    \"n_d\": 32,\n",
        "    \"n_a\": 32,\n",
        "    \"n_steps\": 5,\n",
        "    \"gamma\": 1.3,\n",
        "    \"momentum\": 0.2,\n",
        "    \"lambda_sparse\": 0.001,\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.01,\n",
        "        \"weight_decay\": 1e-5,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Train model with fixed parameters\n",
        "model = TabNetClassifier(**fixed_params)\n",
        "model.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], patience=10, max_epochs=100,\n",
        "           batch_size=128, virtual_batch_size=32, num_workers=0, drop_last=False)\n",
        "\n",
        "# Visualize feature importance\n",
        "feature_importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(feature_importance_df.set_index('Feature'), cmap='coolwarm', annot=True, fmt=\".3f\")\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test.values)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8jmdGT8ZwOND",
        "outputId": "e6cc7cc9-3b5d-40f1-d982-48ffe13cee17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 2.21533 | val_0_auc: 0.45067 |  0:00:00s\n",
            "epoch 1  | loss: 1.06036 | val_0_auc: 0.50667 |  0:00:00s\n",
            "epoch 2  | loss: 0.69429 | val_0_auc: 0.464   |  0:00:00s\n",
            "epoch 3  | loss: 0.69915 | val_0_auc: 0.588   |  0:00:00s\n",
            "epoch 4  | loss: 0.56156 | val_0_auc: 0.568   |  0:00:00s\n",
            "epoch 5  | loss: 0.54667 | val_0_auc: 0.45067 |  0:00:01s\n",
            "epoch 6  | loss: 0.52341 | val_0_auc: 0.5     |  0:00:01s\n",
            "epoch 7  | loss: 0.3798  | val_0_auc: 0.5     |  0:00:01s\n",
            "epoch 8  | loss: 0.40454 | val_0_auc: 0.5     |  0:00:01s\n",
            "epoch 9  | loss: 0.36761 | val_0_auc: 0.6     |  0:00:01s\n",
            "epoch 10 | loss: 0.35449 | val_0_auc: 0.608   |  0:00:02s\n",
            "epoch 11 | loss: 0.29591 | val_0_auc: 0.576   |  0:00:02s\n",
            "epoch 12 | loss: 0.3325  | val_0_auc: 0.48    |  0:00:02s\n",
            "epoch 13 | loss: 0.38641 | val_0_auc: 0.5     |  0:00:03s\n",
            "epoch 14 | loss: 0.2856  | val_0_auc: 0.5     |  0:00:03s\n",
            "epoch 15 | loss: 0.24465 | val_0_auc: 0.5     |  0:00:03s\n",
            "epoch 16 | loss: 0.28596 | val_0_auc: 0.5     |  0:00:03s\n",
            "epoch 17 | loss: 0.22304 | val_0_auc: 0.5     |  0:00:04s\n",
            "epoch 18 | loss: 0.21563 | val_0_auc: 0.5     |  0:00:04s\n",
            "epoch 19 | loss: 0.20191 | val_0_auc: 0.5     |  0:00:04s\n",
            "epoch 20 | loss: 0.29142 | val_0_auc: 0.53333 |  0:00:04s\n",
            "\n",
            "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.27      0.40        15\n",
            "           1       0.69      0.96      0.80        25\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.74      0.61      0.60        40\n",
            "weighted avg       0.73      0.70      0.65        40\n",
            "\n",
            "Accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your CSV file\n",
        "data = pd.read_csv('synthetic_data_rounded.csv')\n",
        "\n",
        "# Split into features and target\n",
        "X = data.drop(columns=['Preterm Pregnancy'])\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define fixed hyperparameters for TabNet\n",
        "fixed_params = {\n",
        "    \"n_d\": 32,\n",
        "    \"n_a\": 32,\n",
        "    \"n_steps\": 5,\n",
        "    \"gamma\": 1.3,\n",
        "    \"momentum\": 0.2,\n",
        "    \"lambda_sparse\": 0.001,\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.01,\n",
        "        \"weight_decay\": 1e-5,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Train model with fixed parameters\n",
        "model = TabNetClassifier(**fixed_params)\n",
        "model.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], patience=10, max_epochs=100,\n",
        "           batch_size=128, virtual_batch_size=32, num_workers=0, drop_last=False)\n",
        "\n",
        "# Visualize feature importance\n",
        "feature_importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(feature_importance_df.set_index('Feature'), cmap='coolwarm', annot=True, fmt=\".3f\")\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test.values)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FHqiXnQ7xdwj",
        "outputId": "5809d209-db7c-4685-bc14-94186bb1e61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.64108 | val_0_auc: 0.5     |  0:00:02s\n",
            "epoch 1  | loss: 0.49628 | val_0_auc: 0.56677 |  0:00:05s\n",
            "epoch 2  | loss: 0.44281 | val_0_auc: 0.59413 |  0:00:07s\n",
            "epoch 3  | loss: 0.42318 | val_0_auc: 0.61778 |  0:00:10s\n",
            "epoch 4  | loss: 0.41802 | val_0_auc: 0.76965 |  0:00:11s\n",
            "epoch 5  | loss: 0.40868 | val_0_auc: 0.7963  |  0:00:13s\n",
            "epoch 6  | loss: 0.4049  | val_0_auc: 0.80647 |  0:00:14s\n",
            "epoch 7  | loss: 0.39614 | val_0_auc: 0.80965 |  0:00:16s\n",
            "epoch 8  | loss: 0.38779 | val_0_auc: 0.81307 |  0:00:18s\n",
            "epoch 9  | loss: 0.39159 | val_0_auc: 0.8196  |  0:00:20s\n",
            "epoch 10 | loss: 0.3874  | val_0_auc: 0.83408 |  0:00:22s\n",
            "epoch 11 | loss: 0.38227 | val_0_auc: 0.85447 |  0:00:23s\n",
            "epoch 12 | loss: 0.36715 | val_0_auc: 0.82045 |  0:00:25s\n",
            "epoch 13 | loss: 0.36656 | val_0_auc: 0.81996 |  0:00:27s\n",
            "epoch 14 | loss: 0.36395 | val_0_auc: 0.82453 |  0:00:28s\n",
            "epoch 15 | loss: 0.36144 | val_0_auc: 0.83214 |  0:00:30s\n",
            "epoch 16 | loss: 0.35203 | val_0_auc: 0.84282 |  0:00:32s\n",
            "epoch 17 | loss: 0.3635  | val_0_auc: 0.84509 |  0:00:34s\n",
            "epoch 18 | loss: 0.34788 | val_0_auc: 0.86375 |  0:00:35s\n",
            "epoch 19 | loss: 0.34586 | val_0_auc: 0.86177 |  0:00:37s\n",
            "epoch 20 | loss: 0.33179 | val_0_auc: 0.86414 |  0:00:39s\n",
            "epoch 21 | loss: 0.3421  | val_0_auc: 0.85399 |  0:00:40s\n",
            "epoch 22 | loss: 0.34807 | val_0_auc: 0.85909 |  0:00:42s\n",
            "epoch 23 | loss: 0.3282  | val_0_auc: 0.87063 |  0:00:45s\n",
            "epoch 24 | loss: 0.33633 | val_0_auc: 0.88006 |  0:00:46s\n",
            "epoch 25 | loss: 0.32758 | val_0_auc: 0.88031 |  0:00:48s\n",
            "epoch 26 | loss: 0.32171 | val_0_auc: 0.8673  |  0:00:50s\n",
            "epoch 27 | loss: 0.33783 | val_0_auc: 0.88052 |  0:00:51s\n",
            "epoch 28 | loss: 0.32037 | val_0_auc: 0.86937 |  0:00:53s\n",
            "epoch 29 | loss: 0.31765 | val_0_auc: 0.88909 |  0:00:55s\n",
            "epoch 30 | loss: 0.31312 | val_0_auc: 0.86719 |  0:00:57s\n",
            "epoch 31 | loss: 0.32175 | val_0_auc: 0.89493 |  0:00:58s\n",
            "epoch 32 | loss: 0.31381 | val_0_auc: 0.88705 |  0:01:00s\n",
            "epoch 33 | loss: 0.30885 | val_0_auc: 0.87999 |  0:01:02s\n",
            "epoch 34 | loss: 0.32965 | val_0_auc: 0.89755 |  0:01:03s\n",
            "epoch 35 | loss: 0.30767 | val_0_auc: 0.90412 |  0:01:05s\n",
            "epoch 36 | loss: 0.30088 | val_0_auc: 0.90667 |  0:01:07s\n",
            "epoch 37 | loss: 0.29769 | val_0_auc: 0.91654 |  0:01:09s\n",
            "epoch 38 | loss: 0.29186 | val_0_auc: 0.90446 |  0:01:12s\n",
            "epoch 39 | loss: 0.29931 | val_0_auc: 0.8919  |  0:01:13s\n",
            "epoch 40 | loss: 0.29834 | val_0_auc: 0.89474 |  0:01:15s\n",
            "epoch 41 | loss: 0.2899  | val_0_auc: 0.88417 |  0:01:16s\n",
            "epoch 42 | loss: 0.28053 | val_0_auc: 0.91653 |  0:01:18s\n",
            "epoch 43 | loss: 0.27616 | val_0_auc: 0.90663 |  0:01:20s\n",
            "epoch 44 | loss: 0.29085 | val_0_auc: 0.91114 |  0:01:22s\n",
            "epoch 45 | loss: 0.27958 | val_0_auc: 0.91474 |  0:01:24s\n",
            "epoch 46 | loss: 0.27745 | val_0_auc: 0.90781 |  0:01:25s\n",
            "epoch 47 | loss: 0.27491 | val_0_auc: 0.92023 |  0:01:27s\n",
            "epoch 48 | loss: 0.27161 | val_0_auc: 0.92062 |  0:01:29s\n",
            "epoch 49 | loss: 0.28312 | val_0_auc: 0.92179 |  0:01:30s\n",
            "epoch 50 | loss: 0.26188 | val_0_auc: 0.92079 |  0:01:32s\n",
            "epoch 51 | loss: 0.27823 | val_0_auc: 0.91171 |  0:01:35s\n",
            "epoch 52 | loss: 0.27628 | val_0_auc: 0.92445 |  0:01:37s\n",
            "epoch 53 | loss: 0.27283 | val_0_auc: 0.91235 |  0:01:39s\n",
            "epoch 54 | loss: 0.27951 | val_0_auc: 0.91143 |  0:01:41s\n",
            "epoch 55 | loss: 0.27103 | val_0_auc: 0.92625 |  0:01:42s\n",
            "epoch 56 | loss: 0.26609 | val_0_auc: 0.92695 |  0:01:44s\n",
            "epoch 57 | loss: 0.26074 | val_0_auc: 0.91809 |  0:01:47s\n",
            "epoch 58 | loss: 0.26737 | val_0_auc: 0.92614 |  0:01:49s\n",
            "epoch 59 | loss: 0.26821 | val_0_auc: 0.91547 |  0:01:51s\n",
            "epoch 60 | loss: 0.27457 | val_0_auc: 0.92703 |  0:01:53s\n",
            "epoch 61 | loss: 0.2488  | val_0_auc: 0.93099 |  0:01:55s\n",
            "epoch 62 | loss: 0.26659 | val_0_auc: 0.91571 |  0:01:57s\n",
            "epoch 63 | loss: 0.25871 | val_0_auc: 0.91573 |  0:01:59s\n",
            "epoch 64 | loss: 0.25715 | val_0_auc: 0.91734 |  0:02:01s\n",
            "epoch 65 | loss: 0.25044 | val_0_auc: 0.91904 |  0:02:03s\n",
            "epoch 66 | loss: 0.27431 | val_0_auc: 0.91939 |  0:02:05s\n",
            "epoch 67 | loss: 0.26229 | val_0_auc: 0.91774 |  0:02:07s\n",
            "epoch 68 | loss: 0.25195 | val_0_auc: 0.91482 |  0:02:09s\n",
            "epoch 69 | loss: 0.24876 | val_0_auc: 0.91736 |  0:02:11s\n",
            "epoch 70 | loss: 0.25588 | val_0_auc: 0.91772 |  0:02:14s\n",
            "epoch 71 | loss: 0.2558  | val_0_auc: 0.90624 |  0:02:16s\n",
            "\n",
            "Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_auc = 0.93099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.60      0.65       192\n",
            "           1       0.91      0.94      0.93       808\n",
            "\n",
            "    accuracy                           0.88      1000\n",
            "   macro avg       0.81      0.77      0.79      1000\n",
            "weighted avg       0.87      0.88      0.87      1000\n",
            "\n",
            "Accuracy: 0.877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your CSV file\n",
        "data = pd.read_csv('balanced_dataset.csv')\n",
        "\n",
        "# Split into features and target\n",
        "X = data.drop(columns=['Preterm Pregnancy'])\n",
        "y = data['Preterm Pregnancy']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define fixed hyperparameters for TabNet\n",
        "fixed_params = {\n",
        "    \"n_d\": 32,\n",
        "    \"n_a\": 32,\n",
        "    \"n_steps\": 5,\n",
        "    \"gamma\": 1.3,\n",
        "    \"momentum\": 0.2,\n",
        "    \"lambda_sparse\": 0.001,\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.01,\n",
        "        \"weight_decay\": 1e-5,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Train model with fixed parameters\n",
        "model = TabNetClassifier(**fixed_params)\n",
        "model.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], patience=10, max_epochs=100,\n",
        "           batch_size=128, virtual_batch_size=32, num_workers=0, drop_last=False)\n",
        "\n",
        "# Visualize feature importance\n",
        "feature_importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(feature_importance_df.set_index('Feature'), cmap='coolwarm', annot=True, fmt=\".3f\")\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test.values)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XGaVleI5yXpj",
        "outputId": "97648174-3f07-42da-b6bc-709f2bad0493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.85944 | val_0_auc: 0.5138  |  0:00:04s\n",
            "epoch 1  | loss: 0.64345 | val_0_auc: 0.69841 |  0:00:08s\n",
            "epoch 2  | loss: 0.60611 | val_0_auc: 0.76453 |  0:00:10s\n",
            "epoch 3  | loss: 0.60504 | val_0_auc: 0.79849 |  0:00:13s\n",
            "epoch 4  | loss: 0.55733 | val_0_auc: 0.82135 |  0:00:16s\n",
            "epoch 5  | loss: 0.54392 | val_0_auc: 0.81477 |  0:00:19s\n",
            "epoch 6  | loss: 0.53696 | val_0_auc: 0.82423 |  0:00:22s\n",
            "epoch 7  | loss: 0.53175 | val_0_auc: 0.84591 |  0:00:24s\n",
            "epoch 8  | loss: 0.51863 | val_0_auc: 0.84051 |  0:00:27s\n",
            "epoch 9  | loss: 0.52646 | val_0_auc: 0.83537 |  0:00:29s\n",
            "epoch 10 | loss: 0.52571 | val_0_auc: 0.84595 |  0:00:33s\n",
            "epoch 11 | loss: 0.5185  | val_0_auc: 0.8358  |  0:00:35s\n",
            "epoch 12 | loss: 0.50672 | val_0_auc: 0.8625  |  0:00:40s\n",
            "epoch 13 | loss: 0.50145 | val_0_auc: 0.86396 |  0:00:43s\n",
            "epoch 14 | loss: 0.48829 | val_0_auc: 0.8583  |  0:00:46s\n",
            "epoch 15 | loss: 0.49302 | val_0_auc: 0.87441 |  0:00:49s\n",
            "epoch 16 | loss: 0.45895 | val_0_auc: 0.8755  |  0:00:51s\n",
            "epoch 17 | loss: 0.4421  | val_0_auc: 0.89915 |  0:00:54s\n",
            "epoch 18 | loss: 0.43309 | val_0_auc: 0.88396 |  0:00:57s\n",
            "epoch 19 | loss: 0.42149 | val_0_auc: 0.89714 |  0:01:00s\n",
            "epoch 20 | loss: 0.40773 | val_0_auc: 0.91822 |  0:01:03s\n",
            "epoch 21 | loss: 0.385   | val_0_auc: 0.91752 |  0:01:05s\n",
            "epoch 22 | loss: 0.38742 | val_0_auc: 0.93012 |  0:01:08s\n",
            "epoch 23 | loss: 0.37394 | val_0_auc: 0.93033 |  0:01:11s\n",
            "epoch 24 | loss: 0.3818  | val_0_auc: 0.93006 |  0:01:15s\n",
            "epoch 25 | loss: 0.36195 | val_0_auc: 0.92996 |  0:01:19s\n",
            "epoch 26 | loss: 0.36882 | val_0_auc: 0.93259 |  0:01:22s\n",
            "epoch 27 | loss: 0.36514 | val_0_auc: 0.92237 |  0:01:25s\n",
            "epoch 28 | loss: 0.36335 | val_0_auc: 0.9396  |  0:01:28s\n",
            "epoch 29 | loss: 0.34484 | val_0_auc: 0.94593 |  0:01:30s\n",
            "epoch 30 | loss: 0.34972 | val_0_auc: 0.94158 |  0:01:33s\n",
            "epoch 31 | loss: 0.33425 | val_0_auc: 0.93993 |  0:01:40s\n",
            "epoch 32 | loss: 0.34458 | val_0_auc: 0.93805 |  0:01:43s\n",
            "epoch 33 | loss: 0.35641 | val_0_auc: 0.94432 |  0:01:47s\n",
            "epoch 34 | loss: 0.34058 | val_0_auc: 0.93548 |  0:01:55s\n",
            "epoch 35 | loss: 0.34349 | val_0_auc: 0.9416  |  0:02:02s\n",
            "epoch 36 | loss: 0.32411 | val_0_auc: 0.94387 |  0:02:06s\n",
            "epoch 37 | loss: 0.33663 | val_0_auc: 0.94294 |  0:02:10s\n",
            "epoch 38 | loss: 0.33559 | val_0_auc: 0.94839 |  0:02:13s\n",
            "epoch 39 | loss: 0.32315 | val_0_auc: 0.94844 |  0:02:17s\n",
            "epoch 40 | loss: 0.32701 | val_0_auc: 0.94555 |  0:02:20s\n",
            "epoch 41 | loss: 0.3225  | val_0_auc: 0.94348 |  0:02:23s\n",
            "epoch 42 | loss: 0.31808 | val_0_auc: 0.93844 |  0:02:26s\n",
            "epoch 43 | loss: 0.33633 | val_0_auc: 0.94926 |  0:02:30s\n",
            "epoch 44 | loss: 0.32783 | val_0_auc: 0.94123 |  0:02:33s\n",
            "epoch 45 | loss: 0.3252  | val_0_auc: 0.9495  |  0:02:37s\n",
            "epoch 46 | loss: 0.30719 | val_0_auc: 0.95056 |  0:02:40s\n",
            "epoch 47 | loss: 0.31366 | val_0_auc: 0.94479 |  0:02:44s\n",
            "epoch 48 | loss: 0.30712 | val_0_auc: 0.95285 |  0:02:50s\n",
            "epoch 49 | loss: 0.30896 | val_0_auc: 0.94872 |  0:02:58s\n",
            "epoch 50 | loss: 0.30516 | val_0_auc: 0.95404 |  0:03:01s\n",
            "epoch 51 | loss: 0.30873 | val_0_auc: 0.94879 |  0:03:04s\n",
            "epoch 52 | loss: 0.29825 | val_0_auc: 0.93779 |  0:03:07s\n",
            "epoch 53 | loss: 0.30403 | val_0_auc: 0.94542 |  0:03:11s\n",
            "epoch 54 | loss: 0.29583 | val_0_auc: 0.95468 |  0:03:15s\n",
            "epoch 55 | loss: 0.28603 | val_0_auc: 0.94847 |  0:03:18s\n",
            "epoch 56 | loss: 0.29313 | val_0_auc: 0.95345 |  0:03:21s\n",
            "epoch 57 | loss: 0.30099 | val_0_auc: 0.95289 |  0:03:25s\n",
            "epoch 58 | loss: 0.29608 | val_0_auc: 0.94707 |  0:03:28s\n",
            "epoch 59 | loss: 0.30792 | val_0_auc: 0.95126 |  0:03:31s\n",
            "epoch 60 | loss: 0.29254 | val_0_auc: 0.94847 |  0:03:35s\n",
            "epoch 61 | loss: 0.29868 | val_0_auc: 0.94972 |  0:03:38s\n",
            "epoch 62 | loss: 0.31055 | val_0_auc: 0.94827 |  0:03:41s\n",
            "epoch 63 | loss: 0.28911 | val_0_auc: 0.95834 |  0:03:45s\n",
            "epoch 64 | loss: 0.2785  | val_0_auc: 0.96214 |  0:03:49s\n",
            "epoch 65 | loss: 0.28723 | val_0_auc: 0.94551 |  0:03:52s\n",
            "epoch 66 | loss: 0.29273 | val_0_auc: 0.95303 |  0:03:55s\n",
            "epoch 67 | loss: 0.28422 | val_0_auc: 0.94937 |  0:03:59s\n",
            "epoch 68 | loss: 0.28475 | val_0_auc: 0.9506  |  0:04:02s\n",
            "epoch 69 | loss: 0.283   | val_0_auc: 0.95465 |  0:04:06s\n",
            "epoch 70 | loss: 0.29141 | val_0_auc: 0.95251 |  0:04:10s\n",
            "epoch 71 | loss: 0.27637 | val_0_auc: 0.95673 |  0:04:13s\n",
            "epoch 72 | loss: 0.2704  | val_0_auc: 0.95293 |  0:04:17s\n",
            "epoch 73 | loss: 0.27803 | val_0_auc: 0.95857 |  0:04:20s\n",
            "epoch 74 | loss: 0.29648 | val_0_auc: 0.95491 |  0:04:23s\n",
            "\n",
            "Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_auc = 0.96214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       817\n",
            "           1       0.94      0.86      0.90       792\n",
            "\n",
            "    accuracy                           0.90      1609\n",
            "   macro avg       0.91      0.90      0.90      1609\n",
            "weighted avg       0.91      0.90      0.90      1609\n",
            "\n",
            "Accuracy: 0.9036668738346799\n"
          ]
        }
      ]
    }
  ]
}